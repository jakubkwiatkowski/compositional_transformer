
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.3.1, mkdocs-material-8.5.4">
    
    
      
        <title>Layers - grid_transformer</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.80dcb947.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.cbb835fc.min.css">
        
          
          
          <meta name="theme-color" content="#4051b5">
        
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#module-grid_transformerlayers" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="grid_transformer" class="md-header__button md-logo" aria-label="grid_transformer" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            grid_transformer
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Layers
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/jakubkwiatkowski/grid_transformer" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    grid_transformer
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="grid_transformer" class="md-nav__button md-logo" aria-label="grid_transformer" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    grid_transformer
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/jakubkwiatkowski/grid_transformer" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    grid_transformer
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../docs/raven/" class="md-nav__link">
        Raven
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../docs/sudoku/" class="md-nav__link">
        Sudoku
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          Reference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Reference" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Reference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1" type="checkbox" id="__nav_4_1" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1">
          Grid Transformer
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Grid Transformer" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_1">
          <span class="md-nav__icon md-icon"></span>
          Grid Transformer
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../augmentation/" class="md-nav__link">
        Augmentation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../augmented_transformer/" class="md-nav__link">
        Augmented Transformer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../grid_transformer/" class="md-nav__link">
        Grid Transformer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        Index
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Layers
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Layers
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#classes" class="md-nav__link">
    Classes
  </a>
  
    <nav class="md-nav" aria-label="Classes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#conversion" class="md-nav__link">
    Conversion
  </a>
  
    <nav class="md-nav" aria-label="Conversion">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods" class="md-nav__link">
    Static methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_config" class="md-nav__link">
    from_config
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#with_name_scope" class="md-nav__link">
    with_name_scope
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_loss" class="md-nav__link">
    add_loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_metric" class="md-nav__link">
    add_metric
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_update" class="md-nav__link">
    add_update
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_variable" class="md-nav__link">
    add_variable
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_weight" class="md-nav__link">
    add_weight
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#build" class="md-nav__link">
    build
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#call" class="md-nav__link">
    call
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compile" class="md-nav__link">
    compile
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_loss" class="md-nav__link">
    compute_loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_mask" class="md-nav__link">
    compute_mask
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_metrics" class="md-nav__link">
    compute_metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_output_shape" class="md-nav__link">
    compute_output_shape
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_output_signature" class="md-nav__link">
    compute_output_signature
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#count_params" class="md-nav__link">
    count_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate" class="md-nav__link">
    evaluate
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate_generator" class="md-nav__link">
    evaluate_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#finalize_state" class="md-nav__link">
    finalize_state
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_generator" class="md-nav__link">
    fit_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_config" class="md-nav__link">
    get_config
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_input_at" class="md-nav__link">
    get_input_at
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_input_mask_at" class="md-nav__link">
    get_input_mask_at
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_input_shape_at" class="md-nav__link">
    get_input_shape_at
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_layer" class="md-nav__link">
    get_layer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_metrics_result" class="md-nav__link">
    get_metrics_result
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_output_at" class="md-nav__link">
    get_output_at
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_output_mask_at" class="md-nav__link">
    get_output_mask_at
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_output_shape_at" class="md-nav__link">
    get_output_shape_at
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_weight_paths" class="md-nav__link">
    get_weight_paths
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_weights" class="md-nav__link">
    get_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load_weights" class="md-nav__link">
    load_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_predict_function" class="md-nav__link">
    make_predict_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_test_function" class="md-nav__link">
    make_test_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_train_function" class="md-nav__link">
    make_train_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_generator" class="md-nav__link">
    predict_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_on_batch" class="md-nav__link">
    predict_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_step" class="md-nav__link">
    predict_step
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reset_metrics" class="md-nav__link">
    reset_metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reset_states" class="md-nav__link">
    reset_states
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save" class="md-nav__link">
    save
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_spec" class="md-nav__link">
    save_spec
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_weights" class="md-nav__link">
    save_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_weights" class="md-nav__link">
    set_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    summary
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_on_batch" class="md-nav__link">
    test_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_step" class="md-nav__link">
    test_step
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_json" class="md-nav__link">
    to_json
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_yaml" class="md-nav__link">
    to_yaml
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_on_batch" class="md-nav__link">
    train_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_step" class="md-nav__link">
    train_step
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vec" class="md-nav__link">
    Vec
  </a>
  
    <nav class="md-nav" aria-label="Vec">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#attributes" class="md-nav__link">
    Attributes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_1" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods_1" class="md-nav__link">
    Static methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_config_1" class="md-nav__link">
    from_config
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#with_name_scope_1" class="md-nav__link">
    with_name_scope
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_1" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_1" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_loss_1" class="md-nav__link">
    add_loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_metric_1" class="md-nav__link">
    add_metric
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_update_1" class="md-nav__link">
    add_update
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_variable_1" class="md-nav__link">
    add_variable
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_weight_1" class="md-nav__link">
    add_weight
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#build_1" class="md-nav__link">
    build
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#call_1" class="md-nav__link">
    call
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compile_1" class="md-nav__link">
    compile
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_loss_1" class="md-nav__link">
    compute_loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_mask_1" class="md-nav__link">
    compute_mask
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_metrics_1" class="md-nav__link">
    compute_metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_output_shape_1" class="md-nav__link">
    compute_output_shape
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_output_signature_1" class="md-nav__link">
    compute_output_signature
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#count_params_1" class="md-nav__link">
    count_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate_1" class="md-nav__link">
    evaluate
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate_generator_1" class="md-nav__link">
    evaluate_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#finalize_state_1" class="md-nav__link">
    finalize_state
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_1" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_generator_1" class="md-nav__link">
    fit_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_config_1" class="md-nav__link">
    get_config
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_input_at_1" class="md-nav__link">
    get_input_at
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_input_mask_at_1" class="md-nav__link">
    get_input_mask_at
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_input_shape_at_1" class="md-nav__link">
    get_input_shape_at
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_layer_1" class="md-nav__link">
    get_layer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_metrics_result_1" class="md-nav__link">
    get_metrics_result
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_output_at_1" class="md-nav__link">
    get_output_at
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_output_mask_at_1" class="md-nav__link">
    get_output_mask_at
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_output_shape_at_1" class="md-nav__link">
    get_output_shape_at
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_weight_paths_1" class="md-nav__link">
    get_weight_paths
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_weights_1" class="md-nav__link">
    get_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load_weights_1" class="md-nav__link">
    load_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_predict_function_1" class="md-nav__link">
    make_predict_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_test_function_1" class="md-nav__link">
    make_test_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_train_function_1" class="md-nav__link">
    make_train_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_1" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_generator_1" class="md-nav__link">
    predict_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_on_batch_1" class="md-nav__link">
    predict_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_step_1" class="md-nav__link">
    predict_step
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reset_metrics_1" class="md-nav__link">
    reset_metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reset_states_1" class="md-nav__link">
    reset_states
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_1" class="md-nav__link">
    save
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_spec_1" class="md-nav__link">
    save_spec
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_weights_1" class="md-nav__link">
    save_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_weights_1" class="md-nav__link">
    set_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary_1" class="md-nav__link">
    summary
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_on_batch_1" class="md-nav__link">
    test_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_step_1" class="md-nav__link">
    test_step
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_json_1" class="md-nav__link">
    to_json
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_yaml_1" class="md-nav__link">
    to_yaml
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_on_batch_1" class="md-nav__link">
    train_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_step_1" class="md-nav__link">
    train_step
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../mask/" class="md-nav__link">
        Mask
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../parameters/" class="md-nav__link">
        Parameters
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../position_embedding/" class="md-nav__link">
        Position Embedding
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../preprocessing/" class="md-nav__link">
        Preprocessing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../simple_transformer/" class="md-nav__link">
        Simple Transformer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../transformer/" class="md-nav__link">
        Transformer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../transformer_block/" class="md-nav__link">
        Transformer Block
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#classes" class="md-nav__link">
    Classes
  </a>
  
    <nav class="md-nav" aria-label="Classes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#conversion" class="md-nav__link">
    Conversion
  </a>
  
    <nav class="md-nav" aria-label="Conversion">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods" class="md-nav__link">
    Static methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_config" class="md-nav__link">
    from_config
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#with_name_scope" class="md-nav__link">
    with_name_scope
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_loss" class="md-nav__link">
    add_loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_metric" class="md-nav__link">
    add_metric
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_update" class="md-nav__link">
    add_update
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_variable" class="md-nav__link">
    add_variable
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_weight" class="md-nav__link">
    add_weight
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#build" class="md-nav__link">
    build
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#call" class="md-nav__link">
    call
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compile" class="md-nav__link">
    compile
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_loss" class="md-nav__link">
    compute_loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_mask" class="md-nav__link">
    compute_mask
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_metrics" class="md-nav__link">
    compute_metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_output_shape" class="md-nav__link">
    compute_output_shape
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_output_signature" class="md-nav__link">
    compute_output_signature
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#count_params" class="md-nav__link">
    count_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate" class="md-nav__link">
    evaluate
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate_generator" class="md-nav__link">
    evaluate_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#finalize_state" class="md-nav__link">
    finalize_state
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_generator" class="md-nav__link">
    fit_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_config" class="md-nav__link">
    get_config
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_input_at" class="md-nav__link">
    get_input_at
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_input_mask_at" class="md-nav__link">
    get_input_mask_at
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_input_shape_at" class="md-nav__link">
    get_input_shape_at
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_layer" class="md-nav__link">
    get_layer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_metrics_result" class="md-nav__link">
    get_metrics_result
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_output_at" class="md-nav__link">
    get_output_at
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_output_mask_at" class="md-nav__link">
    get_output_mask_at
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_output_shape_at" class="md-nav__link">
    get_output_shape_at
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_weight_paths" class="md-nav__link">
    get_weight_paths
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_weights" class="md-nav__link">
    get_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load_weights" class="md-nav__link">
    load_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_predict_function" class="md-nav__link">
    make_predict_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_test_function" class="md-nav__link">
    make_test_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_train_function" class="md-nav__link">
    make_train_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_generator" class="md-nav__link">
    predict_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_on_batch" class="md-nav__link">
    predict_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_step" class="md-nav__link">
    predict_step
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reset_metrics" class="md-nav__link">
    reset_metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reset_states" class="md-nav__link">
    reset_states
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save" class="md-nav__link">
    save
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_spec" class="md-nav__link">
    save_spec
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_weights" class="md-nav__link">
    save_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_weights" class="md-nav__link">
    set_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    summary
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_on_batch" class="md-nav__link">
    test_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_step" class="md-nav__link">
    test_step
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_json" class="md-nav__link">
    to_json
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_yaml" class="md-nav__link">
    to_yaml
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_on_batch" class="md-nav__link">
    train_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_step" class="md-nav__link">
    train_step
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vec" class="md-nav__link">
    Vec
  </a>
  
    <nav class="md-nav" aria-label="Vec">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#attributes" class="md-nav__link">
    Attributes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_1" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods_1" class="md-nav__link">
    Static methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_config_1" class="md-nav__link">
    from_config
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#with_name_scope_1" class="md-nav__link">
    with_name_scope
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_1" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_1" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_loss_1" class="md-nav__link">
    add_loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_metric_1" class="md-nav__link">
    add_metric
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_update_1" class="md-nav__link">
    add_update
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_variable_1" class="md-nav__link">
    add_variable
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_weight_1" class="md-nav__link">
    add_weight
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#build_1" class="md-nav__link">
    build
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#call_1" class="md-nav__link">
    call
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compile_1" class="md-nav__link">
    compile
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_loss_1" class="md-nav__link">
    compute_loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_mask_1" class="md-nav__link">
    compute_mask
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_metrics_1" class="md-nav__link">
    compute_metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_output_shape_1" class="md-nav__link">
    compute_output_shape
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_output_signature_1" class="md-nav__link">
    compute_output_signature
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#count_params_1" class="md-nav__link">
    count_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate_1" class="md-nav__link">
    evaluate
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate_generator_1" class="md-nav__link">
    evaluate_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#finalize_state_1" class="md-nav__link">
    finalize_state
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_1" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_generator_1" class="md-nav__link">
    fit_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_config_1" class="md-nav__link">
    get_config
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_input_at_1" class="md-nav__link">
    get_input_at
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_input_mask_at_1" class="md-nav__link">
    get_input_mask_at
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_input_shape_at_1" class="md-nav__link">
    get_input_shape_at
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_layer_1" class="md-nav__link">
    get_layer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_metrics_result_1" class="md-nav__link">
    get_metrics_result
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_output_at_1" class="md-nav__link">
    get_output_at
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_output_mask_at_1" class="md-nav__link">
    get_output_mask_at
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_output_shape_at_1" class="md-nav__link">
    get_output_shape_at
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_weight_paths_1" class="md-nav__link">
    get_weight_paths
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_weights_1" class="md-nav__link">
    get_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load_weights_1" class="md-nav__link">
    load_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_predict_function_1" class="md-nav__link">
    make_predict_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_test_function_1" class="md-nav__link">
    make_test_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_train_function_1" class="md-nav__link">
    make_train_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_1" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_generator_1" class="md-nav__link">
    predict_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_on_batch_1" class="md-nav__link">
    predict_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_step_1" class="md-nav__link">
    predict_step
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reset_metrics_1" class="md-nav__link">
    reset_metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reset_states_1" class="md-nav__link">
    reset_states
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_1" class="md-nav__link">
    save
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_spec_1" class="md-nav__link">
    save_spec
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_weights_1" class="md-nav__link">
    save_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_weights_1" class="md-nav__link">
    set_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary_1" class="md-nav__link">
    summary
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_on_batch_1" class="md-nav__link">
    test_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_step_1" class="md-nav__link">
    test_step
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_json_1" class="md-nav__link">
    to_json
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_yaml_1" class="md-nav__link">
    to_yaml
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_on_batch_1" class="md-nav__link">
    train_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_step_1" class="md-nav__link">
    train_step
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  <a href="https://github.com/jakubkwiatkowski/grid_transformer/edit/main/reference/grid_transformer/layers.md" title="Edit this page" class="md-content__button md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
  </a>


<h1 id="module-grid_transformerlayers">Module grid_transformer.layers</h1>
<p>The module contains two classes, <code>Conversion</code> and <code>Vec</code>.</p>
<p><code>Conversion</code> class is a model that converts input sequence of tokens to a sequence of tokens desired size and desired number of tokens. It can be initialized with a desired size and maximum token number. The build method is used to set the token_max and mul attributes based on the input_shape, and the call method performs the conversion by reshaping the inputs tensor.</p>
<p><code>Vec</code> class is a model that applies a given model on each element of the input tensor. It is initialized with a model, and the call method applies the model on each element of the input tensor by first transposing the input tensor and then using tf.vectorized_map to apply the model on each element, and then transposing the output tensor.</p>
<p>Example usage:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># create an instance of Conversion model</span>
<span class="n">conversion_model</span> <span class="o">=</span> <span class="n">Conversion</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">max_</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">conversion_model</span><span class="o">.</span><span class="n">build</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>

<span class="c1"># create an instance of Vec model</span>
<span class="n">vec_model</span> <span class="o">=</span> <span class="n">Vec</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">64</span><span class="p">))</span>

<span class="c1"># input tensor</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">100</span><span class="p">))</span>

<span class="c1"># apply conversion model on input tensor</span>
<span class="n">converted_x</span> <span class="o">=</span> <span class="n">conversion_model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># apply vec model on input tensor</span>
<span class="n">vec_x</span> <span class="o">=</span> <span class="n">vec_model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>

<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="s2">&quot;</span><span class="se">&quot;&quot;</span>

<span class="s2">The module contains two classes, `Conversion` and `Vec`.</span>

<span class="s2">`Conversion` class is a model that converts input sequence of tokens to a sequence of tokens desired size and desired number of tokens. It can be initialized with a desired size and maximum token number. The build method is used to set the token_max and mul attributes based on the input_shape, and the call method performs the conversion by reshaping the inputs tensor.</span>

<span class="s2">`Vec` class is a model that applies a given model on each element of the input tensor. It is initialized with a model, and the call method applies the model on each element of the input tensor by first transposing the input tensor and then using tf.vectorized_map to apply the model on each element, and then transposing the output tensor.</span>

<span class="s2">Example usage:</span>

<span class="s2">```python</span>

<span class="s2"># create an instance of Conversion model</span>

<span class="s2">conversion_model = Conversion(size=5, max_=20)</span>

<span class="s2">conversion_model.build((None, 30, 100))</span>

<span class="s2"># create an instance of Vec model</span>

<span class="s2">vec_model = Vec(tf.keras.layers.Dense(units=64))</span>

<span class="s2"># input tensor</span>

<span class="s2">x = tf.random.normal((10,30,100))</span>

<span class="s2"># apply conversion model on input tensor</span>

<span class="s2">converted_x = conversion_model(x)</span>

<span class="s2"># apply vec model on input tensor</span>

<span class="s2">vec_x = vec_model(x)</span>

<span class="s2">```</span>

<span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="k">from</span><span class="w"> </span><span class="n">typing</span><span class="w"> </span><span class="k">import</span><span class="w"> </span><span class="n">Tuple</span><span class="p">,</span><span class="w"> </span><span class="k">Optional</span>

<span class="k">import</span><span class="w"> </span><span class="n">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">tf</span>

<span class="k">import</span><span class="w"> </span><span class="n">math</span>

<span class="k">from</span><span class="w"> </span><span class="n">loguru</span><span class="w"> </span><span class="k">import</span><span class="w"> </span><span class="n">logger</span>

<span class="k">from</span><span class="w"> </span><span class="n">tensorflow</span><span class="p">.</span><span class="n">keras</span><span class="w"> </span><span class="k">import</span><span class="w"> </span><span class="n">Model</span>

<span class="n">class</span><span class="w"> </span><span class="n">Conversion</span><span class="p">(</span><span class="n">Model</span><span class="p">)</span><span class="o">:</span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span>

<span class="s2">    A model for converting input sequence of tokens to a sequence of tokens desired size and desired number of tokens..</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="o">:</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">9</span><span class="p">,</span><span class="w"> </span><span class="n">max_</span><span class="o">:</span><span class="w"> </span><span class="k">Optional</span><span class="err">[</span><span class="kt">int</span><span class="err">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span>

<span class="s2">        Initialize the class with desired size and maximum token number.</span>

<span class="s2">        :param size: The desired size of the output tokens.</span>

<span class="s2">        :param max_: The maximum number of tokens in the output shape.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="k">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">token_max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">max_</span><span class="w">  </span><span class="c1"># number off transformer output token that will be used to create model output</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">size</span><span class="w">  </span><span class="c1"># number of outputs</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">mul</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">build</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">input_shape</span><span class="o">:</span><span class="w"> </span><span class="n">Tuple</span><span class="err">[</span><span class="kt">int</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="err">]</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="k">None</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span>

<span class="s2">        Build the model.</span>

<span class="s2">        :param input_shape: The input shape of the model.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">token_max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="o">:</span>

<span class="w">            </span><span class="n">ratio</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input_shape</span><span class="err">[</span><span class="mi">1</span><span class="err">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">size</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">ratio</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">mul</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">math</span><span class="p">.</span><span class="nf">ceil</span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">ratio</span><span class="p">)</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">token_max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">size</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">input_shape</span><span class="err">[</span><span class="mi">2</span><span class="err">]</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">mul</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="o">:</span>

<span class="w">                    </span><span class="c1"># todo high rise error</span>

<span class="w">                    </span><span class="n">logger</span><span class="p">.</span><span class="k">error</span><span class="p">(</span>

<span class="w">                        </span><span class="n">f</span><span class="s2">&quot;To create {self.size} from {input_shape[1]} tokens the size of transformer {input_shape[2]} need to divisible by {self.mul}.&quot;</span><span class="p">)</span>

<span class="w">            </span><span class="k">else</span><span class="o">:</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">token_max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">math</span><span class="p">.</span><span class="nf">floor</span><span class="p">(</span><span class="n">ratio</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">size</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="k">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="o">:</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span>

<span class="s2">        Perform the conversion.</span>

<span class="s2">        :param inputs: Input tensor of shape (batch_size, tokens, features).</span>

<span class="s2">        :return: Tensor of shape (batch_size, size, features * (token_max / size)).</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="k">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="n">shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">mul</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span>

<span class="w">            </span><span class="n">inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="n">shape</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">shape</span><span class="err">[</span><span class="mi">1</span><span class="err">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">mul</span><span class="p">),</span><span class="w"> </span><span class="kt">int</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">shape</span><span class="err">[</span><span class="mi">2</span><span class="err">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">mul</span><span class="p">)))</span>

<span class="w">            </span><span class="n">shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inputs</span><span class="err">[</span><span class="o">:</span><span class="p">,</span><span class="w"> </span><span class="o">:</span><span class="n">self</span><span class="p">.</span><span class="n">token_max</span><span class="err">]</span><span class="p">,</span>

<span class="w">                          </span><span class="n">tf</span><span class="p">.</span><span class="n">stack</span><span class="p">(</span><span class="err">[</span><span class="n">shape</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">shape</span><span class="err">[</span><span class="o">-</span><span class="mi">1</span><span class="err">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">token_max</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">size</span><span class="p">))</span><span class="err">]</span><span class="p">))</span>

<span class="n">class</span><span class="w"> </span><span class="n">Vec</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">)</span><span class="o">:</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">model</span><span class="o">:</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span>

<span class="s2">        Class that applies a given model on each element of the input tensor.</span>

<span class="s2">        Parameters:</span>

<span class="s2">            model (tf.keras.Model): The model to apply on each element of the input tensor.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="k">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="k">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="o">:</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span>

<span class="s2">        Applies the model on each element of the input tensor.</span>

<span class="s2">        Parameters:</span>

<span class="s2">            x (tf.Tensor): The input tensor</span>

<span class="s2">        Returns:</span>

<span class="s2">            tf.Tensor: The output tensor with the model applied on each element.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">perm</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">))</span>

<span class="w">        </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">vectorized_map</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">perm</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">))</span>
</code></pre></div>

</details>
<h2 id="classes">Classes</h2>
<h3 id="conversion">Conversion</h3>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">Conversion</span><span class="p">(</span>
    <span class="n">size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">9</span><span class="p">,</span>
    <span class="n">max_</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>A model for converting input sequence of tokens to a sequence of tokens desired size and desired number of tokens..</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="n">Conversion</span><span class="p">(</span><span class="n">Model</span><span class="p">)</span><span class="err">:</span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;</span>

<span class="ss">    A model for converting input sequence of tokens to a sequence of tokens desired size and desired number of tokens..</span>

<span class="ss">    &quot;&quot;&quot;</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">size</span><span class="err">:</span><span class="w"> </span><span class="nc">int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">9</span><span class="p">,</span><span class="w"> </span><span class="nl">max_</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="o">[</span><span class="n">int</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;</span>

<span class="ss">        Initialize the class with desired size and maximum token number.</span>

<span class="ss">        :param size: The desired size of the output tokens.</span>

<span class="ss">        :param max_: The maximum number of tokens in the output shape.</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">token_max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">max_</span><span class="w">  </span><span class="err">#</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="k">off</span><span class="w"> </span><span class="n">transformer</span><span class="w"> </span><span class="k">output</span><span class="w"> </span><span class="n">token</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">used</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="k">create</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="k">output</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="k">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">size</span><span class="w">  </span><span class="err">#</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">mul</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">build</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="nl">input_shape</span><span class="p">:</span><span class="w"> </span><span class="n">Tuple</span><span class="o">[</span><span class="n">int, int, int</span><span class="o">]</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="k">None</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;</span>

<span class="ss">        Build the model.</span>

<span class="ss">        :param input_shape: The input shape of the model.</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">token_max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="err">:</span>

<span class="w">            </span><span class="n">ratio</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input_shape</span><span class="o">[</span><span class="n">1</span><span class="o">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="k">size</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">ratio</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">1</span><span class="err">:</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">mul</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">math</span><span class="p">.</span><span class="n">ceil</span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">ratio</span><span class="p">)</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">token_max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="k">size</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">input_shape</span><span class="o">[</span><span class="n">2</span><span class="o">]</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">mul</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="err">:</span>

<span class="w">                    </span><span class="err">#</span><span class="w"> </span><span class="n">todo</span><span class="w"> </span><span class="n">high</span><span class="w"> </span><span class="n">rise</span><span class="w"> </span><span class="n">error</span>

<span class="w">                    </span><span class="n">logger</span><span class="p">.</span><span class="n">error</span><span class="p">(</span>

<span class="w">                        </span><span class="n">f</span><span class="ss">&quot;To create {self.size} from {input_shape[1]} tokens the size of transformer {input_shape[2]} need to divisible by {self.mul}.&quot;</span><span class="p">)</span>

<span class="w">            </span><span class="k">else</span><span class="err">:</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">token_max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">math</span><span class="p">.</span><span class="nf">floor</span><span class="p">(</span><span class="n">ratio</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="k">size</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="k">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="nl">inputs</span><span class="p">:</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="nl">Tensor</span><span class="p">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;</span>

<span class="ss">        Perform the conversion.</span>

<span class="ss">        :param inputs: Input tensor of shape (batch_size, tokens, features).</span>

<span class="ss">        :return: Tensor of shape (batch_size, size, features * (token_max / size)).</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="k">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">)</span><span class="err">:</span>

<span class="w">        </span><span class="n">shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">mul</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">1</span><span class="err">:</span>

<span class="w">            </span><span class="n">inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="n">shape</span><span class="o">[</span><span class="n">0</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="nc">int</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">shape</span><span class="o">[</span><span class="n">1</span><span class="o">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">mul</span><span class="p">),</span><span class="w"> </span><span class="nc">int</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">shape</span><span class="o">[</span><span class="n">2</span><span class="o">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">mul</span><span class="p">)))</span>

<span class="w">            </span><span class="n">shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inputs</span><span class="o">[</span><span class="n">:, :self.token_max</span><span class="o">]</span><span class="p">,</span>

<span class="w">                          </span><span class="n">tf</span><span class="p">.</span><span class="n">stack</span><span class="p">(</span><span class="o">[</span><span class="n">shape[0</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="k">size</span><span class="p">,</span><span class="w"> </span><span class="nc">int</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">shape</span><span class="o">[</span><span class="n">-1</span><span class="o">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">token_max</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="k">size</span><span class="p">))</span><span class="err">]</span><span class="p">))</span>
</code></pre></div>

</details>
<hr />
<h4 id="ancestors-in-mro">Ancestors (in MRO)</h4>
<ul>
<li>keras.engine.training.Model</li>
<li>keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.trackable.autotrackable.AutoTrackable</li>
<li>tensorflow.python.trackable.base.Trackable</li>
<li>keras.utils.version_utils.LayerVersionSelector</li>
<li>keras.utils.version_utils.ModelVersionSelector</li>
</ul>
<h4 id="static-methods">Static methods</h4>
<h4 id="from_config">from_config</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">from_config</span><span class="p">(</span>
    <span class="n">config</span><span class="p">,</span>
    <span class="n">custom_objects</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a layer from its config.</p>
<p>This method is the reverse of <code>get_config</code>,
capable of instantiating the same layer from the config
dictionary. It does not handle layer connectivity
(handled by Network), nor weights (handled by <code>set_weights</code>).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>config</td>
<td>None</td>
<td>A Python dictionary, typically the<br>output of get_config.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A layer instance.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code>    <span class="nd">@classmethod</span>

    <span class="k">def</span> <span class="nf">from_config</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">custom_objects</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

        <span class="n">compile_config</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;compile_config&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="n">build_input_shape</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;build_input_shape&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="c1"># `from_config` assumes `cls` is either `Functional` or a child class of</span>

        <span class="c1"># `Functional`. In the case that `cls` is meant to behave like a child</span>

        <span class="c1"># class of `Functional` but only inherits from the `Model` class, we</span>

        <span class="c1"># have to call `cls(...)` instead of `Functional.from_config`.</span>

        <span class="kn">from</span> <span class="nn">keras.engine</span> <span class="kn">import</span> <span class="n">functional</span>

        <span class="k">with</span> <span class="n">serialization</span><span class="o">.</span><span class="n">SharedObjectLoadingScope</span><span class="p">():</span>

            <span class="n">functional_model_keys</span> <span class="o">=</span> <span class="p">[</span>

                <span class="s2">&quot;name&quot;</span><span class="p">,</span>

                <span class="s2">&quot;layers&quot;</span><span class="p">,</span>

                <span class="s2">&quot;input_layers&quot;</span><span class="p">,</span>

                <span class="s2">&quot;output_layers&quot;</span><span class="p">,</span>

            <span class="p">]</span>

            <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">key</span> <span class="ow">in</span> <span class="n">config</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">functional_model_keys</span><span class="p">):</span>

                <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">layers</span> <span class="o">=</span> <span class="n">functional</span><span class="o">.</span><span class="n">reconstruct_from_config</span><span class="p">(</span>

                    <span class="n">config</span><span class="p">,</span> <span class="n">custom_objects</span>

                <span class="p">)</span>

                <span class="n">model</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span>

                    <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">)</span>

                <span class="p">)</span>

                <span class="n">functional</span><span class="o">.</span><span class="n">connect_ancillary_layers</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">layers</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>

                <span class="c1"># The config does not contain all the information necessary to</span>

                <span class="c1"># revive a Functional model. This happens when the user creates</span>

                <span class="c1"># subclassed models where `get_config()` is returning</span>

                <span class="c1"># insufficient information to be considered a Functional model.</span>

                <span class="c1"># In this case, we fall back to provide all config into the</span>

                <span class="c1"># constructor of the class.</span>

                <span class="k">try</span><span class="p">:</span>

                    <span class="n">model</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="o">**</span><span class="n">config</span><span class="p">)</span>

                <span class="k">except</span> <span class="ne">TypeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>

                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>

                        <span class="s2">&quot;Unable to revive model from config. When overriding &quot;</span>

                        <span class="s2">&quot;the `get_config()`, make sure that the returned &quot;</span>

                        <span class="s2">&quot;config contains all items used as arguments in the &quot;</span>

                        <span class="sa">f</span><span class="s2">&quot;constructor to </span><span class="si">{</span><span class="bp">cls</span><span class="si">}</span><span class="s2">, which is the default behavior. &quot;</span>

                        <span class="s2">&quot;You can override this default behavior by defining a &quot;</span>

                        <span class="s2">&quot;`from_config` method to specify how to create an &quot;</span>

                        <span class="sa">f</span><span class="s2">&quot;instance of </span><span class="si">{</span><span class="bp">cls</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> from the config. </span><span class="se">\n\n</span><span class="s2">&quot;</span>

                        <span class="sa">f</span><span class="s2">&quot;Error encountered during deserialization:</span><span class="se">\n</span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span>

                    <span class="p">)</span>

            <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">saving_lib</span><span class="o">.</span><span class="n">_SAVING_V3_ENABLED</span><span class="p">,</span> <span class="s2">&quot;value&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>

                <span class="k">if</span> <span class="n">build_input_shape</span><span class="p">:</span>

                    <span class="n">model</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">build_input_shape</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">compile_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

                    <span class="n">model</span><span class="o">.</span><span class="n">_compile_from_config</span><span class="p">(</span><span class="n">compile_config</span><span class="p">,</span> <span class="n">base_class</span><span class="o">=</span><span class="n">Model</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">model</span>
</code></pre></div>

</details>
<h4 id="with_name_scope">with_name_scope</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">with_name_scope</span><span class="p">(</span>
    <span class="n">method</span>
<span class="p">)</span>
</code></pre></div>

<p>Decorator to automatically enter the module name scope.</p>
<blockquote>
<blockquote>
<blockquote>
<p>class MyModule(tf.Module):
...   @tf.Module.with_name_scope
...   def <strong>call</strong>(self, x):
...     if not hasattr(self, 'w'):
...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))
...     return tf.matmul(x, self.w)</p>
</blockquote>
</blockquote>
</blockquote>
<p>Using the above module would produce <code>tf.Variable</code>s and <code>tf.Tensor</code>s whose
names included the module name:</p>
<blockquote>
<blockquote>
<blockquote>
<p>mod = MyModule()
mod(tf.ones([1, 2]))
<tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>
mod.w
<tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,
numpy=..., dtype=float32)></p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>method</td>
<td>None</td>
<td>The method to wrap.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>The original method wrapped such that it enters the module's name scope.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@classmethod</span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">with_name_scope</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span><span class="w"> </span><span class="k">method</span><span class="p">)</span><span class="err">:</span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Decorator to automatically enter the module name scope.</span>

<span class="ss">    &gt;&gt;&gt; class MyModule(tf.Module):</span>

<span class="ss">    ...   @tf.Module.with_name_scope</span>

<span class="ss">    ...   def __call__(self, x):</span>

<span class="ss">    ...     if not hasattr(self, &#39;w&#39;):</span>

<span class="ss">    ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))</span>

<span class="ss">    ...     return tf.matmul(x, self.w)</span>

<span class="ss">    Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose</span>

<span class="ss">    names included the module name:</span>

<span class="ss">    &gt;&gt;&gt; mod = MyModule()</span>

<span class="ss">    &gt;&gt;&gt; mod(tf.ones([1, 2]))</span>

<span class="ss">    &lt;tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)&gt;</span>

<span class="ss">    &gt;&gt;&gt; mod.w</span>

<span class="ss">    &lt;tf.Variable &#39;my_module/Variable:0&#39; shape=(2, 3) dtype=float32,</span>

<span class="ss">    numpy=..., dtype=float32)&gt;</span>

<span class="ss">    Args:</span>

<span class="ss">      method: The method to wrap.</span>

<span class="ss">    Returns:</span>

<span class="ss">      The original method wrapped such that it enters the module&#39;s name scope.</span>

<span class="ss">    &quot;&quot;&quot;</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">method_with_name_scope</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="err">:</span>

<span class="w">      </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="nl">name_scope</span><span class="p">:</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="k">method</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">tf_decorator</span><span class="p">.</span><span class="n">make_decorator</span><span class="p">(</span><span class="k">method</span><span class="p">,</span><span class="w"> </span><span class="n">method_with_name_scope</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="instance-variables">Instance variables</h4>
<div class="codehilite"><pre><span></span><code><span class="n">activity_regularizer</span>
</code></pre></div>

<p>Optional regularizer function for the output of this layer.</p>
<div class="codehilite"><pre><span></span><code><span class="n">compute_dtype</span>
</code></pre></div>

<p>The dtype of the layer's computations.</p>
<p>This is equivalent to <code>Layer.dtype_policy.compute_dtype</code>. Unless
mixed precision is used, this is the same as <code>Layer.dtype</code>, the dtype of
the weights.</p>
<p>Layers automatically cast their inputs to the compute dtype, which
causes computations and the output to be in the compute dtype as well.
This is done by the base Layer class in <code>Layer.__call__</code>, so you do not
have to insert these casts if implementing your own layer.</p>
<p>Layers often perform certain internal computations in higher precision
when <code>compute_dtype</code> is float16 or bfloat16 for numeric stability. The
output will still typically be float16 or bfloat16 in such cases.</p>
<div class="codehilite"><pre><span></span><code><span class="n">distribute_reduction_method</span>
</code></pre></div>

<p>The method employed to reduce per-replica values during training.</p>
<p>Unless specified, the value "auto" will be assumed, indicating that
the reduction strategy should be chosen based on the current
running environment.
See <code>reduce_per_replica</code> function for more details.</p>
<div class="codehilite"><pre><span></span><code><span class="n">distribute_strategy</span>
</code></pre></div>

<p>The <code>tf.distribute.Strategy</code> this model was created under.</p>
<div class="codehilite"><pre><span></span><code><span class="n">dtype</span>
</code></pre></div>

<p>The dtype of the layer weights.</p>
<p>This is equivalent to <code>Layer.dtype_policy.variable_dtype</code>. Unless
mixed precision is used, this is the same as <code>Layer.compute_dtype</code>, the
dtype of the layer's computations.</p>
<div class="codehilite"><pre><span></span><code><span class="n">dtype_policy</span>
</code></pre></div>

<p>The dtype policy associated with this layer.</p>
<p>This is an instance of a <code>tf.keras.mixed_precision.Policy</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">dynamic</span>
</code></pre></div>

<p>Whether the layer is dynamic (eager-only); set in the constructor.</p>
<div class="codehilite"><pre><span></span><code><span class="n">inbound_nodes</span>
</code></pre></div>

<p>Return Functional API nodes upstream of this layer.</p>
<div class="codehilite"><pre><span></span><code><span class="nb">input</span>
</code></pre></div>

<p>Retrieves the input tensor(s) of a layer.</p>
<p>Only applicable if the layer has exactly one input,
i.e. if it is connected to one incoming layer.</p>
<div class="codehilite"><pre><span></span><code><span class="n">input_mask</span>
</code></pre></div>

<p>Retrieves the input mask tensor(s) of a layer.</p>
<p>Only applicable if the layer has exactly one inbound node,
i.e. if it is connected to one incoming layer.</p>
<p>Returns:
    Input mask tensor (potentially None) or list of input
    mask tensors.</p>
<p>Raises:
    AttributeError: if the layer is connected to
    more than one incoming layers.</p>
<div class="codehilite"><pre><span></span><code><span class="n">input_shape</span>
</code></pre></div>

<p>Retrieves the input shape(s) of a layer.</p>
<p>Only applicable if the layer has exactly one input,
i.e. if it is connected to one incoming layer, or if all inputs
have the same shape.</p>
<div class="codehilite"><pre><span></span><code><span class="n">input_spec</span>
</code></pre></div>

<p><code>InputSpec</code> instance(s) describing the input format for this layer.</p>
<p>When you create a layer subclass, you can set <code>self.input_spec</code> to
enable the layer to run input compatibility checks when it is called.
Consider a <code>Conv2D</code> layer: it can only be called on a single input
tensor of rank 4. As such, you can set, in <code>__init__()</code>:</p>
<div class="codehilite"><pre><span></span><code><span class="bp">self</span><span class="o">.</span><span class="n">input_spec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">InputSpec</span><span class="p">(</span><span class="n">ndim</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</code></pre></div>

<p>Now, if you try to call the layer on an input that isn't rank 4
(for instance, an input of shape <code>(2,)</code>, it will raise a
nicely-formatted error:</p>
<div class="codehilite"><pre><span></span><code><span class="n">ValueError</span><span class="o">:</span><span class="w"> </span><span class="n">Input</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="n">conv2d</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">incompatible</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">layer</span><span class="o">:</span>
<span class="n">expected</span><span class="w"> </span><span class="n">ndim</span><span class="o">=</span><span class="mi">4</span><span class="o">,</span><span class="w"> </span><span class="n">found</span><span class="w"> </span><span class="n">ndim</span><span class="o">=</span><span class="mi">1</span><span class="o">.</span><span class="w"> </span><span class="n">Full</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="n">received</span><span class="o">:</span><span class="w"> </span><span class="o">[</span><span class="mi">2</span><span class="o">]</span>
</code></pre></div>

<p>Input checks that can be specified via <code>input_spec</code> include:
- Structure (e.g. a single input, a list of 2 inputs, etc)
- Shape
- Rank (ndim)
- Dtype</p>
<p>For more information, see <code>tf.keras.layers.InputSpec</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">layers</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">losses</span>
</code></pre></div>

<p>List of losses added using the <code>add_loss()</code> API.</p>
<p>Variable regularization tensors are created when this property is
accessed, so it is eager safe: accessing <code>losses</code> under a
<code>tf.GradientTape</code> will propagate gradients back to the corresponding
variables.</p>
<div class="codehilite"><pre><span></span><code><span class="n">metrics</span>
</code></pre></div>

<p>Returns the model's metrics added using <code>compile()</code>, <code>add_metric()</code> APIs.</p>
<p>Note: Metrics passed to <code>compile()</code> are available only after a
<code>keras.Model</code> has been trained/evaluated on actual data.</p>
<div class="codehilite"><pre><span></span><code><span class="n">metrics_names</span>
</code></pre></div>

<p>Returns the model's display labels for all outputs.</p>
<p>Note: <code>metrics_names</code> are available only after a <code>keras.Model</code> has been
trained/evaluated on actual data.</p>
<div class="codehilite"><pre><span></span><code><span class="n">name</span>
</code></pre></div>

<p>Name of the layer (string), set in the constructor.</p>
<div class="codehilite"><pre><span></span><code><span class="n">name_scope</span>
</code></pre></div>

<p>Returns a <code>tf.name_scope</code> instance for this class.</p>
<div class="codehilite"><pre><span></span><code><span class="n">non_trainable_variables</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">non_trainable_weights</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">outbound_nodes</span>
</code></pre></div>

<p>Return Functional API nodes downstream of this layer.</p>
<div class="codehilite"><pre><span></span><code><span class="n">output</span>
</code></pre></div>

<p>Retrieves the output tensor(s) of a layer.</p>
<p>Only applicable if the layer has exactly one output,
i.e. if it is connected to one incoming layer.</p>
<div class="codehilite"><pre><span></span><code><span class="n">output_mask</span>
</code></pre></div>

<p>Retrieves the output mask tensor(s) of a layer.</p>
<p>Only applicable if the layer has exactly one inbound node,
i.e. if it is connected to one incoming layer.</p>
<p>Returns:
    Output mask tensor (potentially None) or list of output
    mask tensors.</p>
<p>Raises:
    AttributeError: if the layer is connected to
    more than one incoming layers.</p>
<div class="codehilite"><pre><span></span><code><span class="n">output_shape</span>
</code></pre></div>

<p>Retrieves the output shape(s) of a layer.</p>
<p>Only applicable if the layer has one output,
or if all outputs have the same shape.</p>
<div class="codehilite"><pre><span></span><code><span class="n">run_eagerly</span>
</code></pre></div>

<p>Settable attribute indicating whether the model should run eagerly.</p>
<p>Running eagerly means that your model will be run step by step,
like Python code. Your model might run slower, but it should become
easier for you to debug it by stepping into individual layer calls.</p>
<p>By default, we will attempt to compile your model to a static graph to
deliver the best execution performance.</p>
<div class="codehilite"><pre><span></span><code><span class="n">state_updates</span>
</code></pre></div>

<p>Deprecated, do NOT use!</p>
<p>Returns the <code>updates</code> from all layers that are stateful.</p>
<p>This is useful for separating training updates and
state updates, e.g. when we need to update a layer's internal state
during prediction.</p>
<div class="codehilite"><pre><span></span><code><span class="n">stateful</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">submodules</span>
</code></pre></div>

<p>Sequence of all sub-modules.</p>
<p>Submodules are modules which are properties of this module, or found as
properties of modules which are properties of this module (and so on).</p>
<blockquote>
<blockquote>
<blockquote>
<p>a = tf.Module()
b = tf.Module()
c = tf.Module()
a.b = b
b.c = c
list(a.submodules) == [b, c]
True
list(b.submodules) == [c]
True
list(c.submodules) == []
True</p>
</blockquote>
</blockquote>
</blockquote>
<div class="codehilite"><pre><span></span><code><span class="n">supports_masking</span>
</code></pre></div>

<p>Whether this layer supports computing a mask using <code>compute_mask</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">trainable</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">trainable_variables</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">trainable_weights</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">updates</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">variable_dtype</span>
</code></pre></div>

<p>Alias of <code>Layer.dtype</code>, the dtype of the weights.</p>
<div class="codehilite"><pre><span></span><code><span class="n">variables</span>
</code></pre></div>

<p>Returns the list of all layer variables/weights.</p>
<p>Alias of <code>self.weights</code>.</p>
<p>Note: This will not track the weights of nested <code>tf.Modules</code> that are
not themselves Keras layers.</p>
<div class="codehilite"><pre><span></span><code><span class="n">weights</span>
</code></pre></div>

<p>Returns the list of all layer variables/weights.</p>
<p>Note: This will not track the weights of nested <code>tf.Modules</code> that are
not themselves Keras layers.</p>
<h4 id="methods">Methods</h4>
<h4 id="add_loss">add_loss</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_loss</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">losses</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Add loss tensor(s), potentially dependent on layer inputs.</p>
<p>Some losses (for instance, activity regularization losses) may be
dependent on the inputs passed when calling a layer. Hence, when reusing
the same layer on different inputs <code>a</code> and <code>b</code>, some entries in
<code>layer.losses</code> may be dependent on <code>a</code> and some on <code>b</code>. This method
automatically keeps track of dependencies.</p>
<p>This method can be used inside a subclassed layer or model's <code>call</code>
function, in which case <code>losses</code> should be a Tensor or list of Tensors.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>losses</td>
<td>None</td>
<td>Loss tensor, or list/tuple of tensors. Rather than tensors,<br>losses may also be zero-argument callables which create a loss<br>tensor.</td>
<td>None</td>
</tr>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Used for backwards compatibility only.</td>
<td>None</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code>    <span class="n">def</span> <span class="n">add_loss</span>(<span class="nb">self</span>, <span class="n">losses</span>, **<span class="n">kwargs</span>):

        <span class="s">&quot;&quot;&quot;Add loss tensor(s), potentially dependent on layer inputs.</span>

<span class="s">        Some losses (for instance, activity regularization losses) may be</span>

<span class="s">        dependent on the inputs passed when calling a layer. Hence, when reusing</span>

<span class="s">        the same layer on different inputs `a` and `b`, some entries in</span>

<span class="s">        `layer.losses` may be dependent on `a` and some on `b`. This method</span>

<span class="s">        automatically keeps track of dependencies.</span>

<span class="s">        This method can be used inside a subclassed layer or model&#39;s `call`</span>

<span class="s">        function, in which case `losses` should be a Tensor or list of Tensors.</span>

<span class="s">        Example:</span>

<span class="s">        ```python</span>

<span class="s">        class MyLayer(tf.keras.layers.Layer):</span>

<span class="s">          def call(self, inputs):</span>

<span class="s">            self.add_loss(tf.abs(tf.reduce_mean(inputs)))</span>

<span class="s">            return inputs</span>

<span class="s">        ```</span>

<span class="s">        This method can also be called directly on a Functional Model during</span>

<span class="s">        construction. In this case, any loss Tensors passed to this Model must</span>

<span class="s">        be symbolic and be able to be traced back to the model&#39;s `Input`s. These</span>

<span class="s">        losses become part of the model&#39;s topology and are tracked in</span>

<span class="s">        `get_config`.</span>

<span class="s">        Example:</span>

<span class="s">        ```python</span>

<span class="s">        inputs = tf.keras.Input(shape=(10,))</span>

<span class="s">        x = tf.keras.layers.Dense(10)(inputs)</span>

<span class="s">        outputs = tf.keras.layers.Dense(1)(x)</span>

<span class="s">        model = tf.keras.Model(inputs, outputs)</span>

<span class="s">        # Activity regularization.</span>

<span class="s">        model.add_loss(tf.abs(tf.reduce_mean(x)))</span>

<span class="s">        ```</span>

<span class="s">        If this is not the case for your loss (if, for example, your loss</span>

<span class="s">        references a `Variable` of one of the model&#39;s layers), you can wrap your</span>

<span class="s">        loss in a zero-argument lambda. These losses are not tracked as part of</span>

<span class="s">        the model&#39;s topology since they can&#39;t be serialized.</span>

<span class="s">        Example:</span>

<span class="s">        ```python</span>

<span class="s">        inputs = tf.keras.Input(shape=(10,))</span>

<span class="s">        d = tf.keras.layers.Dense(10)</span>

<span class="s">        x = d(inputs)</span>

<span class="s">        outputs = tf.keras.layers.Dense(1)(x)</span>

<span class="s">        model = tf.keras.Model(inputs, outputs)</span>

<span class="s">        # Weight regularization.</span>

<span class="s">        model.add_loss(lambda: tf.reduce_mean(d.kernel))</span>

<span class="s">        ```</span>

<span class="s">        Args:</span>

<span class="s">          losses: Loss tensor, or list/tuple of tensors. Rather than tensors,</span>

<span class="s">            losses may also be zero-argument callables which create a loss</span>

<span class="s">            tensor.</span>

<span class="s">          **kwargs: Used for backwards compatibility only.</span>

<span class="s">        &quot;&quot;&quot;</span>

        <span class="n">kwargs</span>.<span class="nb">pop</span>(<span class="s">&quot;inputs&quot;</span>, <span class="n">None</span>)

        <span class="k">if</span> <span class="n">kwargs:</span>

            <span class="n">raise</span> <span class="n">TypeError</span>(<span class="nb">f</span><span class="s">&quot;Unknown keyword arguments: {kwargs.keys()}&quot;</span>)

        <span class="n">def</span> <span class="n">_tag_callable</span>(<span class="n">loss</span>):

            <span class="s">&quot;&quot;&quot;Tags callable loss tensor as `_unconditional_loss`.&quot;&quot;&quot;</span>

            <span class="k">if</span> <span class="n">callable</span>(<span class="n">loss</span>):

                <span class="c1"># We run the loss without autocasting, as regularizers are often</span>

                <span class="c1"># numerically unstable in float16.</span>

                <span class="k">with</span> <span class="n">autocast_variable</span>.<span class="n">enable_auto_cast_variables</span>(<span class="n">None</span>):

                    <span class="n">loss</span> = <span class="n">loss</span>()

            <span class="k">if</span> <span class="n">loss</span> <span class="k">is</span> <span class="n">None:</span>

                <span class="c1"># Will be filtered out when computing the .losses property</span>

                <span class="k">return</span> <span class="n">None</span>

            <span class="k">if</span> <span class="nb">not</span> <span class="n">tf</span>.<span class="n">is_tensor</span>(<span class="n">loss</span>):

                <span class="n">loss</span> = <span class="n">tf</span>.<span class="n">convert_to_tensor</span>(<span class="n">loss</span>, <span class="n">dtype</span>=<span class="n">backend</span>.<span class="n">floatx</span>())

            <span class="n">loss</span>.<span class="n">_unconditional_loss</span> = <span class="nb">True</span>

            <span class="k">return</span> <span class="n">loss</span>

        <span class="n">losses</span> = <span class="n">tf</span>.<span class="n">nest</span>.<span class="n">flatten</span>(<span class="n">losses</span>)

        <span class="n">callable_losses</span> = []

        <span class="n">eager_losses</span> = []

        <span class="n">symbolic_losses</span> = []

        <span class="k">for</span> <span class="n">loss</span> <span class="nb">in</span> <span class="n">losses:</span>

            <span class="k">if</span> <span class="n">callable</span>(<span class="n">loss</span>):

                <span class="n">callable_losses</span>.<span class="nb">append</span>(<span class="n">functools</span>.<span class="n">partial</span>(<span class="n">_tag_callable</span>, <span class="n">loss</span>))

                <span class="n">continue</span>

            <span class="k">if</span> <span class="n">loss</span> <span class="k">is</span> <span class="n">None:</span>

                <span class="n">continue</span>

            <span class="k">if</span> <span class="nb">not</span> <span class="n">tf</span>.<span class="n">is_tensor</span>(<span class="n">loss</span>) <span class="o">and</span> <span class="nb">not</span> <span class="n">isinstance</span>(

                <span class="n">loss</span>, <span class="n">keras_tensor</span>.<span class="n">KerasTensor</span>

            ):

                <span class="n">loss</span> = <span class="n">tf</span>.<span class="n">convert_to_tensor</span>(<span class="n">loss</span>, <span class="n">dtype</span>=<span class="n">backend</span>.<span class="n">floatx</span>())

            <span class="c1"># TF Functions should take the eager path.</span>

            <span class="k">if</span> (

                <span class="n">tf_utils</span>.<span class="n">is_symbolic_tensor</span>(<span class="n">loss</span>)

                <span class="o">or</span> <span class="n">isinstance</span>(<span class="n">loss</span>, <span class="n">keras_tensor</span>.<span class="n">KerasTensor</span>)

            ) <span class="o">and</span> <span class="nb">not</span> <span class="n">base_layer_utils</span>.<span class="n">is_in_tf_function</span>():

                <span class="n">symbolic_losses</span>.<span class="nb">append</span>(<span class="n">loss</span>)

            <span class="n">elif</span> <span class="n">tf</span>.<span class="n">is_tensor</span>(<span class="n">loss</span>):

                <span class="n">eager_losses</span>.<span class="nb">append</span>(<span class="n">loss</span>)

        <span class="nb">self</span>.<span class="n">_callable_losses</span>.<span class="n">extend</span>(<span class="n">callable_losses</span>)

        <span class="n">in_call_context</span> = <span class="n">base_layer_utils</span>.<span class="n">call_context</span>().<span class="n">in_call</span>

        <span class="k">if</span> <span class="n">eager_losses</span> <span class="o">and</span> <span class="nb">not</span> <span class="n">in_call_context:</span>

            <span class="n">raise</span> <span class="n">ValueError</span>(

                <span class="s">&quot;Expected a symbolic Tensors or a callable for the loss value. &quot;</span>

                <span class="s">&quot;Please wrap your loss computation in a zero argument `lambda`.&quot;</span>

            )

        <span class="nb">self</span>.<span class="n">_eager_losses</span>.<span class="n">extend</span>(<span class="n">eager_losses</span>)

        <span class="k">for</span> <span class="n">symbolic_loss</span> <span class="nb">in</span> <span class="n">symbolic_losses:</span>

            <span class="k">if</span> <span class="n">getattr</span>(<span class="nb">self</span>, <span class="s">&quot;_is_graph_network&quot;</span>, <span class="nb">False</span>):

                <span class="nb">self</span>.<span class="n">_graph_network_add_loss</span>(<span class="n">symbolic_loss</span>)

            <span class="n">else:</span>

                <span class="c1"># Possible a loss was added in a Layer&#39;s `build`.</span>

                <span class="nb">self</span>.<span class="n">_losses</span>.<span class="nb">append</span>(<span class="n">symbolic_loss</span>)
</code></pre></div>

</details>
<h4 id="add_metric">add_metric</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_metric</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">value</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Adds metric tensor to the layer.</p>
<p>This method can be used inside the <code>call()</code> method of a subclassed layer
or model.</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">MyMetricLayer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MyMetricLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;my_metric_layer&#39;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;metric_1&#39;</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;metric_2&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">inputs</span>
</code></pre></div>

<p>This method can also be called directly on a Functional Model during
construction. In this case, any tensor passed to this Model must
be symbolic and be able to be traced back to the model's <code>Input</code>s. These
metrics become part of the model's topology and are tracked when you
save the model via <code>save()</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="n">math_ops</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;metric_1&#39;</span><span class="p">)</span>
</code></pre></div>

<p>Note: Calling <code>add_metric()</code> with the result of a metric object on a
Functional Model, as shown in the example below, is not supported. This
is because we cannot trace the metric result tensor back to the model's
inputs.</p>
<div class="codehilite"><pre><span></span><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">()(</span><span class="n">x</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;metric_1&#39;</span><span class="p">)</span>
</code></pre></div>

<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>value</td>
<td>None</td>
<td>Metric tensor.</td>
<td>None</td>
</tr>
<tr>
<td>name</td>
<td>None</td>
<td>String metric name.</td>
<td>None</td>
</tr>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Additional keyword arguments for backward compatibility.<br>Accepted values:<br><code>aggregation</code> - When the <code>value</code> tensor provided is not the result<br>of calling a <code>keras.Metric</code> instance, it will be aggregated by<br>default using a <code>keras.Metric.Mean</code>.</td>
<td>None</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">add_metric</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">value</span><span class="p">,</span><span class="w"> </span><span class="k">name</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Adds metric tensor to the layer.</span>

<span class="s2">        This method can be used inside the `call()` method of a subclassed layer</span>

<span class="s2">        or model.</span>

<span class="s2">        ```python</span>

<span class="s2">        class MyMetricLayer(tf.keras.layers.Layer):</span>

<span class="s2">          def __init__(self):</span>

<span class="s2">            super(MyMetricLayer, self).__init__(name=&#39;my_metric_layer&#39;)</span>

<span class="s2">            self.mean = tf.keras.metrics.Mean(name=&#39;metric_1&#39;)</span>

<span class="s2">          def call(self, inputs):</span>

<span class="s2">            self.add_metric(self.mean(inputs))</span>

<span class="s2">            self.add_metric(tf.reduce_sum(inputs), name=&#39;metric_2&#39;)</span>

<span class="s2">            return inputs</span>

<span class="s2">        ```</span>

<span class="s2">        This method can also be called directly on a Functional Model during</span>

<span class="s2">        construction. In this case, any tensor passed to this Model must</span>

<span class="s2">        be symbolic and be able to be traced back to the model&#39;s `Input`s. These</span>

<span class="s2">        metrics become part of the model&#39;s topology and are tracked when you</span>

<span class="s2">        save the model via `save()`.</span>

<span class="s2">        ```python</span>

<span class="s2">        inputs = tf.keras.Input(shape=(10,))</span>

<span class="s2">        x = tf.keras.layers.Dense(10)(inputs)</span>

<span class="s2">        outputs = tf.keras.layers.Dense(1)(x)</span>

<span class="s2">        model = tf.keras.Model(inputs, outputs)</span>

<span class="s2">        model.add_metric(math_ops.reduce_sum(x), name=&#39;metric_1&#39;)</span>

<span class="s2">        ```</span>

<span class="s2">        Note: Calling `add_metric()` with the result of a metric object on a</span>

<span class="s2">        Functional Model, as shown in the example below, is not supported. This</span>

<span class="s2">        is because we cannot trace the metric result tensor back to the model&#39;s</span>

<span class="s2">        inputs.</span>

<span class="s2">        ```python</span>

<span class="s2">        inputs = tf.keras.Input(shape=(10,))</span>

<span class="s2">        x = tf.keras.layers.Dense(10)(inputs)</span>

<span class="s2">        outputs = tf.keras.layers.Dense(1)(x)</span>

<span class="s2">        model = tf.keras.Model(inputs, outputs)</span>

<span class="s2">        model.add_metric(tf.keras.metrics.Mean()(x), name=&#39;metric_1&#39;)</span>

<span class="s2">        ```</span>

<span class="s2">        Args:</span>

<span class="s2">          value: Metric tensor.</span>

<span class="s2">          name: String metric name.</span>

<span class="s2">          **kwargs: Additional keyword arguments for backward compatibility.</span>

<span class="s2">            Accepted values:</span>

<span class="s2">            `aggregation` - When the `value` tensor provided is not the result</span>

<span class="s2">            of calling a `keras.Metric` instance, it will be aggregated by</span>

<span class="s2">            default using a `keras.Metric.Mean`.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">kwargs_keys</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">list</span><span class="p">(</span><span class="n">kwargs</span><span class="p">.</span><span class="k">keys</span><span class="p">())</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">len</span><span class="p">(</span><span class="n">kwargs_keys</span><span class="p">)</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="k">or</span><span class="w"> </span><span class="p">(</span>

<span class="w">            </span><span class="n">len</span><span class="p">(</span><span class="n">kwargs_keys</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">kwargs_keys</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="s2">&quot;aggregation&quot;</span>

<span class="w">        </span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="n">raise</span><span class="w"> </span><span class="n">TypeError</span><span class="p">(</span>

<span class="w">                </span><span class="n">f</span><span class="s2">&quot;Unknown keyword arguments: {kwargs.keys()}. &quot;</span>

<span class="w">                </span><span class="s2">&quot;Expected `aggregation`.&quot;</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="n">from_metric_obj</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hasattr</span><span class="p">(</span><span class="k">value</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;_metric_obj&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="n">is_symbolic</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="k">value</span><span class="p">,</span><span class="w"> </span><span class="n">keras_tensor</span><span class="p">.</span><span class="n">KerasTensor</span><span class="p">)</span>

<span class="w">        </span><span class="n">in_call_context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">base_layer_utils</span><span class="p">.</span><span class="n">call_context</span><span class="p">().</span><span class="n">in_call</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="k">name</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">from_metric_obj</span><span class="o">:</span>

<span class="w">            </span><span class="c1"># Eg. `self.add_metric(math_ops.reduce_sum(x))` In eager mode, we</span>

<span class="w">            </span><span class="c1"># use metric name to lookup a metric. Without a name, a new Mean</span>

<span class="w">            </span><span class="c1"># metric wrapper will be created on every model/layer call. So, we</span>

<span class="w">            </span><span class="c1"># raise an error when no name is provided. We will do the same for</span>

<span class="w">            </span><span class="c1"># symbolic mode for consistency although a name will be generated if</span>

<span class="w">            </span><span class="c1"># no name is provided.</span>

<span class="w">            </span><span class="c1"># We will not raise this error in the foll use case for the sake of</span>

<span class="w">            </span><span class="c1"># consistency as name in provided in the metric constructor.</span>

<span class="w">            </span><span class="c1"># mean = metrics.Mean(name=&#39;my_metric&#39;)</span>

<span class="w">            </span><span class="c1"># model.add_metric(mean(outputs))</span>

<span class="w">            </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                </span><span class="s2">&quot;Please provide a name for your metric like &quot;</span>

<span class="w">                </span><span class="s2">&quot;`self.add_metric(tf.reduce_sum(inputs), &quot;</span>

<span class="w">                </span><span class="s2">&quot;name=&#39;mean_activation&#39;)`&quot;</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="n">elif</span><span class="w"> </span><span class="n">from_metric_obj</span><span class="o">:</span>

<span class="w">            </span><span class="k">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">value</span><span class="p">.</span><span class="n">_metric_obj</span><span class="p">.</span><span class="k">name</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">in_call_context</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">is_symbolic</span><span class="o">:</span>

<span class="w">            </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                </span><span class="s2">&quot;Expected a symbolic Tensor for the metric value, received: &quot;</span>

<span class="w">                </span><span class="o">+</span><span class="w"> </span><span class="n">str</span><span class="p">(</span><span class="k">value</span><span class="p">)</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="c1"># If a metric was added in a Layer&#39;s `call` or `build`.</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">in_call_context</span><span class="w"> </span><span class="k">or</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;_is_graph_network&quot;</span><span class="p">,</span><span class="w"> </span><span class="no">False</span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="c1"># TF Function path should take the eager path.</span>

<span class="w">            </span><span class="c1"># If the given metric is available in `metrics` list we just update</span>

<span class="w">            </span><span class="c1"># state on it, otherwise we create a new metric instance and</span>

<span class="w">            </span><span class="c1"># add it to the `metrics` list.</span>

<span class="w">            </span><span class="n">metric_obj</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="k">value</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;_metric_obj&quot;</span><span class="p">,</span><span class="w"> </span><span class="k">None</span><span class="p">)</span>

<span class="w">            </span><span class="c1"># Tensors that come from a Metric object already updated the Metric</span>

<span class="w">            </span><span class="c1"># state.</span>

<span class="w">            </span><span class="n">should_update_state</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">metric_obj</span>

<span class="w">            </span><span class="k">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">metric_obj</span><span class="p">.</span><span class="k">name</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">metric_obj</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="k">name</span>

<span class="w">            </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_metrics_lock</span><span class="o">:</span>

<span class="w">                </span><span class="k">match</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_existing_metric</span><span class="p">(</span><span class="k">name</span><span class="p">)</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="k">match</span><span class="o">:</span>

<span class="w">                    </span><span class="n">metric_obj</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">match</span>

<span class="w">                </span><span class="n">elif</span><span class="w"> </span><span class="n">metric_obj</span><span class="o">:</span>

<span class="w">                    </span><span class="n">self</span><span class="p">.</span><span class="n">_metrics</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">metric_obj</span><span class="p">)</span>

<span class="w">                </span><span class="k">else</span><span class="o">:</span>

<span class="w">                    </span><span class="c1"># Build the metric object with the value&#39;s dtype if it</span>

<span class="w">                    </span><span class="c1"># defines one</span>

<span class="w">                    </span><span class="n">metric_obj</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">metrics_mod</span><span class="p">.</span><span class="n">Mean</span><span class="p">(</span>

<span class="w">                        </span><span class="k">name</span><span class="o">=</span><span class="k">name</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="o">=</span><span class="n">getattr</span><span class="p">(</span><span class="k">value</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;dtype&quot;</span><span class="p">,</span><span class="w"> </span><span class="k">None</span><span class="p">)</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">                    </span><span class="n">self</span><span class="p">.</span><span class="n">_metrics</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">metric_obj</span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">should_update_state</span><span class="o">:</span>

<span class="w">                </span><span class="n">metric_obj</span><span class="p">(</span><span class="k">value</span><span class="p">)</span>

<span class="w">        </span><span class="k">else</span><span class="o">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">from_metric_obj</span><span class="o">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                    </span><span class="s2">&quot;Using the result of calling a `Metric` object &quot;</span>

<span class="w">                    </span><span class="s2">&quot;when calling `add_metric` on a Functional &quot;</span>

<span class="w">                    </span><span class="s2">&quot;Model is not supported. Please pass the &quot;</span>

<span class="w">                    </span><span class="s2">&quot;Tensor to monitor directly.&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="c1"># Insert layers into the Keras Graph Network.</span>

<span class="w">            </span><span class="n">aggregation</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">from_metric_obj</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s2">&quot;mean&quot;</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">_graph_network_add_metric</span><span class="p">(</span><span class="k">value</span><span class="p">,</span><span class="w"> </span><span class="n">aggregation</span><span class="p">,</span><span class="w"> </span><span class="k">name</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="add_update">add_update</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_update</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">updates</span>
<span class="p">)</span>
</code></pre></div>

<p>Add update op(s), potentially dependent on layer inputs.</p>
<p>Weight updates (for instance, the updates of the moving mean and
variance in a BatchNormalization layer) may be dependent on the inputs
passed when calling a layer. Hence, when reusing the same layer on
different inputs <code>a</code> and <code>b</code>, some entries in <code>layer.updates</code> may be
dependent on <code>a</code> and some on <code>b</code>. This method automatically keeps track
of dependencies.</p>
<p>This call is ignored when eager execution is enabled (in that case,
variable updates are run on the fly and thus do not need to be tracked
for later execution).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>updates</td>
<td>None</td>
<td>Update op, or list/tuple of update ops, or zero-arg callable<br>that returns an update op. A zero-arg callable should be passed in<br>order to disable running the updates by setting <code>trainable=False</code><br>on this Layer, when executing in Eager mode.</td>
<td>None</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@doc_controls.do_not_doc_inheritable</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">add_update</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">updates</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Add update op(s), potentially dependent on layer inputs.</span>

<span class="s2">        Weight updates (for instance, the updates of the moving mean and</span>

<span class="s2">        variance in a BatchNormalization layer) may be dependent on the inputs</span>

<span class="s2">        passed when calling a layer. Hence, when reusing the same layer on</span>

<span class="s2">        different inputs `a` and `b`, some entries in `layer.updates` may be</span>

<span class="s2">        dependent on `a` and some on `b`. This method automatically keeps track</span>

<span class="s2">        of dependencies.</span>

<span class="s2">        This call is ignored when eager execution is enabled (in that case,</span>

<span class="s2">        variable updates are run on the fly and thus do not need to be tracked</span>

<span class="s2">        for later execution).</span>

<span class="s2">        Args:</span>

<span class="s2">          updates: Update op, or list/tuple of update ops, or zero-arg callable</span>

<span class="s2">            that returns an update op. A zero-arg callable should be passed in</span>

<span class="s2">            order to disable running the updates by setting `trainable=False`</span>

<span class="s2">            on this Layer, when executing in Eager mode.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">call_context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">base_layer_utils</span><span class="p">.</span><span class="n">call_context</span><span class="p">()</span>

<span class="w">        </span><span class="c1"># No need to run updates during Functional API construction.</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">call_context</span><span class="p">.</span><span class="n">in_keras_graph</span><span class="o">:</span>

<span class="w">            </span><span class="k">return</span>

<span class="w">        </span><span class="c1"># Callable updates are disabled by setting `trainable=False`.</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">call_context</span><span class="p">.</span><span class="n">frozen</span><span class="o">:</span>

<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="k">update</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">updates</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">callable</span><span class="p">(</span><span class="k">update</span><span class="p">)</span><span class="o">:</span>

<span class="w">                    </span><span class="k">update</span><span class="p">()</span>
</code></pre></div>

</details>
<h4 id="add_variable">add_variable</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_variable</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Deprecated, do NOT use! Alias for <code>add_weight</code>.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@doc_controls.do_not_doc_inheritable</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">add_variable</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Deprecated, do NOT use! Alias for `add_weight`.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="k">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span>

<span class="w">            </span><span class="s2">&quot;`layer.add_variable` is deprecated and &quot;</span>

<span class="w">            </span><span class="s2">&quot;will be removed in a future version. &quot;</span>

<span class="w">            </span><span class="s2">&quot;Please use the `layer.add_weight()` method instead.&quot;</span><span class="p">,</span>

<span class="w">            </span><span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>

<span class="w">        </span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">add_weight</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="add_weight">add_weight</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_weight</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">initializer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">trainable</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">constraint</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">use_resource</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">synchronization</span><span class="o">=&lt;</span><span class="n">VariableSynchronization</span><span class="o">.</span><span class="n">AUTO</span><span class="p">:</span> <span class="mi">0</span><span class="o">&gt;</span><span class="p">,</span>
    <span class="n">aggregation</span><span class="o">=&lt;</span><span class="n">VariableAggregationV2</span><span class="o">.</span><span class="n">NONE</span><span class="p">:</span> <span class="mi">0</span><span class="o">&gt;</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Adds a new variable to the layer.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>name</td>
<td>None</td>
<td>Variable name.</td>
<td>None</td>
</tr>
<tr>
<td>shape</td>
<td>None</td>
<td>Variable shape. Defaults to scalar if unspecified.</td>
<td>scalar if unspecified</td>
</tr>
<tr>
<td>dtype</td>
<td>None</td>
<td>The type of the variable. Defaults to <code>self.dtype</code>.</td>
<td><code>self.dtype</code></td>
</tr>
<tr>
<td>initializer</td>
<td>None</td>
<td>Initializer instance (callable).</td>
<td>None</td>
</tr>
<tr>
<td>regularizer</td>
<td>None</td>
<td>Regularizer instance (callable).</td>
<td>None</td>
</tr>
<tr>
<td>trainable</td>
<td>None</td>
<td>Boolean, whether the variable should be part of the layer's<br>"trainable_variables" (e.g. variables, biases)<br>or "non_trainable_variables" (e.g. BatchNorm mean and variance).<br>Note that <code>trainable</code> cannot be <code>True</code> if <code>synchronization</code><br>is set to <code>ON_READ</code>.</td>
<td>None</td>
</tr>
<tr>
<td>constraint</td>
<td>None</td>
<td>Constraint instance (callable).</td>
<td>None</td>
</tr>
<tr>
<td>use_resource</td>
<td>None</td>
<td>Whether to use a <code>ResourceVariable</code> or not.<br>See <a href="&lt;br&gt;https://www.tensorflow.org/guide/migrate/tf1_vs_tf2#resourcevariables_instead_of_referencevariables">this guide</a><br> for more information.</td>
<td>None</td>
</tr>
<tr>
<td>synchronization</td>
<td>None</td>
<td>Indicates when a distributed a variable will be<br>aggregated. Accepted values are constants defined in the class<br><code>tf.VariableSynchronization</code>. By default the synchronization is set<br>to <code>AUTO</code> and the current <code>DistributionStrategy</code> chooses when to<br>synchronize. If <code>synchronization</code> is set to <code>ON_READ</code>, <code>trainable</code><br>must not be set to <code>True</code>.</td>
<td>None</td>
</tr>
<tr>
<td>aggregation</td>
<td>None</td>
<td>Indicates how a distributed variable will be aggregated.<br>Accepted values are constants defined in the class<br><code>tf.VariableAggregation</code>.</td>
<td>None</td>
</tr>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Additional keyword arguments. Accepted values are <code>getter</code>,<br><code>collections</code>, <code>experimental_autocast</code> and <code>caching_device</code>.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>The variable created.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>When giving unsupported dtype and no initializer or when<br>trainable has been set to True with synchronization set as<br><code>ON_READ</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="p">@</span><span class="n">doc_controls</span><span class="p">.</span><span class="n">for_subclass_implementers</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">add_weight</span><span class="p">(</span>

<span class="w">        </span><span class="nb">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">name</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">shape</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">dtype</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">initializer</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">regularizer</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">trainable</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">constraint</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">use_resource</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">synchronization</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">VariableSynchronization</span><span class="p">.</span><span class="n">AUTO</span><span class="p">,</span>

<span class="w">        </span><span class="n">aggregation</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">VariableAggregation</span><span class="p">.</span><span class="n">NONE</span><span class="p">,</span>

<span class="w">        </span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s">&quot;&quot;&quot;Adds a new variable to the layer.</span>

<span class="w">        </span><span class="nl">Args</span><span class="p">:</span>

<span class="w">          </span><span class="nl">name</span><span class="p">:</span><span class="w"> </span><span class="n">Variable</span><span class="w"> </span><span class="n">name</span><span class="p">.</span>

<span class="w">          </span><span class="nl">shape</span><span class="p">:</span><span class="w"> </span><span class="n">Variable</span><span class="w"> </span><span class="n">shape</span><span class="p">.</span><span class="w"> </span><span class="n">Defaults</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">scalar</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">unspecified</span><span class="p">.</span>

<span class="w">          </span><span class="nl">dtype</span><span class="p">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">type</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">variable</span><span class="p">.</span><span class="w"> </span><span class="n">Defaults</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="err">`</span><span class="nb">self</span><span class="p">.</span><span class="n">dtype</span><span class="err">`</span><span class="p">.</span>

<span class="w">          </span><span class="nl">initializer</span><span class="p">:</span><span class="w"> </span><span class="n">Initializer</span><span class="w"> </span><span class="n">instance</span><span class="w"> </span><span class="p">(</span><span class="n">callable</span><span class="p">).</span>

<span class="w">          </span><span class="nl">regularizer</span><span class="p">:</span><span class="w"> </span><span class="n">Regularizer</span><span class="w"> </span><span class="n">instance</span><span class="w"> </span><span class="p">(</span><span class="n">callable</span><span class="p">).</span>

<span class="w">          </span><span class="nl">trainable</span><span class="p">:</span><span class="w"> </span><span class="kt">Boolean</span><span class="p">,</span><span class="w"> </span><span class="n">whether</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">variable</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">part</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">layer</span><span class="err">&#39;</span><span class="n">s</span>

<span class="w">            </span><span class="s">&quot;trainable_variables&quot;</span><span class="w"> </span><span class="p">(</span><span class="n">e</span><span class="p">.</span><span class="n">g</span><span class="p">.</span><span class="w"> </span><span class="n">variables</span><span class="p">,</span><span class="w"> </span><span class="n">biases</span><span class="p">)</span>

<span class="w">            </span><span class="n">or</span><span class="w"> </span><span class="s">&quot;non_trainable_variables&quot;</span><span class="w"> </span><span class="p">(</span><span class="n">e</span><span class="p">.</span><span class="n">g</span><span class="p">.</span><span class="w"> </span><span class="n">BatchNorm</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">variance</span><span class="p">).</span>

<span class="w">            </span><span class="n">Note</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="err">`</span><span class="n">trainable</span><span class="err">`</span><span class="w"> </span><span class="n">cannot</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="err">`</span><span class="n">True</span><span class="err">`</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="err">`</span><span class="n">synchronization</span><span class="err">`</span>

<span class="w">            </span><span class="n">is</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="err">`</span><span class="n">ON_READ</span><span class="err">`</span><span class="p">.</span>

<span class="w">          </span><span class="nl">constraint</span><span class="p">:</span><span class="w"> </span><span class="n">Constraint</span><span class="w"> </span><span class="n">instance</span><span class="w"> </span><span class="p">(</span><span class="n">callable</span><span class="p">).</span>

<span class="w">          </span><span class="nl">use_resource</span><span class="p">:</span><span class="w"> </span><span class="n">Whether</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">use</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="err">`</span><span class="n">ResourceVariable</span><span class="err">`</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">not</span><span class="p">.</span>

<span class="w">            </span><span class="n">See</span><span class="w"> </span><span class="p">[</span><span class="n">this</span><span class="w"> </span><span class="n">guide</span><span class="p">](</span>

<span class="w">            </span><span class="nl">https</span><span class="p">:</span><span class="c1">//www.tensorflow.org/guide/migrate/tf1_vs_tf2#resourcevariables_instead_of_referencevariables)</span>

<span class="w">             </span><span class="k">for</span><span class="w"> </span><span class="n">more</span><span class="w"> </span><span class="n">information</span><span class="p">.</span>

<span class="w">          </span><span class="nl">synchronization</span><span class="p">:</span><span class="w"> </span><span class="n">Indicates</span><span class="w"> </span><span class="n">when</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">distributed</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">variable</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">be</span>

<span class="w">            </span><span class="n">aggregated</span><span class="p">.</span><span class="w"> </span><span class="n">Accepted</span><span class="w"> </span><span class="n">values</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">constants</span><span class="w"> </span><span class="n">defined</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">class</span>

<span class="w">            </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">VariableSynchronization</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">By</span><span class="w"> </span><span class="k">default</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">synchronization</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">set</span>

<span class="w">            </span><span class="n">to</span><span class="w"> </span><span class="err">`</span><span class="n">AUTO</span><span class="err">`</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">current</span><span class="w"> </span><span class="err">`</span><span class="n">DistributionStrategy</span><span class="err">`</span><span class="w"> </span><span class="n">chooses</span><span class="w"> </span><span class="n">when</span><span class="w"> </span><span class="n">to</span>

<span class="w">            </span><span class="n">synchronize</span><span class="p">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="err">`</span><span class="n">synchronization</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="err">`</span><span class="n">ON_READ</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="err">`</span><span class="n">trainable</span><span class="err">`</span>

<span class="w">            </span><span class="n">must</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="err">`</span><span class="n">True</span><span class="err">`</span><span class="p">.</span>

<span class="w">          </span><span class="nl">aggregation</span><span class="p">:</span><span class="w"> </span><span class="n">Indicates</span><span class="w"> </span><span class="n">how</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">distributed</span><span class="w"> </span><span class="n">variable</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">aggregated</span><span class="p">.</span>

<span class="w">            </span><span class="n">Accepted</span><span class="w"> </span><span class="n">values</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">constants</span><span class="w"> </span><span class="n">defined</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">class</span>

<span class="w">            </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">VariableAggregation</span><span class="err">`</span><span class="p">.</span>

<span class="w">          </span><span class="o">**</span><span class="n">kwargs</span><span class="o">:</span><span class="w"> </span><span class="n">Additional</span><span class="w"> </span><span class="n">keyword</span><span class="w"> </span><span class="n">arguments</span><span class="p">.</span><span class="w"> </span><span class="n">Accepted</span><span class="w"> </span><span class="n">values</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="err">`</span><span class="k">getter</span><span class="err">`</span><span class="p">,</span>

<span class="w">            </span><span class="err">`</span><span class="n">collections</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="err">`</span><span class="n">experimental_autocast</span><span class="err">`</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="err">`</span><span class="n">caching_device</span><span class="err">`</span><span class="p">.</span>

<span class="w">        </span><span class="nl">Returns</span><span class="p">:</span>

<span class="w">          </span><span class="n">The</span><span class="w"> </span><span class="n">variable</span><span class="w"> </span><span class="n">created</span><span class="p">.</span>

<span class="w">        </span><span class="nl">Raises</span><span class="p">:</span>

<span class="w">          </span><span class="nl">ValueError</span><span class="p">:</span><span class="w"> </span><span class="n">When</span><span class="w"> </span><span class="n">giving</span><span class="w"> </span><span class="n">unsupported</span><span class="w"> </span><span class="n">dtype</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">no</span><span class="w"> </span><span class="n">initializer</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">when</span>

<span class="w">            </span><span class="n">trainable</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">been</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">True</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">synchronization</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">as</span>

<span class="w">            </span><span class="err">`</span><span class="n">ON_READ</span><span class="err">`</span><span class="p">.</span>

<span class="w">        </span><span class="s">&quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">None</span><span class="o">:</span>

<span class="w">            </span><span class="n">shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">()</span>

<span class="w">        </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">&quot;partitioner&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">)</span><span class="w">  </span><span class="err">#</span><span class="w"> </span><span class="n">Ignored</span><span class="p">.</span>

<span class="w">        </span><span class="cp"># Validate optional keyword arguments.</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">kwarg</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">kwargs</span><span class="o">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">kwarg</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="p">[</span>

<span class="w">                </span><span class="s">&quot;collections&quot;</span><span class="p">,</span>

<span class="w">                </span><span class="s">&quot;experimental_autocast&quot;</span><span class="p">,</span>

<span class="w">                </span><span class="s">&quot;caching_device&quot;</span><span class="p">,</span>

<span class="w">                </span><span class="s">&quot;getter&quot;</span><span class="p">,</span>

<span class="w">                </span><span class="s">&quot;layout&quot;</span><span class="p">,</span>

<span class="w">            </span><span class="p">]</span><span class="o">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">TypeError</span><span class="p">(</span><span class="s">&quot;Unknown keyword argument:&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">kwarg</span><span class="p">)</span>

<span class="w">        </span><span class="n">collections_arg</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">&quot;collections&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">)</span>

<span class="w">        </span><span class="cp"># &#39;experimental_autocast&#39; can be set to False by the caller to indicate</span>

<span class="w">        </span><span class="cp"># an AutoCastVariable should never be created.</span>

<span class="w">        </span><span class="n">autocast</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">&quot;experimental_autocast&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">True</span><span class="p">)</span>

<span class="w">        </span><span class="cp"># See the docstring for tf.Variable about the details for</span>

<span class="w">        </span><span class="cp"># caching_device.</span>

<span class="w">        </span><span class="n">caching_device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">&quot;caching_device&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">)</span>

<span class="w">        </span><span class="n">layout</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">&quot;layout&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">)</span>

<span class="w">        </span><span class="cp"># Specially handling of auto layout fetch, based on the variable name</span>

<span class="w">        </span><span class="cp"># and attribute name. For built-in keras layers, usually the variable</span>

<span class="w">        </span><span class="cp"># name, eg &#39;kernel&#39;, will match with a &#39;kernel_layout&#39; attribute name on</span>

<span class="w">        </span><span class="cp"># the instance. We will try to do this auto fetch if layout is not</span>

<span class="w">        </span><span class="cp"># explicitly specified. This is mainly a quick workaround for not</span>

<span class="w">        </span><span class="cp"># applying too many interface change to built-in layers, until DTensor</span>

<span class="w">        </span><span class="cp"># is a public API.  Also see dtensor.utils.allow_initializer_layout for</span>

<span class="w">        </span><span class="cp"># more details.</span>

<span class="w">        </span><span class="cp"># TODO(scottzhu): Remove this once dtensor is public to end user.</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">layout</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">name</span><span class="o">:</span>

<span class="w">            </span><span class="n">layout</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span><span class="w"> </span><span class="n">name</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s">&quot;_layout&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">dtype</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">None</span><span class="o">:</span>

<span class="w">            </span><span class="n">dtype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">dtype</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">backend</span><span class="p">.</span><span class="n">floatx</span><span class="p">()</span>

<span class="w">        </span><span class="n">dtype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">as_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">_dtype_policy</span><span class="p">.</span><span class="n">variable_dtype</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">None</span><span class="o">:</span>

<span class="w">            </span><span class="cp"># The policy is &quot;_infer&quot;, so we infer the policy from the variable</span>

<span class="w">            </span><span class="cp"># dtype.</span>

<span class="w">            </span><span class="nb">self</span><span class="p">.</span><span class="n">_set_dtype_policy</span><span class="p">(</span><span class="n">policy</span><span class="p">.</span><span class="n">Policy</span><span class="p">(</span><span class="n">dtype</span><span class="p">.</span><span class="n">base_dtype</span><span class="p">.</span><span class="n">name</span><span class="p">))</span>

<span class="w">        </span><span class="n">initializer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">initializers</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">initializer</span><span class="p">)</span>

<span class="w">        </span><span class="n">regularizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">regularizers</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">regularizer</span><span class="p">)</span>

<span class="w">        </span><span class="n">constraint</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">constraints</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">constraint</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">synchronization</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">VariableSynchronization</span><span class="p">.</span><span class="n">ON_READ</span><span class="o">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">trainable</span><span class="o">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                    </span><span class="s">&quot;Synchronization value can be set to &quot;</span>

<span class="w">                    </span><span class="s">&quot;VariableSynchronization.ON_READ only for non-trainable &quot;</span>

<span class="w">                    </span><span class="s">&quot;variables. You have specified trainable=True and &quot;</span>

<span class="w">                    </span><span class="s">&quot;synchronization=VariableSynchronization.ON_READ.&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="nl">else</span><span class="p">:</span>

<span class="w">                </span><span class="cp"># Set trainable to be false when variable is to be synced on</span>

<span class="w">                </span><span class="cp"># read.</span>

<span class="w">                </span><span class="n">trainable</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">False</span>

<span class="w">        </span><span class="n">elif</span><span class="w"> </span><span class="n">trainable</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">None</span><span class="o">:</span>

<span class="w">            </span><span class="n">trainable</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">True</span>

<span class="w">        </span><span class="cp"># Initialize variable when no initializer provided</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">initializer</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">None</span><span class="o">:</span>

<span class="w">            </span><span class="cp"># If dtype is DT_FLOAT, provide a uniform unit scaling initializer</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">dtype</span><span class="p">.</span><span class="n">is_floating</span><span class="o">:</span>

<span class="w">                </span><span class="n">initializer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">initializers</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">&quot;glorot_uniform&quot;</span><span class="p">)</span>

<span class="w">            </span><span class="cp"># If dtype is DT_INT/DT_UINT, provide a default value `zero`</span>

<span class="w">            </span><span class="cp"># If dtype is DT_BOOL, provide a default value `FALSE`</span>

<span class="w">            </span><span class="n">elif</span><span class="w"> </span><span class="n">dtype</span><span class="p">.</span><span class="n">is_integer</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">dtype</span><span class="p">.</span><span class="n">is_unsigned</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">dtype</span><span class="p">.</span><span class="n">is_bool</span><span class="o">:</span>

<span class="w">                </span><span class="n">initializer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">initializers</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">&quot;zeros&quot;</span><span class="p">)</span>

<span class="w">            </span><span class="cp"># NOTES:Do we need to support for handling DT_STRING and DT_COMPLEX</span>

<span class="w">            </span><span class="cp"># here?</span>

<span class="w">            </span><span class="n">elif</span><span class="w"> </span><span class="s">&quot;getter&quot;</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">kwargs</span><span class="o">:</span>

<span class="w">                </span><span class="cp"># When `getter` is specified, it&#39;s possibly fine for</span>

<span class="w">                </span><span class="cp"># `initializer` to be None since it&#39;s up to the custom `getter`</span>

<span class="w">                </span><span class="cp"># to raise error in case it indeed needs `initializer`.</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                    </span><span class="n">f</span><span class="s">&quot;An initializer for variable {name} of type &quot;</span>

<span class="w">                    </span><span class="n">f</span><span class="s">&quot;{dtype.base_dtype} is required for layer &quot;</span>

<span class="w">                    </span><span class="n">f</span><span class="s">&quot;{self.name}. Received: {initializer}.&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">        </span><span class="k">getter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">&quot;getter&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">base_layer_utils</span><span class="p">.</span><span class="n">make_variable</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span>

<span class="w">            </span><span class="n">autocast</span>

<span class="w">            </span><span class="n">and</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">_dtype_policy</span><span class="p">.</span><span class="n">compute_dtype</span>

<span class="w">            </span><span class="o">!=</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">_dtype_policy</span><span class="p">.</span><span class="n">variable_dtype</span>

<span class="w">            </span><span class="n">and</span><span class="w"> </span><span class="n">dtype</span><span class="p">.</span><span class="n">is_floating</span>

<span class="w">        </span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="n">old_getter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">getter</span>

<span class="w">            </span><span class="cp"># Wrap variable constructor to return an AutoCastVariable.</span>

<span class="w">            </span><span class="n">def</span><span class="w"> </span><span class="k">getter</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">variable</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">old_getter</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">autocast_variable</span><span class="p">.</span><span class="n">create_autocast_variable</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>

<span class="w">            </span><span class="cp"># Also the caching_device does not work with the mixed precision</span>

<span class="w">            </span><span class="cp"># API, disable it if it is specified.</span>

<span class="w">            </span><span class="cp"># TODO(b/142020079): Re-enable it once the bug is fixed.</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">caching_device</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">None</span><span class="o">:</span>

<span class="w">                </span><span class="n">tf_logging</span><span class="p">.</span><span class="n">warning</span><span class="p">(</span>

<span class="w">                    </span><span class="s">&quot;`caching_device` does not work with mixed precision API. &quot;</span>

<span class="w">                    </span><span class="s">&quot;Ignoring user specified `caching_device`.&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">                </span><span class="n">caching_device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">layout</span><span class="o">:</span>

<span class="w">            </span><span class="k">getter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">functools</span><span class="p">.</span><span class="n">partial</span><span class="p">(</span><span class="k">getter</span><span class="p">,</span><span class="w"> </span><span class="n">layout</span><span class="o">=</span><span class="n">layout</span><span class="p">)</span>

<span class="w">        </span><span class="n">variable</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">_add_variable_with_custom_getter</span><span class="p">(</span>

<span class="w">            </span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>

<span class="w">            </span><span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>

<span class="w">            </span><span class="cp"># TODO(allenl): a `make_variable` equivalent should be added as a</span>

<span class="w">            </span><span class="cp"># `Trackable` method.</span>

<span class="w">            </span><span class="k">getter</span><span class="o">=</span><span class="k">getter</span><span class="p">,</span>

<span class="w">            </span><span class="cp"># Manage errors in Layer rather than Trackable.</span>

<span class="w">            </span><span class="n">overwrite</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

<span class="w">            </span><span class="n">initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span>

<span class="w">            </span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>

<span class="w">            </span><span class="n">constraint</span><span class="o">=</span><span class="n">constraint</span><span class="p">,</span>

<span class="w">            </span><span class="n">trainable</span><span class="o">=</span><span class="n">trainable</span><span class="p">,</span>

<span class="w">            </span><span class="n">use_resource</span><span class="o">=</span><span class="n">use_resource</span><span class="p">,</span>

<span class="w">            </span><span class="n">collections</span><span class="o">=</span><span class="n">collections_arg</span><span class="p">,</span>

<span class="w">            </span><span class="n">synchronization</span><span class="o">=</span><span class="n">synchronization</span><span class="p">,</span>

<span class="w">            </span><span class="n">aggregation</span><span class="o">=</span><span class="n">aggregation</span><span class="p">,</span>

<span class="w">            </span><span class="n">caching_device</span><span class="o">=</span><span class="n">caching_device</span><span class="p">,</span>

<span class="w">        </span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">regularizer</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">None</span><span class="o">:</span>

<span class="w">            </span><span class="cp"># TODO(fchollet): in the future, this should be handled at the</span>

<span class="w">            </span><span class="cp"># level of variable creation, and weight regularization losses</span>

<span class="w">            </span><span class="cp"># should be variable attributes.</span>

<span class="w">            </span><span class="n">name_in_scope</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">variable</span><span class="p">.</span><span class="n">name</span><span class="p">[</span><span class="o">:</span><span class="w"> </span><span class="n">variable</span><span class="p">.</span><span class="n">name</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="s">&quot;:&quot;</span><span class="p">)]</span>

<span class="w">            </span><span class="nb">self</span><span class="p">.</span><span class="n">_handle_weight_regularization</span><span class="p">(</span>

<span class="w">                </span><span class="n">name_in_scope</span><span class="p">,</span><span class="w"> </span><span class="n">variable</span><span class="p">,</span><span class="w"> </span><span class="n">regularizer</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">base_layer_utils</span><span class="p">.</span><span class="n">is_split_variable</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">v</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">variable</span><span class="o">:</span>

<span class="w">                </span><span class="n">backend</span><span class="p">.</span><span class="n">track_variable</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">trainable</span><span class="o">:</span>

<span class="w">                    </span><span class="nb">self</span><span class="p">.</span><span class="n">_trainable_weights</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

<span class="w">                </span><span class="nl">else</span><span class="p">:</span>

<span class="w">                    </span><span class="nb">self</span><span class="p">.</span><span class="n">_non_trainable_weights</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

<span class="w">        </span><span class="nl">else</span><span class="p">:</span>

<span class="w">            </span><span class="n">backend</span><span class="p">.</span><span class="n">track_variable</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">trainable</span><span class="o">:</span>

<span class="w">                </span><span class="nb">self</span><span class="p">.</span><span class="n">_trainable_weights</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>

<span class="w">            </span><span class="nl">else</span><span class="p">:</span>

<span class="w">                </span><span class="nb">self</span><span class="p">.</span><span class="n">_non_trainable_weights</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">variable</span>
</code></pre></div>

</details>
<h4 id="build">build</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">build</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

<p>Build the model.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>input_shape</td>
<td>None</td>
<td>The input shape of the model.</td>
<td>None</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="kr">build</span><span class="p">(</span><span class="kr">self</span><span class="p">,</span><span class="w"> </span><span class="n">input_shape</span><span class="o">:</span><span class="w"> </span><span class="n">Tuple</span><span class="p">[</span><span class="n">int</span><span class="p">,</span><span class="w"> </span><span class="n">int</span><span class="p">,</span><span class="w"> </span><span class="n">int</span><span class="p">])</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">None</span><span class="o">:</span>

<span class="w">        </span><span class="s">&quot;&quot;&quot;</span>

<span class="s">        Build the model.</span>

<span class="s">        :param input_shape: The input shape of the model.</span>

<span class="s">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="nf">if</span><span class="w"> </span><span class="kr">self</span><span class="p">.</span><span class="n">token_max</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">None</span><span class="o">:</span>

<span class="w">            </span><span class="n">ratio</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="kr">self</span><span class="p">.</span><span class="n">size</span>

<span class="w">            </span><span class="nf">if</span><span class="w"> </span><span class="n">ratio</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span>

<span class="w">                </span><span class="kr">self</span><span class="p">.</span><span class="n">mul</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">math</span><span class="p">.</span><span class="n">ceil</span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">ratio</span><span class="p">)</span>

<span class="w">                </span><span class="kr">self</span><span class="p">.</span><span class="n">token_max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kr">self</span><span class="p">.</span><span class="n">size</span>

<span class="w">                </span><span class="nf">if</span><span class="w"> </span><span class="n">input_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="kr">self</span><span class="p">.</span><span class="n">mul</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="o">:</span>

<span class="w">                    </span><span class="err">#</span><span class="w"> </span><span class="n">todo</span><span class="w"> </span><span class="n">high</span><span class="w"> </span><span class="n">rise</span><span class="w"> </span><span class="nf">error</span>

<span class="w">                    </span><span class="n">logger</span><span class="p">.</span><span class="nf">error</span><span class="p">(</span>

<span class="w">                        </span><span class="n">f</span><span class="s">&quot;To create {self.size} from {input_shape[1]} tokens the size of transformer {input_shape[2]} need to divisible by {self.mul}.&quot;</span><span class="p">)</span>

<span class="w">            </span><span class="n">else</span><span class="o">:</span>

<span class="w">                </span><span class="kr">self</span><span class="p">.</span><span class="n">token_max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">math</span><span class="p">.</span><span class="n">floor</span><span class="p">(</span><span class="n">ratio</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="kr">self</span><span class="p">.</span><span class="n">size</span>
</code></pre></div>

</details>
<h4 id="call">call</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span>
<span class="p">)</span>
</code></pre></div>

<p>Calls the model on new inputs and returns the outputs as tensors.</p>
<p>In this case <code>call()</code> just reapplies
all ops in the graph to the new inputs
(e.g. build a new computational graph from the provided inputs).</p>
<p>Note: This method should not be called directly. It is only meant to be
overridden when subclassing <code>tf.keras.Model</code>.
To call a model on an input, always use the <code>__call__()</code> method,
i.e. <code>model(inputs)</code>, which relies on the underlying <code>call()</code> method.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>inputs</td>
<td>None</td>
<td>Input tensor, or dict/list/tuple of input tensors.</td>
<td>None</td>
</tr>
<tr>
<td>training</td>
<td>None</td>
<td>Boolean or boolean scalar tensor, indicating whether to<br>run the <code>Network</code> in training mode or inference mode.</td>
<td>None</td>
</tr>
<tr>
<td>mask</td>
<td>None</td>
<td>A mask or list of masks. A mask can be either a boolean tensor<br>or None (no mask). For more details, check the guide<br><a href="https://www.tensorflow.org/guide/keras/masking_and_padding">here</a>.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A tensor if there is a single output, or<br>a list of tensors if there are more than one outputs.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">def</span><span class="w"> </span><span class="nv">call</span><span class="ss">(</span><span class="nv">self</span>,<span class="w"> </span><span class="nv">inputs</span><span class="ss">)</span>:

<span class="w">        </span><span class="nv">shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">tf</span>.<span class="nv">shape</span><span class="ss">(</span><span class="nv">inputs</span><span class="ss">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="nv">self</span>.<span class="nv">mul</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">1</span>:

<span class="w">            </span><span class="nv">inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">tf</span>.<span class="nv">reshape</span><span class="ss">(</span><span class="nv">inputs</span>,<span class="w"> </span><span class="ss">(</span><span class="nv">shape</span>[<span class="mi">0</span>],<span class="w"> </span><span class="nv">int</span><span class="ss">(</span><span class="nv">inputs</span>.<span class="nv">shape</span>[<span class="mi">1</span>]<span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nv">self</span>.<span class="nv">mul</span><span class="ss">)</span>,<span class="w"> </span><span class="nv">int</span><span class="ss">(</span><span class="nv">inputs</span>.<span class="nv">shape</span>[<span class="mi">2</span>]<span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nv">self</span>.<span class="nv">mul</span><span class="ss">)))</span>

<span class="w">            </span><span class="nv">shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">tf</span>.<span class="nv">shape</span><span class="ss">(</span><span class="nv">inputs</span><span class="ss">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="nv">tf</span>.<span class="nv">reshape</span><span class="ss">(</span><span class="nv">inputs</span>[:,<span class="w"> </span>:<span class="nv">self</span>.<span class="nv">token_max</span>],

<span class="w">                          </span><span class="nv">tf</span>.<span class="nv">stack</span><span class="ss">(</span>[<span class="nv">shape</span>[<span class="mi">0</span>],<span class="w"> </span><span class="nv">self</span>.<span class="nv">size</span>,<span class="w"> </span><span class="nv">int</span><span class="ss">(</span><span class="nv">inputs</span>.<span class="nv">shape</span>[<span class="o">-</span><span class="mi">1</span>]<span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">token_max</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nv">self</span>.<span class="nv">size</span><span class="ss">))</span>]<span class="ss">))</span>
</code></pre></div>

</details>
<h4 id="compile">compile</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compile</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">loss_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">weighted_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">run_eagerly</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">steps_per_execution</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">jit_compile</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Configures the model for training.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>optimizer</td>
<td>None</td>
<td>String (name of optimizer) or optimizer instance. See<br><code>tf.keras.optimizers</code>.</td>
<td>None</td>
</tr>
<tr>
<td>loss</td>
<td>None</td>
<td>Loss function. May be a string (name of loss function), or<br>a <code>tf.keras.losses.Loss</code> instance. See <code>tf.keras.losses</code>. A loss<br>function is any callable with the signature <code>loss = fn(y_true,&lt;br&gt;y_pred)</code>, where <code>y_true</code> are the ground truth values, and<br><code>y_pred</code> are the model's predictions.<br><code>y_true</code> should have shape<br><code>(batch_size, d0, .. dN)</code> (except in the case of<br>sparse loss functions such as<br>sparse categorical crossentropy which expects integer arrays of<br>shape <code>(batch_size, d0, .. dN-1)</code>).<br><code>y_pred</code> should have shape <code>(batch_size, d0, .. dN)</code>.<br>The loss function should return a float tensor.<br>If a custom <code>Loss</code> instance is<br>used and reduction is set to <code>None</code>, return value has shape<br><code>(batch_size, d0, .. dN-1)</code> i.e. per-sample or per-timestep loss<br>values; otherwise, it is a scalar. If the model has multiple<br>outputs, you can use a different loss on each output by passing a<br>dictionary or a list of losses. The loss value that will be<br>minimized by the model will then be the sum of all individual<br>losses, unless <code>loss_weights</code> is specified.</td>
<td>None</td>
</tr>
<tr>
<td>metrics</td>
<td>None</td>
<td>List of metrics to be evaluated by the model during<br>training and testing. Each of this can be a string (name of a<br>built-in function), function or a <code>tf.keras.metrics.Metric</code><br>instance. See <code>tf.keras.metrics</code>. Typically you will use<br><code>metrics=['accuracy']</code>.<br>A function is any callable with the signature <code>result = fn(y_true,&lt;br&gt;y_pred)</code>. To specify different metrics for different outputs of a<br>multi-output model, you could also pass a dictionary, such as<br><code>metrics={'output_a':'accuracy', 'output_b':['accuracy', 'mse']}</code>.<br>You can also pass a list to specify a metric or a list of metrics<br>for each output, such as<br><code>metrics=[['accuracy'], ['accuracy', 'mse']]</code><br>or <code>metrics=['accuracy', ['accuracy', 'mse']]</code>. When you pass the<br>strings 'accuracy' or 'acc', we convert this to one of<br><code>tf.keras.metrics.BinaryAccuracy</code>,<br><code>tf.keras.metrics.CategoricalAccuracy</code>,<br><code>tf.keras.metrics.SparseCategoricalAccuracy</code> based on the shapes<br>of the targets and of the model output. We do a similar<br>conversion for the strings 'crossentropy' and 'ce' as well.<br>The metrics passed here are evaluated without sample weighting; if<br>you would like sample weighting to apply, you can specify your<br>metrics via the <code>weighted_metrics</code> argument instead.</td>
<td>None</td>
</tr>
<tr>
<td>loss_weights</td>
<td>None</td>
<td>Optional list or dictionary specifying scalar<br>coefficients (Python floats) to weight the loss contributions of<br>different model outputs. The loss value that will be minimized by<br>the model will then be the <em>weighted sum</em> of all individual<br>losses, weighted by the <code>loss_weights</code> coefficients.  If a list,<br>it is expected to have a 1:1 mapping to the model's outputs. If a<br>dict, it is expected to map output names (strings) to scalar<br>coefficients.</td>
<td>None</td>
</tr>
<tr>
<td>weighted_metrics</td>
<td>None</td>
<td>List of metrics to be evaluated and weighted by<br><code>sample_weight</code> or <code>class_weight</code> during training and testing.</td>
<td>None</td>
</tr>
<tr>
<td>run_eagerly</td>
<td>None</td>
<td>Bool. Defaults to <code>False</code>. If <code>True</code>, this <code>Model</code>'s<br>logic will not be wrapped in a <code>tf.function</code>. Recommended to leave<br>this as <code>None</code> unless your <code>Model</code> cannot be run inside a<br><code>tf.function</code>. <code>run_eagerly=True</code> is not supported when using<br><code>tf.distribute.experimental.ParameterServerStrategy</code>.</td>
<td><code>False</code></td>
</tr>
<tr>
<td>steps_per_execution</td>
<td>None</td>
<td>Int. Defaults to 1. The number of batches to<br>run during each <code>tf.function</code> call. Running multiple batches<br>inside a single <code>tf.function</code> call can greatly improve performance<br>on TPUs or small models with a large Python overhead. At most, one<br>full epoch will be run each execution. If a number larger than the<br>size of the epoch is passed, the execution will be truncated to<br>the size of the epoch. Note that if <code>steps_per_execution</code> is set<br>to <code>N</code>, <code>Callback.on_batch_begin</code> and <code>Callback.on_batch_end</code><br>methods will only be called every <code>N</code> batches (i.e. before/after<br>each <code>tf.function</code> execution).</td>
<td>1</td>
</tr>
<tr>
<td>jit_compile</td>
<td>None</td>
<td>If <code>True</code>, compile the model training step with XLA.<br><a href="https://www.tensorflow.org/xla">XLA</a> is an optimizing compiler<br>for machine learning.<br><code>jit_compile</code> is not enabled for by default.<br>This option cannot be enabled with <code>run_eagerly=True</code>.<br>Note that <code>jit_compile=True</code><br>may not necessarily work for all models.<br>For more information on supported operations please refer to the<br><a href="https://www.tensorflow.org/xla">XLA documentation</a>.<br>Also refer to<br><a href="https://www.tensorflow.org/xla/known_issues">known XLA issues</a><br>for more details.</td>
<td>None</td>
</tr>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Arguments supported for backwards compatibility only.</td>
<td>None</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="p">@</span><span class="n">traceback_utils</span><span class="p">.</span><span class="n">filter_traceback</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">compile</span><span class="p">(</span>

<span class="w">        </span><span class="nb">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">optimizer</span><span class="o">=</span><span class="s">&quot;rmsprop&quot;</span><span class="p">,</span>

<span class="w">        </span><span class="n">loss</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">metrics</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">loss_weights</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">weighted_metrics</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">run_eagerly</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">jit_compile</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s">&quot;&quot;&quot;Configures the model for training.</span>

<span class="w">        </span><span class="nl">Example</span><span class="p">:</span>

<span class="w">        </span><span class="err">```</span><span class="n">python</span>

<span class="w">        </span><span class="n">model</span><span class="p">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">),</span>

<span class="w">                      </span><span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">BinaryCrossentropy</span><span class="p">(),</span>

<span class="w">                      </span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">BinaryAccuracy</span><span class="p">(),</span>

<span class="w">                               </span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">FalseNegatives</span><span class="p">()])</span>

<span class="w">        </span><span class="err">```</span>

<span class="w">        </span><span class="nl">Args</span><span class="p">:</span>

<span class="w">            </span><span class="nl">optimizer</span><span class="p">:</span><span class="w"> </span><span class="n">String</span><span class="w"> </span><span class="p">(</span><span class="n">name</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">optimizer</span><span class="p">)</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">optimizer</span><span class="w"> </span><span class="n">instance</span><span class="p">.</span><span class="w"> </span><span class="n">See</span>

<span class="w">              </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="err">`</span><span class="p">.</span>

<span class="w">            </span><span class="nl">loss</span><span class="p">:</span><span class="w"> </span><span class="n">Loss</span><span class="w"> </span><span class="n">function</span><span class="p">.</span><span class="w"> </span><span class="n">May</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">string</span><span class="w"> </span><span class="p">(</span><span class="n">name</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">function</span><span class="p">),</span><span class="w"> </span><span class="n">or</span>

<span class="w">              </span><span class="n">a</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">Loss</span><span class="err">`</span><span class="w"> </span><span class="n">instance</span><span class="p">.</span><span class="w"> </span><span class="n">See</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">A</span><span class="w"> </span><span class="n">loss</span>

<span class="w">              </span><span class="n">function</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">any</span><span class="w"> </span><span class="n">callable</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">signature</span><span class="w"> </span><span class="err">`</span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fn</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span>

<span class="w">              </span><span class="n">y_pred</span><span class="p">)</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="err">`</span><span class="n">y_true</span><span class="err">`</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">ground</span><span class="w"> </span><span class="n">truth</span><span class="w"> </span><span class="n">values</span><span class="p">,</span><span class="w"> </span><span class="n">and</span>

<span class="w">              </span><span class="err">`</span><span class="n">y_pred</span><span class="err">`</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="err">&#39;</span><span class="n">s</span><span class="w"> </span><span class="n">predictions</span><span class="p">.</span>

<span class="w">              </span><span class="err">`</span><span class="n">y_true</span><span class="err">`</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">shape</span>

<span class="w">              </span><span class="err">`</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="n">d0</span><span class="p">,</span><span class="w"> </span><span class="p">..</span><span class="w"> </span><span class="n">dN</span><span class="p">)</span><span class="err">`</span><span class="w"> </span><span class="p">(</span><span class="n">except</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">case</span><span class="w"> </span><span class="no">of</span>

<span class="w">              </span><span class="no">sparse</span><span class="w"> </span><span class="no">loss</span><span class="w"> </span><span class="no">functions</span><span class="w"> </span><span class="no">such</span><span class="w"> </span><span class="no">as</span>

<span class="w">              </span><span class="no">sparse</span><span class="w"> </span><span class="no">categorical</span><span class="w"> </span><span class="no">crossentropy</span><span class="w"> </span><span class="no">which</span><span class="w"> </span><span class="no">expects</span><span class="w"> </span><span class="no">integer</span><span class="w"> </span><span class="no">arrays</span><span class="w"> </span><span class="no">of</span>

<span class="w">              </span><span class="no">shape</span><span class="w"> </span><span class="err">`</span><span class="p">(</span><span class="no">batch_size</span><span class="p">,</span><span class="w"> </span><span class="no">d0</span><span class="p">,</span><span class="w"> </span><span class="p">..</span><span class="w"> </span><span class="no">dN</span><span class="mi">-1</span><span class="p">)</span><span class="err">`</span><span class="p">).</span>

<span class="w">              </span><span class="err">`</span><span class="no">y_pred</span><span class="err">`</span><span class="w"> </span><span class="no">should</span><span class="w"> </span><span class="no">have</span><span class="w"> </span><span class="no">shape</span><span class="w"> </span><span class="err">`</span><span class="p">(</span><span class="no">batch_size</span><span class="p">,</span><span class="w"> </span><span class="no">d0</span><span class="p">,</span><span class="w"> </span><span class="p">..</span><span class="w"> </span><span class="no">dN</span><span class="p">)</span><span class="err">`</span><span class="p">.</span>

<span class="w">              </span><span class="no">The</span><span class="w"> </span><span class="no">loss</span><span class="w"> </span><span class="no">function</span><span class="w"> </span><span class="no">should</span><span class="w"> </span><span class="no">return</span><span class="w"> </span><span class="no">a</span><span class="w"> </span><span class="no">float</span><span class="w"> </span><span class="no">tensor</span><span class="p">.</span>

<span class="w">              </span><span class="no">If</span><span class="w"> </span><span class="no">a</span><span class="w"> </span><span class="no">custom</span><span class="w"> </span><span class="err">`</span><span class="no">Loss</span><span class="err">`</span><span class="w"> </span><span class="no">instance</span><span class="w"> </span><span class="no">is</span>

<span class="w">              </span><span class="no">used</span><span class="w"> </span><span class="no">and</span><span class="w"> </span><span class="no">reduction</span><span class="w"> </span><span class="no">is</span><span class="w"> </span><span class="no">set</span><span class="w"> </span><span class="no">to</span><span class="w"> </span><span class="err">`</span><span class="no">None</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="no">return</span><span class="w"> </span><span class="no">value</span><span class="w"> </span><span class="no">has</span><span class="w"> </span><span class="no">shape</span>

<span class="w">              </span><span class="err">`</span><span class="p">(</span><span class="no">batch_size</span><span class="p">,</span><span class="w"> </span><span class="no">d0</span><span class="p">,</span><span class="w"> </span><span class="p">..</span><span class="w"> </span><span class="no">dN</span><span class="mi">-1</span><span class="p">)</span><span class="err">`</span><span class="w"> </span><span class="no">i</span><span class="p">.</span><span class="no">e</span><span class="p">.</span><span class="w"> </span><span class="no">per</span><span class="o">-</span><span class="no">sample</span><span class="w"> </span><span class="no">or</span><span class="w"> </span><span class="no">per</span><span class="o">-</span><span class="no">timestep</span><span class="w"> </span><span class="no">loss</span>

<span class="w">              </span><span class="no">values</span><span class="err">;</span><span class="w"> </span><span class="no">otherwise</span><span class="p">,</span><span class="w"> </span><span class="no">it</span><span class="w"> </span><span class="no">is</span><span class="w"> </span><span class="no">a</span><span class="w"> </span><span class="no">scalar</span><span class="p">.</span><span class="w"> </span><span class="no">If</span><span class="w"> </span><span class="no">the</span><span class="w"> </span><span class="no">model</span><span class="w"> </span><span class="no">has</span><span class="w"> </span><span class="no">multiple</span>

<span class="w">              </span><span class="no">outputs</span><span class="p">,</span><span class="w"> </span><span class="no">you</span><span class="w"> </span><span class="no">can</span><span class="w"> </span><span class="no">use</span><span class="w"> </span><span class="no">a</span><span class="w"> </span><span class="no">different</span><span class="w"> </span><span class="no">loss</span><span class="w"> </span><span class="no">on</span><span class="w"> </span><span class="no">each</span><span class="w"> </span><span class="no">output</span><span class="w"> </span><span class="no">by</span><span class="w"> </span><span class="no">passing</span><span class="w"> </span><span class="no">a</span>

<span class="w">              </span><span class="no">dictionary</span><span class="w"> </span><span class="no">or</span><span class="w"> </span><span class="no">a</span><span class="w"> </span><span class="no">list</span><span class="w"> </span><span class="no">of</span><span class="w"> </span><span class="no">losses</span><span class="p">.</span><span class="w"> </span><span class="no">The</span><span class="w"> </span><span class="no">loss</span><span class="w"> </span><span class="no">value</span><span class="w"> </span><span class="no">that</span><span class="w"> </span><span class="no">will</span><span class="w"> </span><span class="no">be</span>

<span class="w">              </span><span class="no">minimized</span><span class="w"> </span><span class="no">by</span><span class="w"> </span><span class="no">the</span><span class="w"> </span><span class="no">model</span><span class="w"> </span><span class="no">will</span><span class="w"> </span><span class="no">then</span><span class="w"> </span><span class="no">be</span><span class="w"> </span><span class="no">the</span><span class="w"> </span><span class="no">sum</span><span class="w"> </span><span class="no">of</span><span class="w"> </span><span class="no">all</span><span class="w"> </span><span class="no">individual</span>

<span class="w">              </span><span class="no">losses</span><span class="p">,</span><span class="w"> </span><span class="no">unless</span><span class="w"> </span><span class="err">`</span><span class="no">loss_weights</span><span class="err">`</span><span class="w"> </span><span class="no">is</span><span class="w"> </span><span class="no">specified</span><span class="p">.</span>

<span class="w">            </span><span class="nl">metrics</span><span class="p">:</span><span class="w"> </span><span class="no">List</span><span class="w"> </span><span class="no">of</span><span class="w"> </span><span class="no">metrics</span><span class="w"> </span><span class="no">to</span><span class="w"> </span><span class="no">be</span><span class="w"> </span><span class="no">evaluated</span><span class="w"> </span><span class="no">by</span><span class="w"> </span><span class="no">the</span><span class="w"> </span><span class="no">model</span><span class="w"> </span><span class="no">during</span>

<span class="w">              </span><span class="no">training</span><span class="w"> </span><span class="no">and</span><span class="w"> </span><span class="no">testing</span><span class="p">.</span><span class="w"> </span><span class="no">Each</span><span class="w"> </span><span class="no">of</span><span class="w"> </span><span class="no">this</span><span class="w"> </span><span class="no">can</span><span class="w"> </span><span class="no">be</span><span class="w"> </span><span class="no">a</span><span class="w"> </span><span class="no">string</span><span class="w"> </span><span class="p">(</span><span class="no">name</span><span class="w"> </span><span class="no">of</span><span class="w"> </span><span class="no">a</span>

<span class="w">              </span><span class="no">built</span><span class="o">-</span><span class="no">in</span><span class="w"> </span><span class="no">function</span><span class="p">),</span><span class="w"> </span><span class="no">function</span><span class="w"> </span><span class="no">or</span><span class="w"> </span><span class="no">a</span><span class="w"> </span><span class="err">`</span><span class="no">tf</span><span class="p">.</span><span class="no">keras</span><span class="p">.</span><span class="no">metrics</span><span class="p">.</span><span class="no">Metric</span><span class="err">`</span>

<span class="w">              </span><span class="no">instance</span><span class="p">.</span><span class="w"> </span><span class="no">See</span><span class="w"> </span><span class="err">`</span><span class="no">tf</span><span class="p">.</span><span class="no">keras</span><span class="p">.</span><span class="no">metrics</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="no">Typically</span><span class="w"> </span><span class="no">you</span><span class="w"> </span><span class="no">will</span><span class="w"> </span><span class="no">use</span>

<span class="w">              </span><span class="err">`</span><span class="no">metrics</span><span class="o">=</span><span class="p">[</span><span class="err">&#39;</span><span class="no">accuracy</span><span class="err">&#39;</span><span class="p">]</span><span class="err">`</span><span class="p">.</span>

<span class="w">              </span><span class="no">A</span><span class="w"> </span><span class="no">function</span><span class="w"> </span><span class="no">is</span><span class="w"> </span><span class="no">any</span><span class="w"> </span><span class="no">callable</span><span class="w"> </span><span class="no">with</span><span class="w"> </span><span class="no">the</span><span class="w"> </span><span class="no">signature</span><span class="w"> </span><span class="err">`</span><span class="no">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="no">fn</span><span class="p">(</span><span class="no">y_true</span><span class="p">,</span>

<span class="w">              </span><span class="no">y_pred</span><span class="p">)</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="no">To</span><span class="w"> </span><span class="no">specify</span><span class="w"> </span><span class="no">different</span><span class="w"> </span><span class="no">metrics</span><span class="w"> </span><span class="no">for</span><span class="w"> </span><span class="no">different</span><span class="w"> </span><span class="no">outputs</span><span class="w"> </span><span class="no">of</span><span class="w"> </span><span class="no">a</span>

<span class="w">              </span><span class="no">multi</span><span class="o">-</span><span class="no">output</span><span class="w"> </span><span class="no">model</span><span class="p">,</span><span class="w"> </span><span class="no">you</span><span class="w"> </span><span class="no">could</span><span class="w"> </span><span class="no">also</span><span class="w"> </span><span class="no">pass</span><span class="w"> </span><span class="no">a</span><span class="w"> </span><span class="no">dictionary</span><span class="p">,</span><span class="w"> </span><span class="no">such</span><span class="w"> </span><span class="no">as</span>

<span class="w">              </span><span class="err">`</span><span class="no">metrics</span><span class="o">=</span><span class="err">{&#39;</span><span class="no">output_a</span><span class="sc">&#39;:&#39;</span><span class="no">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="no">output_b</span><span class="err">&#39;</span><span class="p">:[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="n">mse</span><span class="err">&#39;</span><span class="p">]}</span><span class="err">`</span><span class="p">.</span>

<span class="w">              </span><span class="n">You</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">also</span><span class="w"> </span><span class="n">pass</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">specify</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">metric</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">metrics</span>

<span class="w">              </span><span class="k">for</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="n">output</span><span class="p">,</span><span class="w"> </span><span class="n">such</span><span class="w"> </span><span class="n">as</span>

<span class="w">              </span><span class="err">`</span><span class="n">metrics</span><span class="o">=</span><span class="p">[[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="n">mse</span><span class="err">&#39;</span><span class="p">]]</span><span class="err">`</span>

<span class="w">              </span><span class="n">or</span><span class="w"> </span><span class="err">`</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="n">mse</span><span class="err">&#39;</span><span class="p">]]</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">When</span><span class="w"> </span><span class="n">you</span><span class="w"> </span><span class="n">pass</span><span class="w"> </span><span class="n">the</span>

<span class="w">              </span><span class="n">strings</span><span class="w"> </span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="err">&#39;</span><span class="n">acc</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">convert</span><span class="w"> </span><span class="n">this</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">one</span><span class="w"> </span><span class="n">of</span>

<span class="w">              </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">BinaryAccuracy</span><span class="err">`</span><span class="p">,</span>

<span class="w">              </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">CategoricalAccuracy</span><span class="err">`</span><span class="p">,</span>

<span class="w">              </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">SparseCategoricalAccuracy</span><span class="err">`</span><span class="w"> </span><span class="n">based</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">shapes</span>

<span class="w">              </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">targets</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">output</span><span class="p">.</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="k">do</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">similar</span>

<span class="w">              </span><span class="n">conversion</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">strings</span><span class="w"> </span><span class="err">&#39;</span><span class="n">crossentropy</span><span class="err">&#39;</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="err">&#39;</span><span class="n">ce</span><span class="err">&#39;</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="n">well</span><span class="p">.</span>

<span class="w">              </span><span class="n">The</span><span class="w"> </span><span class="n">metrics</span><span class="w"> </span><span class="n">passed</span><span class="w"> </span><span class="n">here</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">evaluated</span><span class="w"> </span><span class="n">without</span><span class="w"> </span><span class="n">sample</span><span class="w"> </span><span class="n">weighting</span><span class="p">;</span><span class="w"> </span><span class="k">if</span>

<span class="w">              </span><span class="n">you</span><span class="w"> </span><span class="n">would</span><span class="w"> </span><span class="n">like</span><span class="w"> </span><span class="n">sample</span><span class="w"> </span><span class="n">weighting</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">apply</span><span class="p">,</span><span class="w"> </span><span class="n">you</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">specify</span><span class="w"> </span><span class="n">your</span>

<span class="w">              </span><span class="n">metrics</span><span class="w"> </span><span class="n">via</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="err">`</span><span class="n">weighted_metrics</span><span class="err">`</span><span class="w"> </span><span class="n">argument</span><span class="w"> </span><span class="n">instead</span><span class="p">.</span>

<span class="w">            </span><span class="nl">loss_weights</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">dictionary</span><span class="w"> </span><span class="n">specifying</span><span class="w"> </span><span class="n">scalar</span>

<span class="w">              </span><span class="n">coefficients</span><span class="w"> </span><span class="p">(</span><span class="n">Python</span><span class="w"> </span><span class="n">floats</span><span class="p">)</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">weight</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">contributions</span><span class="w"> </span><span class="n">of</span>

<span class="w">              </span><span class="n">different</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">outputs</span><span class="p">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">minimized</span><span class="w"> </span><span class="n">by</span>

<span class="w">              </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">then</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="o">*</span><span class="n">weighted</span><span class="w"> </span><span class="n">sum</span><span class="o">*</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">individual</span>

<span class="w">              </span><span class="n">losses</span><span class="p">,</span><span class="w"> </span><span class="n">weighted</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="err">`</span><span class="n">loss_weights</span><span class="err">`</span><span class="w"> </span><span class="n">coefficients</span><span class="p">.</span><span class="w">  </span><span class="n">If</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="p">,</span>

<span class="w">              </span><span class="n">it</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">expected</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="mi">1</span><span class="w"> </span><span class="n">mapping</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="err">&#39;</span><span class="n">s</span><span class="w"> </span><span class="n">outputs</span><span class="p">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">a</span>

<span class="w">              </span><span class="n">dict</span><span class="p">,</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">expected</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">map</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="n">names</span><span class="w"> </span><span class="p">(</span><span class="n">strings</span><span class="p">)</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">scalar</span>

<span class="w">              </span><span class="n">coefficients</span><span class="p">.</span>

<span class="w">            </span><span class="nl">weighted_metrics</span><span class="p">:</span><span class="w"> </span><span class="n">List</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">metrics</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">evaluated</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">weighted</span><span class="w"> </span><span class="n">by</span>

<span class="w">              </span><span class="err">`</span><span class="n">sample_weight</span><span class="err">`</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="err">`</span><span class="n">class_weight</span><span class="err">`</span><span class="w"> </span><span class="n">during</span><span class="w"> </span><span class="n">training</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">testing</span><span class="p">.</span>

<span class="w">            </span><span class="nl">run_eagerly</span><span class="p">:</span><span class="w"> </span><span class="n">Bool</span><span class="p">.</span><span class="w"> </span><span class="n">Defaults</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="err">`</span><span class="n">False</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="err">`</span><span class="n">True</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="n">this</span><span class="w"> </span><span class="err">`</span><span class="n">Model</span><span class="err">`&#39;</span><span class="n">s</span>

<span class="w">              </span><span class="n">logic</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">wrapped</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">Recommended</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">leave</span>

<span class="w">              </span><span class="n">this</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="err">`</span><span class="n">None</span><span class="err">`</span><span class="w"> </span><span class="n">unless</span><span class="w"> </span><span class="n">your</span><span class="w"> </span><span class="err">`</span><span class="n">Model</span><span class="err">`</span><span class="w"> </span><span class="n">cannot</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">run</span><span class="w"> </span><span class="n">inside</span><span class="w"> </span><span class="n">a</span>

<span class="w">              </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="err">`</span><span class="n">run_eagerly</span><span class="o">=</span><span class="n">True</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">supported</span><span class="w"> </span><span class="n">when</span><span class="w"> </span><span class="n">using</span>

<span class="w">              </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">distribute</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">ParameterServerStrategy</span><span class="err">`</span><span class="p">.</span>

<span class="w">            </span><span class="nl">steps_per_execution</span><span class="p">:</span><span class="w"> </span><span class="n">Int</span><span class="p">.</span><span class="w"> </span><span class="n">Defaults</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="mf">1.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">batches</span><span class="w"> </span><span class="n">to</span>

<span class="w">              </span><span class="n">run</span><span class="w"> </span><span class="n">during</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="w"> </span><span class="n">call</span><span class="p">.</span><span class="w"> </span><span class="n">Running</span><span class="w"> </span><span class="n">multiple</span><span class="w"> </span><span class="n">batches</span>

<span class="w">              </span><span class="n">inside</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">single</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="w"> </span><span class="n">call</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">greatly</span><span class="w"> </span><span class="n">improve</span><span class="w"> </span><span class="n">performance</span>

<span class="w">              </span><span class="n">on</span><span class="w"> </span><span class="n">TPUs</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">small</span><span class="w"> </span><span class="n">models</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">large</span><span class="w"> </span><span class="n">Python</span><span class="w"> </span><span class="n">overhead</span><span class="p">.</span><span class="w"> </span><span class="n">At</span><span class="w"> </span><span class="n">most</span><span class="p">,</span><span class="w"> </span><span class="n">one</span>

<span class="w">              </span><span class="n">full</span><span class="w"> </span><span class="n">epoch</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">run</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="n">execution</span><span class="p">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="n">larger</span><span class="w"> </span><span class="n">than</span><span class="w"> </span><span class="n">the</span>

<span class="w">              </span><span class="n">size</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">epoch</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">passed</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">execution</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">truncated</span><span class="w"> </span><span class="n">to</span>

<span class="w">              </span><span class="n">the</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">epoch</span><span class="p">.</span><span class="w"> </span><span class="n">Note</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="err">`</span><span class="n">steps_per_execution</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">set</span>

<span class="w">              </span><span class="n">to</span><span class="w"> </span><span class="err">`</span><span class="n">N</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="err">`</span><span class="n">Callback</span><span class="p">.</span><span class="n">on_batch_begin</span><span class="err">`</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="err">`</span><span class="n">Callback</span><span class="p">.</span><span class="n">on_batch_end</span><span class="err">`</span>

<span class="w">              </span><span class="n">methods</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">only</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">called</span><span class="w"> </span><span class="n">every</span><span class="w"> </span><span class="err">`</span><span class="n">N</span><span class="err">`</span><span class="w"> </span><span class="n">batches</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="p">.</span><span class="n">e</span><span class="p">.</span><span class="w"> </span><span class="n">before</span><span class="o">/</span><span class="n">after</span>

<span class="w">              </span><span class="n">each</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="w"> </span><span class="n">execution</span><span class="p">).</span>

<span class="w">            </span><span class="nl">jit_compile</span><span class="p">:</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="err">`</span><span class="n">True</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="n">compile</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">training</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">XLA</span><span class="p">.</span>

<span class="w">              </span><span class="p">[</span><span class="n">XLA</span><span class="p">](</span><span class="n">https</span><span class="o">:</span><span class="c1">//www.tensorflow.org/xla) is an optimizing compiler</span>

<span class="w">              </span><span class="k">for</span><span class="w"> </span><span class="n">machine</span><span class="w"> </span><span class="n">learning</span><span class="p">.</span>

<span class="w">              </span><span class="err">`</span><span class="n">jit_compile</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">enabled</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="k">default</span><span class="p">.</span>

<span class="w">              </span><span class="n">This</span><span class="w"> </span><span class="n">option</span><span class="w"> </span><span class="n">cannot</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">enabled</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="err">`</span><span class="n">run_eagerly</span><span class="o">=</span><span class="n">True</span><span class="err">`</span><span class="p">.</span>

<span class="w">              </span><span class="n">Note</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="err">`</span><span class="n">jit_compile</span><span class="o">=</span><span class="n">True</span><span class="err">`</span>

<span class="w">              </span><span class="n">may</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">necessarily</span><span class="w"> </span><span class="n">work</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">models</span><span class="p">.</span>

<span class="w">              </span><span class="n">For</span><span class="w"> </span><span class="n">more</span><span class="w"> </span><span class="n">information</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">supported</span><span class="w"> </span><span class="n">operations</span><span class="w"> </span><span class="n">please</span><span class="w"> </span><span class="n">refer</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span>

<span class="w">              </span><span class="p">[</span><span class="n">XLA</span><span class="w"> </span><span class="n">documentation</span><span class="p">](</span><span class="n">https</span><span class="o">:</span><span class="c1">//www.tensorflow.org/xla).</span>

<span class="w">              </span><span class="n">Also</span><span class="w"> </span><span class="n">refer</span><span class="w"> </span><span class="n">to</span>

<span class="w">              </span><span class="p">[</span><span class="n">known</span><span class="w"> </span><span class="n">XLA</span><span class="w"> </span><span class="n">issues</span><span class="p">](</span><span class="n">https</span><span class="o">:</span><span class="c1">//www.tensorflow.org/xla/known_issues)</span>

<span class="w">              </span><span class="k">for</span><span class="w"> </span><span class="n">more</span><span class="w"> </span><span class="n">details</span><span class="p">.</span>

<span class="w">            </span><span class="o">**</span><span class="n">kwargs</span><span class="o">:</span><span class="w"> </span><span class="n">Arguments</span><span class="w"> </span><span class="n">supported</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">backwards</span><span class="w"> </span><span class="n">compatibility</span><span class="w"> </span><span class="n">only</span><span class="p">.</span>

<span class="w">        </span><span class="s">&quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">base_layer</span><span class="p">.</span><span class="n">keras_api_gauge</span><span class="p">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s">&quot;compile&quot;</span><span class="p">).</span><span class="n">set</span><span class="p">(</span><span class="n">True</span><span class="p">)</span>

<span class="w">        </span><span class="nb">self</span><span class="p">.</span><span class="n">_compile_config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">generic_utils</span><span class="p">.</span><span class="n">Config</span><span class="p">(</span>

<span class="w">            </span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>

<span class="w">            </span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>

<span class="w">            </span><span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span>

<span class="w">            </span><span class="n">loss_weights</span><span class="o">=</span><span class="n">loss_weights</span><span class="p">,</span>

<span class="w">            </span><span class="n">weighted_metrics</span><span class="o">=</span><span class="n">weighted_metrics</span><span class="p">,</span>

<span class="w">            </span><span class="n">run_eagerly</span><span class="o">=</span><span class="n">run_eagerly</span><span class="p">,</span>

<span class="w">            </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="n">steps_per_execution</span><span class="p">,</span>

<span class="w">            </span><span class="n">jit_compile</span><span class="o">=</span><span class="n">jit_compile</span><span class="p">,</span>

<span class="w">        </span><span class="p">)</span>

<span class="w">        </span><span class="n">with</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="s">&quot;experimental_steps_per_execution&quot;</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">kwargs</span><span class="o">:</span>

<span class="w">                </span><span class="n">logging</span><span class="p">.</span><span class="n">warning</span><span class="p">(</span>

<span class="w">                    </span><span class="s">&quot;The argument `steps_per_execution` is no longer &quot;</span>

<span class="w">                    </span><span class="s">&quot;experimental. Pass `steps_per_execution` instead of &quot;</span>

<span class="w">                    </span><span class="s">&quot;`experimental_steps_per_execution`.&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">steps_per_execution</span><span class="o">:</span>

<span class="w">                    </span><span class="n">steps_per_execution</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span>

<span class="w">                        </span><span class="s">&quot;experimental_steps_per_execution&quot;</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">            </span><span class="cp"># When compiling from an already-serialized model, we do not want to</span>

<span class="w">            </span><span class="cp"># reapply some processing steps (e.g. metric renaming for</span>

<span class="w">            </span><span class="cp"># multi-output models, which have prefixes added for each</span>

<span class="w">            </span><span class="cp"># corresponding output name).</span>

<span class="w">            </span><span class="n">from_serialized</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">&quot;from_serialized&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">False</span><span class="p">)</span>

<span class="w">            </span><span class="nb">self</span><span class="p">.</span><span class="n">_validate_compile</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span><span class="w"> </span><span class="n">metrics</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="w">            </span><span class="nb">self</span><span class="p">.</span><span class="n">_run_eagerly</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">run_eagerly</span>

<span class="w">            </span><span class="nb">self</span><span class="p">.</span><span class="n">optimizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">_get_optimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="n">compile_utils</span><span class="p">.</span><span class="n">LossesContainer</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="nb">self</span><span class="p">.</span><span class="n">compiled_loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">loss</span>

<span class="w">            </span><span class="nl">else</span><span class="p">:</span>

<span class="w">                </span><span class="nb">self</span><span class="p">.</span><span class="n">compiled_loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">compile_utils</span><span class="p">.</span><span class="n">LossesContainer</span><span class="p">(</span>

<span class="w">                    </span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="n">loss_weights</span><span class="p">,</span><span class="w"> </span><span class="n">output_names</span><span class="o">=</span><span class="nb">self</span><span class="p">.</span><span class="n">output_names</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="nb">self</span><span class="p">.</span><span class="n">compiled_metrics</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">compile_utils</span><span class="p">.</span><span class="n">MetricsContainer</span><span class="p">(</span>

<span class="w">                </span><span class="n">metrics</span><span class="p">,</span>

<span class="w">                </span><span class="n">weighted_metrics</span><span class="p">,</span>

<span class="w">                </span><span class="n">output_names</span><span class="o">=</span><span class="nb">self</span><span class="p">.</span><span class="n">output_names</span><span class="p">,</span>

<span class="w">                </span><span class="n">from_serialized</span><span class="o">=</span><span class="n">from_serialized</span><span class="p">,</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">            </span><span class="nb">self</span><span class="p">.</span><span class="n">_configure_steps_per_execution</span><span class="p">(</span><span class="n">steps_per_execution</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>

<span class="w">            </span><span class="cp"># Initializes attrs that are reset each time `compile` is called.</span>

<span class="w">            </span><span class="nb">self</span><span class="p">.</span><span class="n">_reset_compile_cache</span><span class="p">()</span>

<span class="w">            </span><span class="nb">self</span><span class="p">.</span><span class="n">_is_compiled</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">True</span>

<span class="w">            </span><span class="nb">self</span><span class="p">.</span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="p">{}</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nb">self</span><span class="p">.</span><span class="n">_run_eagerly</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">dynamic</span><span class="p">)</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">jit_compile</span><span class="o">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                    </span><span class="s">&quot;You cannot enable `run_eagerly` and `jit_compile` &quot;</span>

<span class="w">                    </span><span class="s">&quot;at the same time.&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="nl">else</span><span class="p">:</span>

<span class="w">                </span><span class="nb">self</span><span class="p">.</span><span class="n">_jit_compile</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">jit_compile</span>
</code></pre></div>

</details>
<h4 id="compute_loss">compute_loss</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Compute the total loss, validate it, and return it.</p>
<p>Subclasses can optionally override this method to provide custom loss
computation logic.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input data.</td>
<td>None</td>
</tr>
<tr>
<td>y</td>
<td>None</td>
<td>Target data.</td>
<td>None</td>
</tr>
<tr>
<td>y_pred</td>
<td>None</td>
<td>Predictions returned by the model (output of <code>model(x)</code>)</td>
<td>None</td>
</tr>
<tr>
<td>sample_weight</td>
<td>None</td>
<td>Sample weights for weighting the loss function.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>The total loss as a <code>tf.Tensor</code>, or <code>None</code> if no loss results (which<br>is the case when called by <code>Model.test_step</code>).</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">compute_loss</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Compute the total loss, validate it, and return it.</span>

<span class="s2">        Subclasses can optionally override this method to provide custom loss</span>

<span class="s2">        computation logic.</span>

<span class="s2">        Example:</span>

<span class="s2">        ```python</span>

<span class="s2">        class MyModel(tf.keras.Model):</span>

<span class="s2">          def __init__(self, *args, **kwargs):</span>

<span class="s2">            super(MyModel, self).__init__(*args, **kwargs)</span>

<span class="s2">            self.loss_tracker = tf.keras.metrics.Mean(name=&#39;loss&#39;)</span>

<span class="s2">          def compute_loss(self, x, y, y_pred, sample_weight):</span>

<span class="s2">            loss = tf.reduce_mean(tf.math.squared_difference(y_pred, y))</span>

<span class="s2">            loss += tf.add_n(self.losses)</span>

<span class="s2">            self.loss_tracker.update_state(loss)</span>

<span class="s2">            return loss</span>

<span class="s2">          def reset_metrics(self):</span>

<span class="s2">            self.loss_tracker.reset_states()</span>

<span class="s2">          @property</span>

<span class="s2">          def metrics(self):</span>

<span class="s2">            return [self.loss_tracker]</span>

<span class="s2">        tensors = tf.random.uniform((10, 10)), tf.random.uniform((10,))</span>

<span class="s2">        dataset = tf.data.Dataset.from_tensor_slices(tensors).repeat().batch(1)</span>

<span class="s2">        inputs = tf.keras.layers.Input(shape=(10,), name=&#39;my_input&#39;)</span>

<span class="s2">        outputs = tf.keras.layers.Dense(10)(inputs)</span>

<span class="s2">        model = MyModel(inputs, outputs)</span>

<span class="s2">        model.add_loss(tf.reduce_sum(outputs))</span>

<span class="s2">        optimizer = tf.keras.optimizers.SGD()</span>

<span class="s2">        model.compile(optimizer, loss=&#39;mse&#39;, steps_per_execution=10)</span>

<span class="s2">        model.fit(dataset, epochs=2, steps_per_epoch=10)</span>

<span class="s2">        print(&#39;My custom loss: &#39;, model.loss_tracker.result().numpy())</span>

<span class="s2">        ```</span>

<span class="s2">        Args:</span>

<span class="s2">          x: Input data.</span>

<span class="s2">          y: Target data.</span>

<span class="s2">          y_pred: Predictions returned by the model (output of `model(x)`)</span>

<span class="s2">          sample_weight: Sample weights for weighting the loss function.</span>

<span class="s2">        Returns:</span>

<span class="s2">          The total loss as a `tf.Tensor`, or `None` if no loss results (which</span>

<span class="s2">          is the case when called by `Model.test_step`).</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">del</span><span class="w"> </span><span class="n">x</span><span class="w">  </span><span class="c1"># The default implementation does not use `x`.</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">compiled_loss</span><span class="p">(</span>

<span class="w">            </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">,</span><span class="w"> </span><span class="n">regularization_losses</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">losses</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="compute_mask">compute_mask</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_mask</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">,</span>
    <span class="n">mask</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Computes an output mask tensor.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>inputs</td>
<td>None</td>
<td>Tensor or list of tensors.</td>
<td>None</td>
</tr>
<tr>
<td>mask</td>
<td>None</td>
<td>Tensor or list of tensors.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>None or a tensor (or list of tensors,<br>one per output tensor of the layer).</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@generic_utils</span><span class="p">.</span><span class="k">default</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">compute_mask</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">mask</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Computes an output mask tensor.</span>

<span class="ss">        Args:</span>

<span class="ss">            inputs: Tensor or list of tensors.</span>

<span class="ss">            mask: Tensor or list of tensors.</span>

<span class="ss">        Returns:</span>

<span class="ss">            None or a tensor (or list of tensors,</span>

<span class="ss">                one per output tensor of the layer).</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="nl">_supports_masking</span><span class="p">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="ow">any</span><span class="p">(</span><span class="n">m</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">mask</span><span class="p">))</span><span class="err">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">TypeError</span><span class="p">(</span>

<span class="w">                    </span><span class="ss">&quot;Layer &quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">name</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="ss">&quot; does not support masking, &quot;</span>

<span class="w">                    </span><span class="ss">&quot;but was passed an input_mask: &quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">str</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="err">#</span><span class="w"> </span><span class="n">masking</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">explicitly</span><span class="w"> </span><span class="nl">supported</span><span class="p">:</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">mask</span><span class="p">.</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="k">None</span>

<span class="w">        </span><span class="err">#</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">masking</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">explicitly</span><span class="w"> </span><span class="n">supported</span><span class="p">,</span><span class="w"> </span><span class="k">by</span><span class="w"> </span><span class="k">default</span>

<span class="w">        </span><span class="err">#</span><span class="w"> </span><span class="n">carry</span><span class="w"> </span><span class="k">over</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">input</span><span class="w"> </span><span class="n">mask</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">mask</span>
</code></pre></div>

</details>
<h4 id="compute_metrics">compute_metrics</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">,</span>
    <span class="n">sample_weight</span>
<span class="p">)</span>
</code></pre></div>

<p>Update metric states and collect all metrics to be returned.</p>
<p>Subclasses can optionally override this method to provide custom metric
updating and collection logic.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input data.</td>
<td>None</td>
</tr>
<tr>
<td>y</td>
<td>None</td>
<td>Target data.</td>
<td>None</td>
</tr>
<tr>
<td>y_pred</td>
<td>None</td>
<td>Predictions returned by the model (output of <code>model.call(x)</code>)</td>
<td>None</td>
</tr>
<tr>
<td>sample_weight</td>
<td>None</td>
<td>Sample weights for weighting the loss function.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A <code>dict</code> containing values that will be passed to<br><code>tf.keras.callbacks.CallbackList.on_train_batch_end()</code>. Typically, the<br>values of the metrics listed in <code>self.metrics</code> are returned. Example:<br><code>{'loss': 0.2, 'accuracy': 0.7}</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">compute_metrics</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Update metric states and collect all metrics to be returned.</span>

<span class="s2">        Subclasses can optionally override this method to provide custom metric</span>

<span class="s2">        updating and collection logic.</span>

<span class="s2">        Example:</span>

<span class="s2">        ```python</span>

<span class="s2">        class MyModel(tf.keras.Sequential):</span>

<span class="s2">          def compute_metrics(self, x, y, y_pred, sample_weight):</span>

<span class="s2">            # This super call updates `self.compiled_metrics` and returns</span>

<span class="s2">            # results for all metrics listed in `self.metrics`.</span>

<span class="s2">            metric_results = super(MyModel, self).compute_metrics(</span>

<span class="s2">                x, y, y_pred, sample_weight)</span>

<span class="s2">            # Note that `self.custom_metric` is not listed in `self.metrics`.</span>

<span class="s2">            self.custom_metric.update_state(x, y, y_pred, sample_weight)</span>

<span class="s2">            metric_results[&#39;custom_metric_name&#39;] = self.custom_metric.result()</span>

<span class="s2">            return metric_results</span>

<span class="s2">        ```</span>

<span class="s2">        Args:</span>

<span class="s2">          x: Input data.</span>

<span class="s2">          y: Target data.</span>

<span class="s2">          y_pred: Predictions returned by the model (output of `model.call(x)`)</span>

<span class="s2">          sample_weight: Sample weights for weighting the loss function.</span>

<span class="s2">        Returns:</span>

<span class="s2">          A `dict` containing values that will be passed to</span>

<span class="s2">          `tf.keras.callbacks.CallbackList.on_train_batch_end()`. Typically, the</span>

<span class="s2">          values of the metrics listed in `self.metrics` are returned. Example:</span>

<span class="s2">          `{&#39;loss&#39;: 0.2, &#39;accuracy&#39;: 0.7}`.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">del</span><span class="w"> </span><span class="n">x</span><span class="w">  </span><span class="c1"># The default implementation does not use `x`.</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">compiled_metrics</span><span class="p">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">get_metrics_result</span><span class="p">()</span>
</code></pre></div>

</details>
<h4 id="compute_output_shape">compute_output_shape</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_shape</span>
<span class="p">)</span>
</code></pre></div>

<p>Computes the output shape of the layer.</p>
<p>This method will cause the layer's state to be built, if that has not
happened before. This requires that the layer will later be used with
inputs that match the input shape provided here.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>input_shape</td>
<td>None</td>
<td>Shape tuple (tuple of integers) or <code>tf.TensorShape</code>,<br>or structure of shape tuples / <code>tf.TensorShape</code> instances<br>(one per output tensor of the layer).<br>Shape tuples can include None for free dimensions,<br>instead of an integer.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A <code>tf.TensorShape</code> instance<br>or structure of <code>tf.TensorShape</code> instances.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code>    <span class="n">def</span> <span class="n">compute_output_shape</span>(<span class="nb">self</span>, <span class="n">input_shape</span>):

        <span class="s">&quot;&quot;&quot;Computes the output shape of the layer.</span>

<span class="s">        This method will cause the layer&#39;s state to be built, if that has not</span>

<span class="s">        happened before. This requires that the layer will later be used with</span>

<span class="s">        inputs that match the input shape provided here.</span>

<span class="s">        Args:</span>

<span class="s">            input_shape: Shape tuple (tuple of integers) or `tf.TensorShape`,</span>

<span class="s">                or structure of shape tuples / `tf.TensorShape` instances</span>

<span class="s">                (one per output tensor of the layer).</span>

<span class="s">                Shape tuples can include None for free dimensions,</span>

<span class="s">                instead of an integer.</span>

<span class="s">        Returns:</span>

<span class="s">            A `tf.TensorShape` instance</span>

<span class="s">            or structure of `tf.TensorShape` instances.</span>

<span class="s">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">tf</span>.<span class="n">executing_eagerly</span>():

            <span class="c1"># In this case we build the model first in order to do shape</span>

            <span class="c1"># inference.  This is acceptable because the framework only calls</span>

            <span class="c1"># `compute_output_shape` on shape values that the layer would later</span>

            <span class="c1"># be built for. It would however cause issues in case a user</span>

            <span class="c1"># attempts to use `compute_output_shape` manually with shapes that</span>

            <span class="c1"># are incompatible with the shape the Layer will be called on (these</span>

            <span class="c1"># users will have to implement `compute_output_shape` themselves).</span>

            <span class="nb">self</span>.<span class="n">_maybe_build</span>(<span class="n">input_shape</span>)

            <span class="n">graph_name</span> = <span class="n">str</span>(<span class="nb">self</span>.<span class="nb">name</span>) + <span class="s">&quot;_scratch_graph&quot;</span>

            <span class="k">with</span> <span class="n">tf</span>.<span class="n">__internal__</span>.<span class="n">FuncGraph</span>(<span class="n">graph_name</span>).<span class="n">as_default</span>():

                <span class="n">input_shape</span> = <span class="n">tf_utils</span>.<span class="n">convert_shapes</span>(

                    <span class="n">input_shape</span>, <span class="n">to_tuples</span>=<span class="nb">False</span>

                )

                <span class="n">def</span> <span class="n">_make_placeholder_like</span>(<span class="nb">shape</span>):

                    <span class="n">ph</span> = <span class="n">backend</span>.<span class="nb">placeholder</span>(<span class="nb">shape</span>=<span class="nb">shape</span>, <span class="n">dtype</span>=<span class="nb">self</span>.<span class="n">dtype</span>)

                    <span class="n">ph</span>.<span class="n">_keras_mask</span> = <span class="n">None</span>

                    <span class="k">return</span> <span class="n">ph</span>

                <span class="n">inputs</span> = <span class="n">tf</span>.<span class="n">nest</span>.<span class="n">map_structure</span>(

                    <span class="n">_make_placeholder_like</span>, <span class="n">input_shape</span>

                )

                <span class="n">try:</span>

                    <span class="n">outputs</span> = <span class="nb">self</span>(<span class="n">inputs</span>, <span class="n">training</span>=<span class="nb">False</span>)

                <span class="n">except</span> <span class="n">TypeError</span> <span class="n">as</span> <span class="n">e:</span>

                    <span class="n">raise</span> <span class="n">NotImplementedError</span>(

                        <span class="s">&quot;We could not automatically infer the static shape of &quot;</span>

                        <span class="s">&quot;the layer&#39;s output. Please implement the &quot;</span>

                        <span class="s">&quot;`compute_output_shape` method on your layer (%s).&quot;</span>

                        % <span class="nb">self</span>.<span class="n">__class__</span>.<span class="n">__name__</span>

                    ) <span class="nb">from</span> <span class="nb">e</span>

            <span class="k">return</span> <span class="n">tf</span>.<span class="n">nest</span>.<span class="n">map_structure</span>(<span class="n">lambda</span> <span class="n">t:</span> <span class="nb">t</span>.<span class="nb">shape</span>, <span class="n">outputs</span>)

        <span class="n">raise</span> <span class="n">NotImplementedError</span>(

            <span class="s">&quot;Please run in eager mode or implement the `compute_output_shape` &quot;</span>

            <span class="s">&quot;method on your layer (%s).&quot;</span> % <span class="nb">self</span>.<span class="n">__class__</span>.<span class="n">__name__</span>

        )
</code></pre></div>

</details>
<h4 id="compute_output_signature">compute_output_signature</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_output_signature</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_signature</span>
<span class="p">)</span>
</code></pre></div>

<p>Compute the output tensor signature of the layer based on the inputs.</p>
<p>Unlike a TensorShape object, a TensorSpec object contains both shape
and dtype information for a tensor. This method allows layers to provide
output dtype information if it is different from the input dtype.
For any layer that doesn't implement this function,
the framework will fall back to use <code>compute_output_shape</code>, and will
assume that the output dtype matches the input dtype.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>input_signature</td>
<td>None</td>
<td>Single TensorSpec or nested structure of TensorSpec<br>objects, describing a candidate input for the layer.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Single TensorSpec or nested structure of TensorSpec objects,<br>describing how the layer would transform the provided input.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>TypeError</td>
<td>If input_signature contains a non-TensorSpec object.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@doc_controls.for_subclass_implementers</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">compute_output_signature</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">input_signature</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Compute the output tensor signature of the layer based on the inputs.</span>

<span class="s2">        Unlike a TensorShape object, a TensorSpec object contains both shape</span>

<span class="s2">        and dtype information for a tensor. This method allows layers to provide</span>

<span class="s2">        output dtype information if it is different from the input dtype.</span>

<span class="s2">        For any layer that doesn&#39;t implement this function,</span>

<span class="s2">        the framework will fall back to use `compute_output_shape`, and will</span>

<span class="s2">        assume that the output dtype matches the input dtype.</span>

<span class="s2">        Args:</span>

<span class="s2">          input_signature: Single TensorSpec or nested structure of TensorSpec</span>

<span class="s2">            objects, describing a candidate input for the layer.</span>

<span class="s2">        Returns:</span>

<span class="s2">          Single TensorSpec or nested structure of TensorSpec objects,</span>

<span class="s2">            describing how the layer would transform the provided input.</span>

<span class="s2">        Raises:</span>

<span class="s2">          TypeError: If input_signature contains a non-TensorSpec object.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">def</span><span class="w"> </span><span class="n">check_type_return_shape</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">TensorSpec</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">TypeError</span><span class="p">(</span>

<span class="w">                    </span><span class="s2">&quot;Only TensorSpec signature types are supported. &quot;</span>

<span class="w">                    </span><span class="n">f</span><span class="s2">&quot;Received: {s}.&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">s</span><span class="p">.</span><span class="n">shape</span>

<span class="w">        </span><span class="n">input_shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span>

<span class="w">            </span><span class="n">check_type_return_shape</span><span class="p">,</span><span class="w"> </span><span class="n">input_signature</span>

<span class="w">        </span><span class="p">)</span>

<span class="w">        </span><span class="n">output_shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">compute_output_shape</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>

<span class="w">        </span><span class="n">dtype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_compute_dtype</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">dtype</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="o">:</span>

<span class="w">            </span><span class="n">input_dtypes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">[</span><span class="n">s</span><span class="p">.</span><span class="n">dtype</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">input_signature</span><span class="p">)</span><span class="err">]</span>

<span class="w">            </span><span class="c1"># Default behavior when self.dtype is None, is to use the first</span>

<span class="w">            </span><span class="c1"># input&#39;s dtype.</span>

<span class="w">            </span><span class="n">dtype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input_dtypes</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span>

<span class="w">            </span><span class="n">lambda</span><span class="w"> </span><span class="n">s</span><span class="o">:</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">TensorSpec</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="n">shape</span><span class="o">=</span><span class="n">s</span><span class="p">),</span><span class="w"> </span><span class="n">output_shape</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="count_params">count_params</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">count_params</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Count the total number of scalars composing the weights.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>An integer count.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>if the layer isn't yet built<br>(in which case its weights aren't yet defined).</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">count_params</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Count the total number of scalars composing the weights.</span>

<span class="s2">        Returns:</span>

<span class="s2">            An integer count.</span>

<span class="s2">        Raises:</span>

<span class="s2">            ValueError: if the layer isn&#39;t yet built</span>

<span class="s2">              (in which case its weights aren&#39;t yet defined).</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">built</span><span class="o">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;_is_graph_network&quot;</span><span class="p">,</span><span class="w"> </span><span class="no">False</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="k">with</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">maybe_init_scope</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

<span class="w">                    </span><span class="n">self</span><span class="p">.</span><span class="n">_maybe_build</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">inputs</span><span class="p">)</span>

<span class="w">            </span><span class="k">else</span><span class="o">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                    </span><span class="s2">&quot;You tried to call `count_params` &quot;</span>

<span class="w">                    </span><span class="n">f</span><span class="s2">&quot;on layer {self.name}&quot;</span>

<span class="w">                    </span><span class="s2">&quot;, but the layer isn&#39;t built. &quot;</span>

<span class="w">                    </span><span class="s2">&quot;You can build it manually via: &quot;</span>

<span class="w">                    </span><span class="n">f</span><span class="s2">&quot;`{self.name}.build(batch_input_shape)`.&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">layer_utils</span><span class="p">.</span><span class="n">count_params</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">weights</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="evaluate">evaluate</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns the loss value &amp; metrics values for the model in test mode.</p>
<p>Computation is done in batches (see the <code>batch_size</code> arg.)</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input data. It could be:<br>- A Numpy array (or array-like), or a list of arrays<br>  (in case the model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors<br>  (in case the model has multiple inputs).<br>- A dict mapping input names to the corresponding array/tensors,<br>  if the model has named inputs.<br>- A <code>tf.data</code> dataset. Should return a tuple<br>  of either <code>(inputs, targets)</code> or<br>  <code>(inputs, targets, sample_weights)</code>.<br>- A generator or <code>keras.utils.Sequence</code> returning <code>(inputs,&lt;br&gt;  targets)</code> or <code>(inputs, targets, sample_weights)</code>.<br>A more detailed description of unpacking behavior for iterator<br>types (Dataset, generator, Sequence) is given in the <code>Unpacking&lt;br&gt;behavior for iterator-like inputs</code> section of <code>Model.fit</code>.</td>
<td>None</td>
</tr>
<tr>
<td>y</td>
<td>None</td>
<td>Target data. Like the input data <code>x</code>, it could be either Numpy<br>array(s) or TensorFlow tensor(s). It should be consistent with <code>x</code><br>(you cannot have Numpy inputs and tensor targets, or inversely).<br>If <code>x</code> is a dataset, generator or <code>keras.utils.Sequence</code> instance,<br><code>y</code> should not be specified (since targets will be obtained from<br>the iterator/dataset).</td>
<td>None</td>
</tr>
<tr>
<td>batch_size</td>
<td>None</td>
<td>Integer or <code>None</code>. Number of samples per batch of<br>computation. If unspecified, <code>batch_size</code> will default to 32. Do<br>not specify the <code>batch_size</code> if your data is in the form of a<br>dataset, generators, or <code>keras.utils.Sequence</code> instances (since<br>they generate batches).</td>
<td>None</td>
</tr>
<tr>
<td>verbose</td>
<td>None</td>
<td><code>"auto"</code>, 0, 1, or 2. Verbosity mode.<br>0 = silent, 1 = progress bar, 2 = single line.<br><code>"auto"</code> defaults to 1 for most cases, and to 2 when used with<br><code>ParameterServerStrategy</code>. Note that the progress bar is not<br>particularly useful when logged to a file, so <code>verbose=2</code> is<br>recommended when not running interactively (e.g. in a production<br>environment).</td>
<td>None</td>
</tr>
<tr>
<td>sample_weight</td>
<td>None</td>
<td>Optional Numpy array of weights for the test samples,<br>used for weighting the loss function. You can either pass a flat<br>(1D) Numpy array with the same length as the input samples<br>  (1:1 mapping between weights and samples), or in the case of<br>    temporal data, you can pass a 2D array with shape <code>(samples,&lt;br&gt;    sequence_length)</code>, to apply a different weight to every<br>    timestep of every sample. This argument is not supported when<br>    <code>x</code> is a dataset, instead pass sample weights as the third<br>    element of <code>x</code>.</td>
<td>None</td>
</tr>
<tr>
<td>steps</td>
<td>None</td>
<td>Integer or <code>None</code>. Total number of steps (batches of samples)<br>before declaring the evaluation round finished. Ignored with the<br>default value of <code>None</code>. If x is a <code>tf.data</code> dataset and <code>steps</code><br>is None, 'evaluate' will run until the dataset is exhausted. This<br>argument is not supported with array inputs.</td>
<td>None</td>
</tr>
<tr>
<td>callbacks</td>
<td>None</td>
<td>List of <code>keras.callbacks.Callback</code> instances. List of<br>callbacks to apply during evaluation. See<br><a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks">callbacks</a>.</td>
<td>None</td>
</tr>
<tr>
<td>max_queue_size</td>
<td>None</td>
<td>Integer. Used for generator or<br><code>keras.utils.Sequence</code> input only. Maximum size for the generator<br>queue. If unspecified, <code>max_queue_size</code> will default to 10.</td>
<td>None</td>
</tr>
<tr>
<td>workers</td>
<td>None</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code> input<br>only. Maximum number of processes to spin up when using<br>process-based threading. If unspecified, <code>workers</code> will default to<br>1.</td>
<td>None</td>
</tr>
<tr>
<td>use_multiprocessing</td>
<td>None</td>
<td>Boolean. Used for generator or<br><code>keras.utils.Sequence</code> input only. If <code>True</code>, use process-based<br>threading. If unspecified, <code>use_multiprocessing</code> will default to<br><code>False</code>. Note that because this implementation relies on<br>multiprocessing, you should not pass non-picklable arguments to<br>the generator as they can't be passed easily to children<br>processes.</td>
<td>None</td>
</tr>
<tr>
<td>return_dict</td>
<td>None</td>
<td>If <code>True</code>, loss and metric results are returned as a<br>dict, with each key being the name of the metric. If <code>False</code>, they<br>are returned as a list.</td>
<td>None</td>
</tr>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Unused at this time.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Scalar test loss (if the model has a single output and no metrics)<br>or list of scalars (if the model has multiple outputs<br>and/or metrics). The attribute <code>model.metrics_names</code> will give you<br>the display labels for the scalar outputs.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.evaluate</code> is wrapped in a <code>tf.function</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@traceback_utils.filter_traceback</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">evaluate</span><span class="p">(</span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">x</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">batch_size</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">verbose</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>

<span class="w">        </span><span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

<span class="w">        </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="no">False</span><span class="p">,</span>

<span class="w">        </span><span class="n">return_dict</span><span class="o">=</span><span class="no">False</span><span class="p">,</span>

<span class="w">        </span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns the loss value &amp; metrics values for the model in test mode.</span>

<span class="s2">        Computation is done in batches (see the `batch_size` arg.)</span>

<span class="s2">        Args:</span>

<span class="s2">            x: Input data. It could be:</span>

<span class="s2">              - A Numpy array (or array-like), or a list of arrays</span>

<span class="s2">                (in case the model has multiple inputs).</span>

<span class="s2">              - A TensorFlow tensor, or a list of tensors</span>

<span class="s2">                (in case the model has multiple inputs).</span>

<span class="s2">              - A dict mapping input names to the corresponding array/tensors,</span>

<span class="s2">                if the model has named inputs.</span>

<span class="s2">              - A `tf.data` dataset. Should return a tuple</span>

<span class="s2">                of either `(inputs, targets)` or</span>

<span class="s2">                `(inputs, targets, sample_weights)`.</span>

<span class="s2">              - A generator or `keras.utils.Sequence` returning `(inputs,</span>

<span class="s2">                targets)` or `(inputs, targets, sample_weights)`.</span>

<span class="s2">              A more detailed description of unpacking behavior for iterator</span>

<span class="s2">              types (Dataset, generator, Sequence) is given in the `Unpacking</span>

<span class="s2">              behavior for iterator-like inputs` section of `Model.fit`.</span>

<span class="s2">            y: Target data. Like the input data `x`, it could be either Numpy</span>

<span class="s2">              array(s) or TensorFlow tensor(s). It should be consistent with `x`</span>

<span class="s2">              (you cannot have Numpy inputs and tensor targets, or inversely).</span>

<span class="s2">              If `x` is a dataset, generator or `keras.utils.Sequence` instance,</span>

<span class="s2">              `y` should not be specified (since targets will be obtained from</span>

<span class="s2">              the iterator/dataset).</span>

<span class="s2">            batch_size: Integer or `None`. Number of samples per batch of</span>

<span class="s2">              computation. If unspecified, `batch_size` will default to 32. Do</span>

<span class="s2">              not specify the `batch_size` if your data is in the form of a</span>

<span class="s2">              dataset, generators, or `keras.utils.Sequence` instances (since</span>

<span class="s2">              they generate batches).</span>

<span class="s2">            verbose: `&quot;</span><span class="n">auto</span><span class="s2">&quot;`, 0, 1, or 2. Verbosity mode.</span>

<span class="s2">                0 = silent, 1 = progress bar, 2 = single line.</span>

<span class="s2">                `&quot;</span><span class="n">auto</span><span class="s2">&quot;` defaults to 1 for most cases, and to 2 when used with</span>

<span class="s2">                `ParameterServerStrategy`. Note that the progress bar is not</span>

<span class="s2">                particularly useful when logged to a file, so `verbose=2` is</span>

<span class="s2">                recommended when not running interactively (e.g. in a production</span>

<span class="s2">                environment).</span>

<span class="s2">            sample_weight: Optional Numpy array of weights for the test samples,</span>

<span class="s2">              used for weighting the loss function. You can either pass a flat</span>

<span class="s2">              (1D) Numpy array with the same length as the input samples</span>

<span class="s2">                (1:1 mapping between weights and samples), or in the case of</span>

<span class="s2">                  temporal data, you can pass a 2D array with shape `(samples,</span>

<span class="s2">                  sequence_length)`, to apply a different weight to every</span>

<span class="s2">                  timestep of every sample. This argument is not supported when</span>

<span class="s2">                  `x` is a dataset, instead pass sample weights as the third</span>

<span class="s2">                  element of `x`.</span>

<span class="s2">            steps: Integer or `None`. Total number of steps (batches of samples)</span>

<span class="s2">              before declaring the evaluation round finished. Ignored with the</span>

<span class="s2">              default value of `None`. If x is a `tf.data` dataset and `steps`</span>

<span class="s2">              is None, &#39;evaluate&#39; will run until the dataset is exhausted. This</span>

<span class="s2">              argument is not supported with array inputs.</span>

<span class="s2">            callbacks: List of `keras.callbacks.Callback` instances. List of</span>

<span class="s2">              callbacks to apply during evaluation. See</span>

<span class="s2">              [callbacks](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks).</span>

<span class="s2">            max_queue_size: Integer. Used for generator or</span>

<span class="s2">              `keras.utils.Sequence` input only. Maximum size for the generator</span>

<span class="s2">              queue. If unspecified, `max_queue_size` will default to 10.</span>

<span class="s2">            workers: Integer. Used for generator or `keras.utils.Sequence` input</span>

<span class="s2">              only. Maximum number of processes to spin up when using</span>

<span class="s2">              process-based threading. If unspecified, `workers` will default to</span>

<span class="s2">              1.</span>

<span class="s2">            use_multiprocessing: Boolean. Used for generator or</span>

<span class="s2">              `keras.utils.Sequence` input only. If `True`, use process-based</span>

<span class="s2">              threading. If unspecified, `use_multiprocessing` will default to</span>

<span class="s2">              `False`. Note that because this implementation relies on</span>

<span class="s2">              multiprocessing, you should not pass non-picklable arguments to</span>

<span class="s2">              the generator as they can&#39;t be passed easily to children</span>

<span class="s2">              processes.</span>

<span class="s2">            return_dict: If `True`, loss and metric results are returned as a</span>

<span class="s2">              dict, with each key being the name of the metric. If `False`, they</span>

<span class="s2">              are returned as a list.</span>

<span class="s2">            **kwargs: Unused at this time.</span>

<span class="s2">        See the discussion of `Unpacking behavior for iterator-like inputs` for</span>

<span class="s2">        `Model.fit`.</span>

<span class="s2">        Returns:</span>

<span class="s2">            Scalar test loss (if the model has a single output and no metrics)</span>

<span class="s2">            or list of scalars (if the model has multiple outputs</span>

<span class="s2">            and/or metrics). The attribute `model.metrics_names` will give you</span>

<span class="s2">            the display labels for the scalar outputs.</span>

<span class="s2">        Raises:</span>

<span class="s2">            RuntimeError: If `model.evaluate` is wrapped in a `tf.function`.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">base_layer</span><span class="p">.</span><span class="n">keras_api_gauge</span><span class="p">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s2">&quot;evaluate&quot;</span><span class="p">).</span><span class="kt">set</span><span class="p">(</span><span class="no">True</span><span class="p">)</span>

<span class="w">        </span><span class="n">version_utils</span><span class="p">.</span><span class="n">disallow_legacy_graph</span><span class="p">(</span><span class="s2">&quot;Model&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;evaluate&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s2">&quot;evaluate&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_check_sample_weight_warning</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">)</span>

<span class="w">        </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s2">&quot;evaluate&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="n">use_cached_eval_dataset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;_use_cached_eval_dataset&quot;</span><span class="p">,</span><span class="w"> </span><span class="no">False</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">kwargs</span><span class="o">:</span>

<span class="w">            </span><span class="n">raise</span><span class="w"> </span><span class="n">TypeError</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Invalid keyword arguments: {list(kwargs.keys())}&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">_should_use_with_coordinator</span><span class="o">:</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span>

<span class="w">                </span><span class="n">tf</span><span class="p">.</span><span class="n">distribute</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">coordinator</span><span class="p">.</span><span class="n">ClusterCoordinator</span><span class="p">(</span>

<span class="w">                    </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="n">verbose</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">_get_verbosity</span><span class="p">(</span><span class="n">verbose</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">)</span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span>

<span class="w">            </span><span class="c1"># Use cached evaluation data only when it&#39;s called in `Model.fit`</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span>

<span class="w">                </span><span class="n">use_cached_eval_dataset</span>

<span class="w">                </span><span class="k">and</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;_eval_data_handler&quot;</span><span class="p">,</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span>

<span class="w">            </span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_eval_data_handler</span>

<span class="w">            </span><span class="k">else</span><span class="o">:</span>

<span class="w">                </span><span class="c1"># Creates a `tf.data.Dataset` and handles batch and epoch</span>

<span class="w">                </span><span class="c1"># iteration.</span>

<span class="w">                </span><span class="n">data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">get_data_handler</span><span class="p">(</span>

<span class="w">                    </span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>

<span class="w">                    </span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>

<span class="w">                    </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>

<span class="w">                    </span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>

<span class="w">                    </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>

<span class="w">                    </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

<span class="w">                    </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">                    </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

<span class="w">                    </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

<span class="w">                    </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

<span class="w">                    </span><span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span>

<span class="w">                    </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">,</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span><span class="w"> </span><span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">callbacks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">(</span>

<span class="w">                    </span><span class="n">callbacks</span><span class="p">,</span>

<span class="w">                    </span><span class="n">add_history</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

<span class="w">                    </span><span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>

<span class="w">                    </span><span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span>

<span class="w">                    </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>

<span class="w">                    </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">                    </span><span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="p">.</span><span class="n">inferred_steps</span><span class="p">,</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">{}</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">make_test_function</span><span class="p">()</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">_test_counter</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="w">            </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_begin</span><span class="p">()</span>

<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">enumerate_epochs</span><span class="p">()</span><span class="o">:</span><span class="w">  </span><span class="c1"># Single epoch.</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span>

<span class="w">                </span><span class="k">with</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">catch_stop_iteration</span><span class="p">()</span><span class="o">:</span>

<span class="w">                    </span><span class="k">for</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">steps</span><span class="p">()</span><span class="o">:</span>

<span class="w">                        </span><span class="k">with</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">profiler</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">Trace</span><span class="p">(</span>

<span class="w">                            </span><span class="s2">&quot;test&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">step_num</span><span class="o">=</span><span class="n">step</span><span class="p">,</span><span class="w"> </span><span class="n">_r</span><span class="o">=</span><span class="mi">1</span>

<span class="w">                        </span><span class="p">)</span><span class="o">:</span>

<span class="w">                            </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>

<span class="w">                            </span><span class="n">tmp_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

<span class="w">                            </span><span class="k">if</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">should_sync</span><span class="o">:</span>

<span class="w">                                </span><span class="k">context</span><span class="p">.</span><span class="n">async_wait</span><span class="p">()</span>

<span class="w">                            </span><span class="c1"># No error, now safe to assign to logs.</span>

<span class="w">                            </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tmp_logs</span>

<span class="w">                            </span><span class="n">end_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">step_increment</span>

<span class="w">                            </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_batch_end</span><span class="p">(</span><span class="n">end_step</span><span class="p">,</span><span class="w"> </span><span class="k">logs</span><span class="p">)</span>

<span class="w">            </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span>

<span class="w">            </span><span class="c1"># Override with model metrics instead of last step logs</span>

<span class="w">            </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_validate_and_get_metrics_result</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span>

<span class="w">            </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_end</span><span class="p">(</span><span class="k">logs</span><span class="o">=</span><span class="k">logs</span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">return_dict</span><span class="o">:</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="k">logs</span>

<span class="w">            </span><span class="k">else</span><span class="o">:</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">flatten_metrics_in_order</span><span class="p">(</span><span class="k">logs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="evaluate_generator">evaluate_generator</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate_generator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>

<p>Evaluates the model on a data generator.</p>
<p>DEPRECATED:
  <code>Model.evaluate</code> now supports generators, so there is no longer any
  need to use this endpoint.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_generate_docs</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">evaluate_generator</span><span class="p">(</span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">generator</span><span class="p">,</span>

<span class="w">        </span><span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

<span class="w">        </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="k">False</span><span class="p">,</span>

<span class="w">        </span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Evaluates the model on a data generator.</span>

<span class="ss">        DEPRECATED:</span>

<span class="ss">          `Model.evaluate` now supports generators, so there is no longer any</span>

<span class="ss">          need to use this endpoint.</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span>

<span class="w">            </span><span class="ss">&quot;`Model.evaluate_generator` is deprecated and &quot;</span>

<span class="w">            </span><span class="ss">&quot;will be removed in a future version. &quot;</span>

<span class="w">            </span><span class="ss">&quot;Please use `Model.evaluate`, which supports generators.&quot;</span><span class="p">,</span>

<span class="w">            </span><span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>

<span class="w">        </span><span class="p">)</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="ss">&quot;evaluate_generator&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span>

<span class="w">            </span><span class="n">generator</span><span class="p">,</span>

<span class="w">            </span><span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>

<span class="w">            </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

<span class="w">            </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

<span class="w">            </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

<span class="w">            </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>

<span class="w">            </span><span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="finalize_state">finalize_state</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">finalize_state</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Finalizes the layers state after updating layer weights.</p>
<p>This function can be subclassed in a layer and will be called after
updating a layer weights. It can be overridden to finalize any
additional layer state after a weight update.</p>
<p>This function will be called after weights of a layer have been restored
from a loaded model.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="err">@</span><span class="n">doc_controls</span><span class="o">.</span><span class="n">do_not_generate_docs</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">finalize_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;Finalizes the layers state after updating layer weights.</span>

<span class="sd">        This function can be subclassed in a layer and will be called after</span>

<span class="sd">        updating a layer weights. It can be overridden to finalize any</span>

<span class="sd">        additional layer state after a weight update.</span>

<span class="sd">        This function will be called after weights of a layer have been restored</span>

<span class="sd">        from a loaded model.</span>

<span class="sd">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">pass</span>
</code></pre></div>

</details>
<h4 id="fit">fit</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Trains the model for a fixed number of epochs (iterations on a dataset).</p>
<p>Args:
    x: Input data. It could be:
      - A Numpy array (or array-like), or a list of arrays
        (in case the model has multiple inputs).
      - A TensorFlow tensor, or a list of tensors
        (in case the model has multiple inputs).
      - A dict mapping input names to the corresponding array/tensors,
        if the model has named inputs.
      - A <code>tf.data</code> dataset. Should return a tuple
        of either <code>(inputs, targets)</code> or
        <code>(inputs, targets, sample_weights)</code>.
      - A generator or <code>keras.utils.Sequence</code> returning <code>(inputs,
        targets)</code> or <code>(inputs, targets, sample_weights)</code>.
      - A <code>tf.keras.utils.experimental.DatasetCreator</code>, which wraps a
        callable that takes a single argument of type
        <code>tf.distribute.InputContext</code>, and returns a <code>tf.data.Dataset</code>.
        <code>DatasetCreator</code> should be used when users prefer to specify the
        per-replica batching and sharding logic for the <code>Dataset</code>.
        See <code>tf.keras.utils.experimental.DatasetCreator</code> doc for more
        information.
      A more detailed description of unpacking behavior for iterator
      types (Dataset, generator, Sequence) is given below. If these
      include <code>sample_weights</code> as a third component, note that sample
      weighting applies to the <code>weighted_metrics</code> argument but not the
      <code>metrics</code> argument in <code>compile()</code>. If using
      <code>tf.distribute.experimental.ParameterServerStrategy</code>, only
      <code>DatasetCreator</code> type is supported for <code>x</code>.
    y: Target data. Like the input data <code>x</code>,
      it could be either Numpy array(s) or TensorFlow tensor(s).
      It should be consistent with <code>x</code> (you cannot have Numpy inputs and
      tensor targets, or inversely). If <code>x</code> is a dataset, generator,
      or <code>keras.utils.Sequence</code> instance, <code>y</code> should
      not be specified (since targets will be obtained from <code>x</code>).
    batch_size: Integer or <code>None</code>.
        Number of samples per gradient update.
        If unspecified, <code>batch_size</code> will default to 32.
        Do not specify the <code>batch_size</code> if your data is in the
        form of datasets, generators, or <code>keras.utils.Sequence</code>
        instances (since they generate batches).
    epochs: Integer. Number of epochs to train the model.
        An epoch is an iteration over the entire <code>x</code> and <code>y</code>
        data provided
        (unless the <code>steps_per_epoch</code> flag is set to
        something other than None).
        Note that in conjunction with <code>initial_epoch</code>,
        <code>epochs</code> is to be understood as "final epoch".
        The model is not trained for a number of iterations
        given by <code>epochs</code>, but merely until the epoch
        of index <code>epochs</code> is reached.
    verbose: 'auto', 0, 1, or 2. Verbosity mode.
        0 = silent, 1 = progress bar, 2 = one line per epoch.
        'auto' defaults to 1 for most cases, but 2 when used with
        <code>ParameterServerStrategy</code>. Note that the progress bar is not
        particularly useful when logged to a file, so verbose=2 is
        recommended when not running interactively (eg, in a production
        environment).
    callbacks: List of <code>keras.callbacks.Callback</code> instances.
        List of callbacks to apply during training.
        See <code>tf.keras.callbacks</code>. Note
        <code>tf.keras.callbacks.ProgbarLogger</code> and
        <code>tf.keras.callbacks.History</code> callbacks are created automatically
        and need not be passed into <code>model.fit</code>.
        <code>tf.keras.callbacks.ProgbarLogger</code> is created or not based on
        <code>verbose</code> argument to <code>model.fit</code>.
        Callbacks with batch-level calls are currently unsupported with
        <code>tf.distribute.experimental.ParameterServerStrategy</code>, and users
        are advised to implement epoch-level calls instead with an
        appropriate <code>steps_per_epoch</code> value.
    validation_split: Float between 0 and 1.
        Fraction of the training data to be used as validation data.
        The model will set apart this fraction of the training data,
        will not train on it, and will evaluate
        the loss and any model metrics
        on this data at the end of each epoch.
        The validation data is selected from the last samples
        in the <code>x</code> and <code>y</code> data provided, before shuffling. This
        argument is not supported when <code>x</code> is a dataset, generator or
        <code>keras.utils.Sequence</code> instance.
        If both <code>validation_data</code> and <code>validation_split</code> are provided,
        <code>validation_data</code> will override <code>validation_split</code>.
        <code>validation_split</code> is not yet supported with
        <code>tf.distribute.experimental.ParameterServerStrategy</code>.
    validation_data: Data on which to evaluate
        the loss and any model metrics at the end of each epoch.
        The model will not be trained on this data. Thus, note the fact
        that the validation loss of data provided using
        <code>validation_split</code> or <code>validation_data</code> is not affected by
        regularization layers like noise and dropout.
        <code>validation_data</code> will override <code>validation_split</code>.
        <code>validation_data</code> could be:
          - A tuple <code>(x_val, y_val)</code> of Numpy arrays or tensors.
          - A tuple <code>(x_val, y_val, val_sample_weights)</code> of NumPy
            arrays.
          - A <code>tf.data.Dataset</code>.
          - A Python generator or <code>keras.utils.Sequence</code> returning
          <code>(inputs, targets)</code> or <code>(inputs, targets, sample_weights)</code>.
        <code>validation_data</code> is not yet supported with
        <code>tf.distribute.experimental.ParameterServerStrategy</code>.
    shuffle: Boolean (whether to shuffle the training data
        before each epoch) or str (for 'batch'). This argument is
        ignored when <code>x</code> is a generator or an object of tf.data.Dataset.
        'batch' is a special option for dealing
        with the limitations of HDF5 data; it shuffles in batch-sized
        chunks. Has no effect when <code>steps_per_epoch</code> is not <code>None</code>.
    class_weight: Optional dictionary mapping class indices (integers)
        to a weight (float) value, used for weighting the loss function
        (during training only).
        This can be useful to tell the model to
        "pay more attention" to samples from
        an under-represented class.
    sample_weight: Optional Numpy array of weights for
        the training samples, used for weighting the loss function
        (during training only). You can either pass a flat (1D)
        Numpy array with the same length as the input samples
        (1:1 mapping between weights and samples),
        or in the case of temporal data,
        you can pass a 2D array with shape
        <code>(samples, sequence_length)</code>,
        to apply a different weight to every timestep of every sample.
        This argument is not supported when <code>x</code> is a dataset, generator,
        or <code>keras.utils.Sequence</code> instance, instead provide the
        sample_weights as the third element of <code>x</code>.
        Note that sample weighting does not apply to metrics specified
        via the <code>metrics</code> argument in <code>compile()</code>. To apply sample
        weighting to your metrics, you can specify them via the
        <code>weighted_metrics</code> in <code>compile()</code> instead.
    initial_epoch: Integer.
        Epoch at which to start training
        (useful for resuming a previous training run).
    steps_per_epoch: Integer or <code>None</code>.
        Total number of steps (batches of samples)
        before declaring one epoch finished and starting the
        next epoch. When training with input tensors such as
        TensorFlow data tensors, the default <code>None</code> is equal to
        the number of samples in your dataset divided by
        the batch size, or 1 if that cannot be determined. If x is a
        <code>tf.data</code> dataset, and 'steps_per_epoch'
        is None, the epoch will run until the input dataset is
        exhausted.  When passing an infinitely repeating dataset, you
        must specify the <code>steps_per_epoch</code> argument. If
        <code>steps_per_epoch=-1</code> the training will run indefinitely with an
        infinitely repeating dataset.  This argument is not supported
        with array inputs.
        When using <code>tf.distribute.experimental.ParameterServerStrategy</code>:
          * <code>steps_per_epoch=None</code> is not supported.
    validation_steps: Only relevant if <code>validation_data</code> is provided and
        is a <code>tf.data</code> dataset. Total number of steps (batches of
        samples) to draw before stopping when performing validation
        at the end of every epoch. If 'validation_steps' is None,
        validation will run until the <code>validation_data</code> dataset is
        exhausted. In the case of an infinitely repeated dataset, it
        will run into an infinite loop. If 'validation_steps' is
        specified and only part of the dataset will be consumed, the
        evaluation will start from the beginning of the dataset at each
        epoch. This ensures that the same validation samples are used
        every time.
    validation_batch_size: Integer or <code>None</code>.
        Number of samples per validation batch.
        If unspecified, will default to <code>batch_size</code>.
        Do not specify the <code>validation_batch_size</code> if your data is in
        the form of datasets, generators, or <code>keras.utils.Sequence</code>
        instances (since they generate batches).
    validation_freq: Only relevant if validation data is provided.
      Integer or <code>collections.abc.Container</code> instance (e.g. list, tuple,
      etc.).  If an integer, specifies how many training epochs to run
      before a new validation run is performed, e.g. <code>validation_freq=2</code>
      runs validation every 2 epochs. If a Container, specifies the
      epochs on which to run validation, e.g.
      <code>validation_freq=[1, 2, 10]</code> runs validation at the end of the
      1st, 2nd, and 10th epochs.
    max_queue_size: Integer. Used for generator or
      <code>keras.utils.Sequence</code> input only. Maximum size for the generator
      queue.  If unspecified, <code>max_queue_size</code> will default to 10.
    workers: Integer. Used for generator or <code>keras.utils.Sequence</code> input
        only. Maximum number of processes to spin up
        when using process-based threading. If unspecified, <code>workers</code>
        will default to 1.
    use_multiprocessing: Boolean. Used for generator or
        <code>keras.utils.Sequence</code> input only. If <code>True</code>, use process-based
        threading. If unspecified, <code>use_multiprocessing</code> will default to
        <code>False</code>. Note that because this implementation relies on
        multiprocessing, you should not pass non-picklable arguments to
        the generator as they can't be passed easily to children
        processes.</p>
<p>Unpacking behavior for iterator-like inputs:
    A common pattern is to pass a tf.data.Dataset, generator, or
  tf.keras.utils.Sequence to the <code>x</code> argument of fit, which will in fact
  yield not only features (x) but optionally targets (y) and sample
  weights.  Keras requires that the output of such iterator-likes be
  unambiguous. The iterator should return a tuple of length 1, 2, or 3,
  where the optional second and third elements will be used for y and
  sample_weight respectively. Any other type provided will be wrapped in
  a length one tuple, effectively treating everything as 'x'. When
  yielding dicts, they should still adhere to the top-level tuple
  structure.
  e.g. <code>({"x0": x0, "x1": x1}, y)</code>. Keras will not attempt to separate
  features, targets, and weights from the keys of a single dict.
    A notable unsupported data type is the namedtuple. The reason is
  that it behaves like both an ordered datatype (tuple) and a mapping
  datatype (dict). So given a namedtuple of the form:
      <code>namedtuple("example_tuple", ["y", "x"])</code>
  it is ambiguous whether to reverse the order of the elements when
  interpreting the value. Even worse is a tuple of the form:
      <code>namedtuple("other_tuple", ["x", "y", "z"])</code>
  where it is unclear if the tuple was intended to be unpacked into x,
  y, and sample_weight or passed through as a single element to <code>x</code>. As
  a result the data processing code will simply raise a ValueError if it
  encounters a namedtuple. (Along with instructions to remedy the
  issue.)</p>
<p>Returns:
    A <code>History</code> object. Its <code>History.history</code> attribute is
    a record of training loss values and metrics values
    at successive epochs, as well as validation loss values
    and validation metrics values (if applicable).</p>
<p>Raises:
    RuntimeError: 1. If the model was never compiled or,
    2. If <code>model.fit</code> is  wrapped in <code>tf.function</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">ValueError</span><span class="o">:</span><span class="w"> </span><span class="n">In</span><span class="w"> </span><span class="k">case</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">mismatch</span><span class="w"> </span><span class="n">between</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">provided</span><span class="w"> </span><span class="n">input</span><span class="w"> </span><span class="n">data</span>
<span class="w">    </span><span class="n">and</span><span class="w"> </span><span class="n">what</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">expects</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">when</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">input</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">empty</span><span class="o">.</span>
</code></pre></div>

<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="err">@</span><span class="n">traceback_utils</span><span class="o">.</span><span class="n">filter_traceback</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">fit</span><span class="p">(</span>

<span class="w">        </span><span class="bp">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">x</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">y</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">batch_size</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="n">verbose</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">validation_split</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>

<span class="w">        </span><span class="n">validation_data</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">shuffle</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

<span class="w">        </span><span class="n">class_weight</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

<span class="w">        </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">validation_steps</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">validation_batch_size</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

<span class="w">        </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">False</span><span class="p">,</span>

<span class="w">    </span><span class="p">):</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;Trains the model for a fixed number of epochs (iterations on a dataset).</span>

<span class="sd">        Args:</span>

<span class="sd">            x: Input data. It could be:</span>

<span class="sd">              - A Numpy array (or array-like), or a list of arrays</span>

<span class="sd">                (in case the model has multiple inputs).</span>

<span class="sd">              - A TensorFlow tensor, or a list of tensors</span>

<span class="sd">                (in case the model has multiple inputs).</span>

<span class="sd">              - A dict mapping input names to the corresponding array/tensors,</span>

<span class="sd">                if the model has named inputs.</span>

<span class="sd">              - A `tf.data` dataset. Should return a tuple</span>

<span class="sd">                of either `(inputs, targets)` or</span>

<span class="sd">                `(inputs, targets, sample_weights)`.</span>

<span class="sd">              - A generator or `keras.utils.Sequence` returning `(inputs,</span>

<span class="sd">                targets)` or `(inputs, targets, sample_weights)`.</span>

<span class="sd">              - A `tf.keras.utils.experimental.DatasetCreator`, which wraps a</span>

<span class="sd">                callable that takes a single argument of type</span>

<span class="sd">                `tf.distribute.InputContext`, and returns a `tf.data.Dataset`.</span>

<span class="sd">                `DatasetCreator` should be used when users prefer to specify the</span>

<span class="sd">                per-replica batching and sharding logic for the `Dataset`.</span>

<span class="sd">                See `tf.keras.utils.experimental.DatasetCreator` doc for more</span>

<span class="sd">                information.</span>

<span class="sd">              A more detailed description of unpacking behavior for iterator</span>

<span class="sd">              types (Dataset, generator, Sequence) is given below. If these</span>

<span class="sd">              include `sample_weights` as a third component, note that sample</span>

<span class="sd">              weighting applies to the `weighted_metrics` argument but not the</span>

<span class="sd">              `metrics` argument in `compile()`. If using</span>

<span class="sd">              `tf.distribute.experimental.ParameterServerStrategy`, only</span>

<span class="sd">              `DatasetCreator` type is supported for `x`.</span>

<span class="sd">            y: Target data. Like the input data `x`,</span>

<span class="sd">              it could be either Numpy array(s) or TensorFlow tensor(s).</span>

<span class="sd">              It should be consistent with `x` (you cannot have Numpy inputs and</span>

<span class="sd">              tensor targets, or inversely). If `x` is a dataset, generator,</span>

<span class="sd">              or `keras.utils.Sequence` instance, `y` should</span>

<span class="sd">              not be specified (since targets will be obtained from `x`).</span>

<span class="sd">            batch_size: Integer or `None`.</span>

<span class="sd">                Number of samples per gradient update.</span>

<span class="sd">                If unspecified, `batch_size` will default to 32.</span>

<span class="sd">                Do not specify the `batch_size` if your data is in the</span>

<span class="sd">                form of datasets, generators, or `keras.utils.Sequence`</span>

<span class="sd">                instances (since they generate batches).</span>

<span class="sd">            epochs: Integer. Number of epochs to train the model.</span>

<span class="sd">                An epoch is an iteration over the entire `x` and `y`</span>

<span class="sd">                data provided</span>

<span class="sd">                (unless the `steps_per_epoch` flag is set to</span>

<span class="sd">                something other than None).</span>

<span class="sd">                Note that in conjunction with `initial_epoch`,</span>

<span class="sd">                `epochs` is to be understood as &quot;final epoch&quot;.</span>

<span class="sd">                The model is not trained for a number of iterations</span>

<span class="sd">                given by `epochs`, but merely until the epoch</span>

<span class="sd">                of index `epochs` is reached.</span>

<span class="sd">            verbose: &#39;auto&#39;, 0, 1, or 2. Verbosity mode.</span>

<span class="sd">                0 = silent, 1 = progress bar, 2 = one line per epoch.</span>

<span class="sd">                &#39;auto&#39; defaults to 1 for most cases, but 2 when used with</span>

<span class="sd">                `ParameterServerStrategy`. Note that the progress bar is not</span>

<span class="sd">                particularly useful when logged to a file, so verbose=2 is</span>

<span class="sd">                recommended when not running interactively (eg, in a production</span>

<span class="sd">                environment).</span>

<span class="sd">            callbacks: List of `keras.callbacks.Callback` instances.</span>

<span class="sd">                List of callbacks to apply during training.</span>

<span class="sd">                See `tf.keras.callbacks`. Note</span>

<span class="sd">                `tf.keras.callbacks.ProgbarLogger` and</span>

<span class="sd">                `tf.keras.callbacks.History` callbacks are created automatically</span>

<span class="sd">                and need not be passed into `model.fit`.</span>

<span class="sd">                `tf.keras.callbacks.ProgbarLogger` is created or not based on</span>

<span class="sd">                `verbose` argument to `model.fit`.</span>

<span class="sd">                Callbacks with batch-level calls are currently unsupported with</span>

<span class="sd">                `tf.distribute.experimental.ParameterServerStrategy`, and users</span>

<span class="sd">                are advised to implement epoch-level calls instead with an</span>

<span class="sd">                appropriate `steps_per_epoch` value.</span>

<span class="sd">            validation_split: Float between 0 and 1.</span>

<span class="sd">                Fraction of the training data to be used as validation data.</span>

<span class="sd">                The model will set apart this fraction of the training data,</span>

<span class="sd">                will not train on it, and will evaluate</span>

<span class="sd">                the loss and any model metrics</span>

<span class="sd">                on this data at the end of each epoch.</span>

<span class="sd">                The validation data is selected from the last samples</span>

<span class="sd">                in the `x` and `y` data provided, before shuffling. This</span>

<span class="sd">                argument is not supported when `x` is a dataset, generator or</span>

<span class="sd">                `keras.utils.Sequence` instance.</span>

<span class="sd">                If both `validation_data` and `validation_split` are provided,</span>

<span class="sd">                `validation_data` will override `validation_split`.</span>

<span class="sd">                `validation_split` is not yet supported with</span>

<span class="sd">                `tf.distribute.experimental.ParameterServerStrategy`.</span>

<span class="sd">            validation_data: Data on which to evaluate</span>

<span class="sd">                the loss and any model metrics at the end of each epoch.</span>

<span class="sd">                The model will not be trained on this data. Thus, note the fact</span>

<span class="sd">                that the validation loss of data provided using</span>

<span class="sd">                `validation_split` or `validation_data` is not affected by</span>

<span class="sd">                regularization layers like noise and dropout.</span>

<span class="sd">                `validation_data` will override `validation_split`.</span>

<span class="sd">                `validation_data` could be:</span>

<span class="sd">                  - A tuple `(x_val, y_val)` of Numpy arrays or tensors.</span>

<span class="sd">                  - A tuple `(x_val, y_val, val_sample_weights)` of NumPy</span>

<span class="sd">                    arrays.</span>

<span class="sd">                  - A `tf.data.Dataset`.</span>

<span class="sd">                  - A Python generator or `keras.utils.Sequence` returning</span>

<span class="sd">                  `(inputs, targets)` or `(inputs, targets, sample_weights)`.</span>

<span class="sd">                `validation_data` is not yet supported with</span>

<span class="sd">                `tf.distribute.experimental.ParameterServerStrategy`.</span>

<span class="sd">            shuffle: Boolean (whether to shuffle the training data</span>

<span class="sd">                before each epoch) or str (for &#39;batch&#39;). This argument is</span>

<span class="sd">                ignored when `x` is a generator or an object of tf.data.Dataset.</span>

<span class="sd">                &#39;batch&#39; is a special option for dealing</span>

<span class="sd">                with the limitations of HDF5 data; it shuffles in batch-sized</span>

<span class="sd">                chunks. Has no effect when `steps_per_epoch` is not `None`.</span>

<span class="sd">            class_weight: Optional dictionary mapping class indices (integers)</span>

<span class="sd">                to a weight (float) value, used for weighting the loss function</span>

<span class="sd">                (during training only).</span>

<span class="sd">                This can be useful to tell the model to</span>

<span class="sd">                &quot;pay more attention&quot; to samples from</span>

<span class="sd">                an under-represented class.</span>

<span class="sd">            sample_weight: Optional Numpy array of weights for</span>

<span class="sd">                the training samples, used for weighting the loss function</span>

<span class="sd">                (during training only). You can either pass a flat (1D)</span>

<span class="sd">                Numpy array with the same length as the input samples</span>

<span class="sd">                (1:1 mapping between weights and samples),</span>

<span class="sd">                or in the case of temporal data,</span>

<span class="sd">                you can pass a 2D array with shape</span>

<span class="sd">                `(samples, sequence_length)`,</span>

<span class="sd">                to apply a different weight to every timestep of every sample.</span>

<span class="sd">                This argument is not supported when `x` is a dataset, generator,</span>

<span class="sd">                or `keras.utils.Sequence` instance, instead provide the</span>

<span class="sd">                sample_weights as the third element of `x`.</span>

<span class="sd">                Note that sample weighting does not apply to metrics specified</span>

<span class="sd">                via the `metrics` argument in `compile()`. To apply sample</span>

<span class="sd">                weighting to your metrics, you can specify them via the</span>

<span class="sd">                `weighted_metrics` in `compile()` instead.</span>

<span class="sd">            initial_epoch: Integer.</span>

<span class="sd">                Epoch at which to start training</span>

<span class="sd">                (useful for resuming a previous training run).</span>

<span class="sd">            steps_per_epoch: Integer or `None`.</span>

<span class="sd">                Total number of steps (batches of samples)</span>

<span class="sd">                before declaring one epoch finished and starting the</span>

<span class="sd">                next epoch. When training with input tensors such as</span>

<span class="sd">                TensorFlow data tensors, the default `None` is equal to</span>

<span class="sd">                the number of samples in your dataset divided by</span>

<span class="sd">                the batch size, or 1 if that cannot be determined. If x is a</span>

<span class="sd">                `tf.data` dataset, and &#39;steps_per_epoch&#39;</span>

<span class="sd">                is None, the epoch will run until the input dataset is</span>

<span class="sd">                exhausted.  When passing an infinitely repeating dataset, you</span>

<span class="sd">                must specify the `steps_per_epoch` argument. If</span>

<span class="sd">                `steps_per_epoch=-1` the training will run indefinitely with an</span>

<span class="sd">                infinitely repeating dataset.  This argument is not supported</span>

<span class="sd">                with array inputs.</span>

<span class="sd">                When using `tf.distribute.experimental.ParameterServerStrategy`:</span>

<span class="sd">                  * `steps_per_epoch=None` is not supported.</span>

<span class="sd">            validation_steps: Only relevant if `validation_data` is provided and</span>

<span class="sd">                is a `tf.data` dataset. Total number of steps (batches of</span>

<span class="sd">                samples) to draw before stopping when performing validation</span>

<span class="sd">                at the end of every epoch. If &#39;validation_steps&#39; is None,</span>

<span class="sd">                validation will run until the `validation_data` dataset is</span>

<span class="sd">                exhausted. In the case of an infinitely repeated dataset, it</span>

<span class="sd">                will run into an infinite loop. If &#39;validation_steps&#39; is</span>

<span class="sd">                specified and only part of the dataset will be consumed, the</span>

<span class="sd">                evaluation will start from the beginning of the dataset at each</span>

<span class="sd">                epoch. This ensures that the same validation samples are used</span>

<span class="sd">                every time.</span>

<span class="sd">            validation_batch_size: Integer or `None`.</span>

<span class="sd">                Number of samples per validation batch.</span>

<span class="sd">                If unspecified, will default to `batch_size`.</span>

<span class="sd">                Do not specify the `validation_batch_size` if your data is in</span>

<span class="sd">                the form of datasets, generators, or `keras.utils.Sequence`</span>

<span class="sd">                instances (since they generate batches).</span>

<span class="sd">            validation_freq: Only relevant if validation data is provided.</span>

<span class="sd">              Integer or `collections.abc.Container` instance (e.g. list, tuple,</span>

<span class="sd">              etc.).  If an integer, specifies how many training epochs to run</span>

<span class="sd">              before a new validation run is performed, e.g. `validation_freq=2`</span>

<span class="sd">              runs validation every 2 epochs. If a Container, specifies the</span>

<span class="sd">              epochs on which to run validation, e.g.</span>

<span class="sd">              `validation_freq=[1, 2, 10]` runs validation at the end of the</span>

<span class="sd">              1st, 2nd, and 10th epochs.</span>

<span class="sd">            max_queue_size: Integer. Used for generator or</span>

<span class="sd">              `keras.utils.Sequence` input only. Maximum size for the generator</span>

<span class="sd">              queue.  If unspecified, `max_queue_size` will default to 10.</span>

<span class="sd">            workers: Integer. Used for generator or `keras.utils.Sequence` input</span>

<span class="sd">                only. Maximum number of processes to spin up</span>

<span class="sd">                when using process-based threading. If unspecified, `workers`</span>

<span class="sd">                will default to 1.</span>

<span class="sd">            use_multiprocessing: Boolean. Used for generator or</span>

<span class="sd">                `keras.utils.Sequence` input only. If `True`, use process-based</span>

<span class="sd">                threading. If unspecified, `use_multiprocessing` will default to</span>

<span class="sd">                `False`. Note that because this implementation relies on</span>

<span class="sd">                multiprocessing, you should not pass non-picklable arguments to</span>

<span class="sd">                the generator as they can&#39;t be passed easily to children</span>

<span class="sd">                processes.</span>

<span class="sd">        Unpacking behavior for iterator-like inputs:</span>

<span class="sd">            A common pattern is to pass a tf.data.Dataset, generator, or</span>

<span class="sd">          tf.keras.utils.Sequence to the `x` argument of fit, which will in fact</span>

<span class="sd">          yield not only features (x) but optionally targets (y) and sample</span>

<span class="sd">          weights.  Keras requires that the output of such iterator-likes be</span>

<span class="sd">          unambiguous. The iterator should return a tuple of length 1, 2, or 3,</span>

<span class="sd">          where the optional second and third elements will be used for y and</span>

<span class="sd">          sample_weight respectively. Any other type provided will be wrapped in</span>

<span class="sd">          a length one tuple, effectively treating everything as &#39;x&#39;. When</span>

<span class="sd">          yielding dicts, they should still adhere to the top-level tuple</span>

<span class="sd">          structure.</span>

<span class="sd">          e.g. `({&quot;x0&quot;: x0, &quot;x1&quot;: x1}, y)`. Keras will not attempt to separate</span>

<span class="sd">          features, targets, and weights from the keys of a single dict.</span>

<span class="sd">            A notable unsupported data type is the namedtuple. The reason is</span>

<span class="sd">          that it behaves like both an ordered datatype (tuple) and a mapping</span>

<span class="sd">          datatype (dict). So given a namedtuple of the form:</span>

<span class="sd">              `namedtuple(&quot;example_tuple&quot;, [&quot;y&quot;, &quot;x&quot;])`</span>

<span class="sd">          it is ambiguous whether to reverse the order of the elements when</span>

<span class="sd">          interpreting the value. Even worse is a tuple of the form:</span>

<span class="sd">              `namedtuple(&quot;other_tuple&quot;, [&quot;x&quot;, &quot;y&quot;, &quot;z&quot;])`</span>

<span class="sd">          where it is unclear if the tuple was intended to be unpacked into x,</span>

<span class="sd">          y, and sample_weight or passed through as a single element to `x`. As</span>

<span class="sd">          a result the data processing code will simply raise a ValueError if it</span>

<span class="sd">          encounters a namedtuple. (Along with instructions to remedy the</span>

<span class="sd">          issue.)</span>

<span class="sd">        Returns:</span>

<span class="sd">            A `History` object. Its `History.history` attribute is</span>

<span class="sd">            a record of training loss values and metrics values</span>

<span class="sd">            at successive epochs, as well as validation loss values</span>

<span class="sd">            and validation metrics values (if applicable).</span>

<span class="sd">        Raises:</span>

<span class="sd">            RuntimeError: 1. If the model was never compiled or,</span>

<span class="sd">            2. If `model.fit` is  wrapped in `tf.function`.</span>

<span class="sd">            ValueError: In case of mismatch between the provided input data</span>

<span class="sd">                and what the model expects or when the input data is empty.</span>

<span class="sd">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">base_layer</span><span class="o">.</span><span class="n">keras_api_gauge</span><span class="o">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s2">&quot;fit&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">True</span><span class="p">)</span>

<span class="w">        </span><span class="c1"># Legacy graph support is contained in `training_v1.Model`.</span>

<span class="w">        </span><span class="n">version_utils</span><span class="o">.</span><span class="n">disallow_legacy_graph</span><span class="p">(</span><span class="s2">&quot;Model&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;fit&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s2">&quot;fit&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s2">&quot;fit&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="n">verbose</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">_get_verbosity</span><span class="p">(</span><span class="n">verbose</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">validation_split</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">validation_data</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">            </span><span class="c1"># Create the validation data using the training data. Only supported</span>

<span class="w">            </span><span class="c1"># for `Tensor` and `NumPy` input.</span>

<span class="w">            </span><span class="p">(</span>

<span class="w">                </span><span class="n">x</span><span class="p">,</span>

<span class="w">                </span><span class="n">y</span><span class="p">,</span>

<span class="w">                </span><span class="n">sample_weight</span><span class="p">,</span>

<span class="w">            </span><span class="p">),</span><span class="w"> </span><span class="n">validation_data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">train_validation_split</span><span class="p">(</span>

<span class="w">                </span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">),</span><span class="w"> </span><span class="n">validation_split</span><span class="o">=</span><span class="n">validation_split</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">validation_data</span><span class="p">:</span>

<span class="w">            </span><span class="p">(</span>

<span class="w">                </span><span class="n">val_x</span><span class="p">,</span>

<span class="w">                </span><span class="n">val_y</span><span class="p">,</span>

<span class="w">                </span><span class="n">val_sample_weight</span><span class="p">,</span>

<span class="w">            </span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">validation_data</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="o">.</span><span class="n">_should_use_with_coordinator</span><span class="p">:</span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">_cluster_coordinator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span>

<span class="w">                </span><span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">coordinator</span><span class="o">.</span><span class="n">ClusterCoordinator</span><span class="p">(</span>

<span class="w">                    </span><span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="n">with</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">(),</span><span class="w"> </span><span class="n">training_utils</span><span class="o">.</span><span class="n">RespectCompiledTrainableState</span><span class="p">(</span><span class="w">  </span><span class="c1"># noqa: E501</span>

<span class="w">            </span><span class="bp">self</span>

<span class="w">        </span><span class="p">):</span>

<span class="w">            </span><span class="c1"># Creates a `tf.data.Dataset` and handles batch and epoch iteration.</span>

<span class="w">            </span><span class="n">data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">get_data_handler</span><span class="p">(</span>

<span class="w">                </span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>

<span class="w">                </span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>

<span class="w">                </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>

<span class="w">                </span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>

<span class="w">                </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span>

<span class="w">                </span><span class="n">initial_epoch</span><span class="o">=</span><span class="n">initial_epoch</span><span class="p">,</span>

<span class="w">                </span><span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>

<span class="w">                </span><span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>

<span class="w">                </span><span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span>

<span class="w">                </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

<span class="w">                </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

<span class="w">                </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

<span class="w">                </span><span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>

<span class="w">                </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps_per_execution</span><span class="p">,</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">            </span><span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span><span class="w"> </span><span class="n">callbacks_module</span><span class="o">.</span><span class="n">CallbackList</span><span class="p">):</span>

<span class="w">                </span><span class="n">callbacks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">callbacks_module</span><span class="o">.</span><span class="n">CallbackList</span><span class="p">(</span>

<span class="w">                    </span><span class="n">callbacks</span><span class="p">,</span>

<span class="w">                    </span><span class="n">add_history</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

<span class="w">                    </span><span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>

<span class="w">                    </span><span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>

<span class="w">                    </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>

<span class="w">                    </span><span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>

<span class="w">                    </span><span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="o">.</span><span class="n">inferred_steps</span><span class="p">,</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">False</span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">make_train_function</span><span class="p">()</span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">_train_counter</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="w">            </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_begin</span><span class="p">()</span>

<span class="w">            </span><span class="n">training_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span>

<span class="w">            </span><span class="c1"># Handle fault-tolerance for multi-worker.</span>

<span class="w">            </span><span class="c1"># TODO(omalleyt): Fix the ordering issues that mean this has to</span>

<span class="w">            </span><span class="c1"># happen after `callbacks.on_train_begin`.</span>

<span class="w">            </span><span class="n">steps_per_epoch_inferred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span>

<span class="w">                </span><span class="n">steps_per_epoch</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">inferred_steps</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">            </span><span class="p">(</span>

<span class="w">                </span><span class="n">data_handler</span><span class="o">.</span><span class="n">_initial_epoch</span><span class="p">,</span>

<span class="w">                </span><span class="n">data_handler</span><span class="o">.</span><span class="n">_initial_step</span><span class="p">,</span>

<span class="w">            </span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_maybe_load_initial_counters_from_ckpt</span><span class="p">(</span>

<span class="w">                </span><span class="n">steps_per_epoch_inferred</span><span class="p">,</span><span class="w"> </span><span class="n">initial_epoch</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">            </span><span class="n">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span>

<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">epoch</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">enumerate_epochs</span><span class="p">():</span>

<span class="w">                </span><span class="bp">self</span><span class="o">.</span><span class="n">reset_metrics</span><span class="p">()</span>

<span class="w">                </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_epoch_begin</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

<span class="w">                </span><span class="n">with</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">catch_stop_iteration</span><span class="p">():</span>

<span class="w">                    </span><span class="k">for</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">steps</span><span class="p">():</span>

<span class="w">                        </span><span class="n">with</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">Trace</span><span class="p">(</span>

<span class="w">                            </span><span class="s2">&quot;train&quot;</span><span class="p">,</span>

<span class="w">                            </span><span class="n">epoch_num</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>

<span class="w">                            </span><span class="n">step_num</span><span class="o">=</span><span class="n">step</span><span class="p">,</span>

<span class="w">                            </span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>

<span class="w">                            </span><span class="n">_r</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">                        </span><span class="p">):</span>

<span class="w">                            </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>

<span class="w">                            </span><span class="n">tmp_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

<span class="w">                            </span><span class="k">if</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">should_sync</span><span class="p">:</span>

<span class="w">                                </span><span class="n">context</span><span class="o">.</span><span class="n">async_wait</span><span class="p">()</span>

<span class="w">                            </span><span class="c1"># No error, now safe to assign to logs.</span>

<span class="w">                            </span><span class="n">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tmp_logs</span>

<span class="w">                            </span><span class="n">end_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">step_increment</span>

<span class="w">                            </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_end</span><span class="p">(</span><span class="n">end_step</span><span class="p">,</span><span class="w"> </span><span class="n">logs</span><span class="p">)</span>

<span class="w">                            </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span>

<span class="w">                                </span><span class="k">break</span>

<span class="w">                </span><span class="n">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf_utils</span><span class="o">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">logs</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">                    </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                        </span><span class="s2">&quot;Unexpected result of `train_function` &quot;</span>

<span class="w">                        </span><span class="s2">&quot;(Empty logs). Please use &quot;</span>

<span class="w">                        </span><span class="s2">&quot;`Model.compile(..., run_eagerly=True)`, or &quot;</span>

<span class="w">                        </span><span class="s2">&quot;`tf.config.run_functions_eagerly(True)` for more &quot;</span>

<span class="w">                        </span><span class="s2">&quot;information of where went wrong, or file a &quot;</span>

<span class="w">                        </span><span class="s2">&quot;issue/bug to `tf.keras`.&quot;</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">                </span><span class="c1"># Override with model metrics instead of last step logs</span>

<span class="w">                </span><span class="n">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_validate_and_get_metrics_result</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

<span class="w">                </span><span class="n">epoch_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

<span class="w">                </span><span class="c1"># Run validation.</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">validation_data</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_should_eval</span><span class="p">(</span>

<span class="w">                    </span><span class="n">epoch</span><span class="p">,</span><span class="w"> </span><span class="n">validation_freq</span>

<span class="w">                </span><span class="p">):</span>

<span class="w">                    </span><span class="c1"># Create data_handler for evaluation and cache it.</span>

<span class="w">                    </span><span class="k">if</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;_eval_data_handler&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">                        </span><span class="bp">self</span><span class="o">.</span><span class="n">_eval_data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">get_data_handler</span><span class="p">(</span>

<span class="w">                            </span><span class="n">x</span><span class="o">=</span><span class="n">val_x</span><span class="p">,</span>

<span class="w">                            </span><span class="n">y</span><span class="o">=</span><span class="n">val_y</span><span class="p">,</span>

<span class="w">                            </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">val_sample_weight</span><span class="p">,</span>

<span class="w">                            </span><span class="n">batch_size</span><span class="o">=</span><span class="n">validation_batch_size</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">batch_size</span><span class="p">,</span>

<span class="w">                            </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span>

<span class="w">                            </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

<span class="w">                            </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">                            </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

<span class="w">                            </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

<span class="w">                            </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

<span class="w">                            </span><span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>

<span class="w">                            </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps_per_execution</span><span class="p">,</span>

<span class="w">                        </span><span class="p">)</span>

<span class="w">                    </span><span class="n">val_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>

<span class="w">                        </span><span class="n">x</span><span class="o">=</span><span class="n">val_x</span><span class="p">,</span>

<span class="w">                        </span><span class="n">y</span><span class="o">=</span><span class="n">val_y</span><span class="p">,</span>

<span class="w">                        </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">val_sample_weight</span><span class="p">,</span>

<span class="w">                        </span><span class="n">batch_size</span><span class="o">=</span><span class="n">validation_batch_size</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">batch_size</span><span class="p">,</span>

<span class="w">                        </span><span class="n">steps</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span>

<span class="w">                        </span><span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>

<span class="w">                        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

<span class="w">                        </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

<span class="w">                        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

<span class="w">                        </span><span class="n">return_dict</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

<span class="w">                        </span><span class="n">_use_cached_eval_dataset</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">                    </span><span class="n">val_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>

<span class="w">                        </span><span class="s2">&quot;val_&quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">name</span><span class="p">:</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">val_logs</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>

<span class="w">                    </span><span class="p">}</span>

<span class="w">                    </span><span class="n">epoch_logs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">val_logs</span><span class="p">)</span>

<span class="w">                </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_epoch_end</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="w"> </span><span class="n">epoch_logs</span><span class="p">)</span>

<span class="w">                </span><span class="n">training_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">epoch_logs</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span>

<span class="w">                    </span><span class="k">break</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span>

<span class="w">                </span><span class="n">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span><span class="w"> </span><span class="n">optimizer_experimental</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">)</span>

<span class="w">                </span><span class="ow">and</span><span class="w"> </span><span class="n">epochs</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span>

<span class="w">            </span><span class="p">):</span>

<span class="w">                </span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">finalize_variable_values</span><span class="p">(</span>

<span class="w">                    </span><span class="bp">self</span><span class="o">.</span><span class="n">trainable_variables</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="c1"># If eval data_handler exists, delete it after all epochs are done.</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;_eval_data_handler&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">                </span><span class="n">del</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_eval_data_handler</span>

<span class="w">            </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_end</span><span class="p">(</span><span class="n">logs</span><span class="o">=</span><span class="n">training_logs</span><span class="p">)</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">history</span>
</code></pre></div>

</details>
<h4 id="fit_generator">fit_generator</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">fit_generator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>

<p>Fits the model on data yielded batch-by-batch by a Python generator.</p>
<p>DEPRECATED:
  <code>Model.fit</code> now supports generators, so there is no longer any need to
  use this endpoint.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_generate_docs</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">fit_generator</span><span class="p">(</span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">generator</span><span class="p">,</span>

<span class="w">        </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">validation_data</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">validation_steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="n">class_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

<span class="w">        </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="k">False</span><span class="p">,</span>

<span class="w">        </span><span class="n">shuffle</span><span class="o">=</span><span class="k">True</span><span class="p">,</span>

<span class="w">        </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Fits the model on data yielded batch-by-batch by a Python generator.</span>

<span class="ss">        DEPRECATED:</span>

<span class="ss">          `Model.fit` now supports generators, so there is no longer any need to</span>

<span class="ss">          use this endpoint.</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span>

<span class="w">            </span><span class="ss">&quot;`Model.fit_generator` is deprecated and &quot;</span>

<span class="w">            </span><span class="ss">&quot;will be removed in a future version. &quot;</span>

<span class="w">            </span><span class="ss">&quot;Please use `Model.fit`, which supports generators.&quot;</span><span class="p">,</span>

<span class="w">            </span><span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>

<span class="w">        </span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>

<span class="w">            </span><span class="n">generator</span><span class="p">,</span>

<span class="w">            </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span>

<span class="w">            </span><span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>

<span class="w">            </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>

<span class="w">            </span><span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>

<span class="w">            </span><span class="n">validation_data</span><span class="o">=</span><span class="n">validation_data</span><span class="p">,</span>

<span class="w">            </span><span class="n">validation_steps</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span>

<span class="w">            </span><span class="n">validation_freq</span><span class="o">=</span><span class="n">validation_freq</span><span class="p">,</span>

<span class="w">            </span><span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span>

<span class="w">            </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

<span class="w">            </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

<span class="w">            </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

<span class="w">            </span><span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>

<span class="w">            </span><span class="n">initial_epoch</span><span class="o">=</span><span class="n">initial_epoch</span><span class="p">,</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="get_config">get_config</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns the config of the <code>Model</code>.</p>
<p>Config is a Python dictionary (serializable) containing the
configuration of an object, which in this case is a <code>Model</code>. This allows
the <code>Model</code> to be be reinstantiated later (without its trained weights)
from this configuration.</p>
<p>Note that <code>get_config()</code> does not guarantee to return a fresh copy of
dict every time it is called. The callers should make a copy of the
returned dict if they want to modify it.</p>
<p>Developers of subclassed <code>Model</code> are advised to override this method,
and continue to update the dict from <code>super(MyModel, self).get_config()</code>
to provide the proper configuration of this <code>Model</code>. The default config
is an empty dict. Optionally, raise <code>NotImplementedError</code> to allow Keras
to attempt a default serialization.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Python dictionary containing the configuration of this <code>Model</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">get_config</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns the config of the `Model`.</span>

<span class="s2">        Config is a Python dictionary (serializable) containing the</span>

<span class="s2">        configuration of an object, which in this case is a `Model`. This allows</span>

<span class="s2">        the `Model` to be be reinstantiated later (without its trained weights)</span>

<span class="s2">        from this configuration.</span>

<span class="s2">        Note that `get_config()` does not guarantee to return a fresh copy of</span>

<span class="s2">        dict every time it is called. The callers should make a copy of the</span>

<span class="s2">        returned dict if they want to modify it.</span>

<span class="s2">        Developers of subclassed `Model` are advised to override this method,</span>

<span class="s2">        and continue to update the dict from `super(MyModel, self).get_config()`</span>

<span class="s2">        to provide the proper configuration of this `Model`. The default config</span>

<span class="s2">        is an empty dict. Optionally, raise `NotImplementedError` to allow Keras</span>

<span class="s2">        to attempt a default serialization.</span>

<span class="s2">        Returns:</span>

<span class="s2">            Python dictionary containing the configuration of this `Model`.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="c1"># Return an empty dict here because otherwise Model</span>

<span class="w">        </span><span class="c1"># subclass developers may see</span>

<span class="w">        </span><span class="c1"># their model&#39;s `__init__()` fed with unexpected keyword arguments,</span>

<span class="w">        </span><span class="c1"># if their `__init__()` takes no argument for example, and they</span>

<span class="w">        </span><span class="c1"># don&#39;t override `from_config()`, which would use `cls(**config)`</span>

<span class="w">        </span><span class="c1"># as a result.</span>

<span class="w">        </span><span class="n">config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">{}</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="n">saving_lib</span><span class="p">.</span><span class="n">_SAVING_V3_ENABLED</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;value&quot;</span><span class="p">,</span><span class="w"> </span><span class="no">False</span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_is_compiled</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">hasattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;_compile_config&quot;</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">config</span><span class="err">[</span><span class="s2">&quot;compile_config&quot;</span><span class="err">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_compile_config</span><span class="p">.</span><span class="n">serialize</span><span class="p">()</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">built</span><span class="o">:</span>

<span class="w">                </span><span class="n">config</span><span class="err">[</span><span class="s2">&quot;build_input_shape&quot;</span><span class="err">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_build_input_shape</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">config</span>
</code></pre></div>

</details>
<h4 id="get_input_at">get_input_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_input_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the input tensor(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node<br>from which to retrieve the attribute.<br>E.g. <code>node_index=0</code> will correspond to the<br>first input node of the layer.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A tensor (or list of tensors if the layer has multiple inputs).</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If called in Eager mode.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">get_input_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Retrieves the input tensor(s) of a layer at a given node.</span>

<span class="ss">        Args:</span>

<span class="ss">            node_index: Integer, index of the node</span>

<span class="ss">                from which to retrieve the attribute.</span>

<span class="ss">                E.g. `node_index=0` will correspond to the</span>

<span class="ss">                first input node of the layer.</span>

<span class="ss">        Returns:</span>

<span class="ss">            A tensor (or list of tensors if the layer has multiple inputs).</span>

<span class="ss">        Raises:</span>

<span class="ss">          RuntimeError: If called in Eager mode.</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span>

<span class="w">            </span><span class="n">node_index</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;input_tensors&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;input&quot;</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="get_input_mask_at">get_input_mask_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_input_mask_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the input mask tensor(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node<br>from which to retrieve the attribute.<br>E.g. <code>node_index=0</code> will correspond to the<br>first time the layer was called.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A mask tensor<br>(or list of tensors if the layer has multiple inputs).</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">get_input_mask_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Retrieves the input mask tensor(s) of a layer at a given node.</span>

<span class="ss">        Args:</span>

<span class="ss">            node_index: Integer, index of the node</span>

<span class="ss">                from which to retrieve the attribute.</span>

<span class="ss">                E.g. `node_index=0` will correspond to the</span>

<span class="ss">                first time the layer was called.</span>

<span class="ss">        Returns:</span>

<span class="ss">            A mask tensor</span>

<span class="ss">            (or list of tensors if the layer has multiple inputs).</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">get_input_at</span><span class="p">(</span><span class="n">node_index</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">list</span><span class="p">)</span><span class="err">:</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="o">[</span><span class="n">getattr(x, &quot;_keras_mask&quot;, None) for x in inputs</span><span class="o">]</span>

<span class="w">        </span><span class="k">else</span><span class="err">:</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;_keras_mask&quot;</span><span class="p">,</span><span class="w"> </span><span class="k">None</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="get_input_shape_at">get_input_shape_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_input_shape_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the input shape(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node<br>from which to retrieve the attribute.<br>E.g. <code>node_index=0</code> will correspond to the<br>first time the layer was called.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A shape tuple<br>(or list of shape tuples if the layer has multiple inputs).</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If called in Eager mode.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">get_input_shape_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Retrieves the input shape(s) of a layer at a given node.</span>

<span class="ss">        Args:</span>

<span class="ss">            node_index: Integer, index of the node</span>

<span class="ss">                from which to retrieve the attribute.</span>

<span class="ss">                E.g. `node_index=0` will correspond to the</span>

<span class="ss">                first time the layer was called.</span>

<span class="ss">        Returns:</span>

<span class="ss">            A shape tuple</span>

<span class="ss">            (or list of shape tuples if the layer has multiple inputs).</span>

<span class="ss">        Raises:</span>

<span class="ss">          RuntimeError: If called in Eager mode.</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span>

<span class="w">            </span><span class="n">node_index</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;input_shapes&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;input shape&quot;</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="get_layer">get_layer</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_layer</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">index</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves a layer based on either its name (unique) or index.</p>
<p>If <code>name</code> and <code>index</code> are both provided, <code>index</code> will take precedence.
Indices are based on order of horizontal graph traversal (bottom-up).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>name</td>
<td>None</td>
<td>String, name of layer.</td>
<td>None</td>
</tr>
<tr>
<td>index</td>
<td>None</td>
<td>Integer, index of layer.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A layer instance.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">get_layer</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">name</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"> </span><span class="k">index</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Retrieves a layer based on either its name (unique) or index.</span>

<span class="s2">        If `name` and `index` are both provided, `index` will take precedence.</span>

<span class="s2">        Indices are based on order of horizontal graph traversal (bottom-up).</span>

<span class="s2">        Args:</span>

<span class="s2">            name: String, name of layer.</span>

<span class="s2">            index: Integer, index of layer.</span>

<span class="s2">        Returns:</span>

<span class="s2">            A layer instance.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="c1"># TODO(fchollet): We could build a dictionary based on layer names</span>

<span class="w">        </span><span class="c1"># since they are constant, but we have not done that yet.</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="k">index</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">name</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="o">:</span>

<span class="w">            </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                </span><span class="s2">&quot;Provide only a layer name or a layer index. Received: &quot;</span>

<span class="w">                </span><span class="n">f</span><span class="s2">&quot;index={index}, name={name}.&quot;</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="k">index</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="o">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="k">index</span><span class="o">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                    </span><span class="n">f</span><span class="s2">&quot;Was asked to retrieve layer at index {index}&quot;</span>

<span class="w">                    </span><span class="n">f</span><span class="s2">&quot; but model only has {len(self.layers)}&quot;</span>

<span class="w">                    </span><span class="s2">&quot; layers.&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="k">else</span><span class="o">:</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="err">[</span><span class="k">index</span><span class="err">]</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="k">name</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="o">:</span>

<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="o">:</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">layer</span><span class="p">.</span><span class="k">name</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">name</span><span class="o">:</span>

<span class="w">                    </span><span class="k">return</span><span class="w"> </span><span class="n">layer</span>

<span class="w">            </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                </span><span class="n">f</span><span class="s2">&quot;No such layer: {name}. Existing layers are: &quot;</span>

<span class="w">                </span><span class="n">f</span><span class="s2">&quot;{list(layer.name for layer in self.layers)}.&quot;</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">            </span><span class="s2">&quot;Provide either a layer name or layer index at `get_layer`.&quot;</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="get_metrics_result">get_metrics_result</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_metrics_result</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns the model's metrics values as a dict.</p>
<p>If any of the metric result is a dict (containing multiple metrics),
each of them gets added to the top level returned dict of this method.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A <code>dict</code> containing values of the metrics listed in <code>self.metrics</code>.<br>Example:<br><code>{'loss': 0.2, 'accuracy': 0.7}</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">get_metrics_result</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns the model&#39;s metrics values as a dict.</span>

<span class="s2">        If any of the metric result is a dict (containing multiple metrics),</span>

<span class="s2">        each of them gets added to the top level returned dict of this method.</span>

<span class="s2">        Returns:</span>

<span class="s2">          A `dict` containing values of the metrics listed in `self.metrics`.</span>

<span class="s2">          Example:</span>

<span class="s2">          `{&#39;loss&#39;: 0.2, &#39;accuracy&#39;: 0.7}`.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="c1"># Collect metrics to return</span>

<span class="w">        </span><span class="n">return_metrics</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">{}</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">metric</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">metrics</span><span class="o">:</span>

<span class="w">            </span><span class="n">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">metric</span><span class="p">.</span><span class="n">result</span><span class="p">()</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span><span class="w"> </span><span class="n">dict</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">return_metrics</span><span class="p">.</span><span class="k">update</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="w">            </span><span class="k">else</span><span class="o">:</span>

<span class="w">                </span><span class="n">return_metrics</span><span class="err">[</span><span class="n">metric</span><span class="p">.</span><span class="k">name</span><span class="err">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">result</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">return_metrics</span>
</code></pre></div>

</details>
<h4 id="get_output_at">get_output_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_output_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the output tensor(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node<br>from which to retrieve the attribute.<br>E.g. <code>node_index=0</code> will correspond to the<br>first output node of the layer.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A tensor (or list of tensors if the layer has multiple outputs).</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If called in Eager mode.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">get_output_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Retrieves the output tensor(s) of a layer at a given node.</span>

<span class="ss">        Args:</span>

<span class="ss">            node_index: Integer, index of the node</span>

<span class="ss">                from which to retrieve the attribute.</span>

<span class="ss">                E.g. `node_index=0` will correspond to the</span>

<span class="ss">                first output node of the layer.</span>

<span class="ss">        Returns:</span>

<span class="ss">            A tensor (or list of tensors if the layer has multiple outputs).</span>

<span class="ss">        Raises:</span>

<span class="ss">          RuntimeError: If called in Eager mode.</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span>

<span class="w">            </span><span class="n">node_index</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;output_tensors&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;output&quot;</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="get_output_mask_at">get_output_mask_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_output_mask_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the output mask tensor(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node<br>from which to retrieve the attribute.<br>E.g. <code>node_index=0</code> will correspond to the<br>first time the layer was called.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A mask tensor<br>(or list of tensors if the layer has multiple outputs).</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">get_output_mask_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Retrieves the output mask tensor(s) of a layer at a given node.</span>

<span class="ss">        Args:</span>

<span class="ss">            node_index: Integer, index of the node</span>

<span class="ss">                from which to retrieve the attribute.</span>

<span class="ss">                E.g. `node_index=0` will correspond to the</span>

<span class="ss">                first time the layer was called.</span>

<span class="ss">        Returns:</span>

<span class="ss">            A mask tensor</span>

<span class="ss">            (or list of tensors if the layer has multiple outputs).</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">get_output_at</span><span class="p">(</span><span class="n">node_index</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="k">output</span><span class="p">,</span><span class="w"> </span><span class="n">list</span><span class="p">)</span><span class="err">:</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="o">[</span><span class="n">getattr(x, &quot;_keras_mask&quot;, None) for x in output</span><span class="o">]</span>

<span class="w">        </span><span class="k">else</span><span class="err">:</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="k">output</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;_keras_mask&quot;</span><span class="p">,</span><span class="w"> </span><span class="k">None</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="get_output_shape_at">get_output_shape_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_output_shape_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the output shape(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node<br>from which to retrieve the attribute.<br>E.g. <code>node_index=0</code> will correspond to the<br>first time the layer was called.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A shape tuple<br>(or list of shape tuples if the layer has multiple outputs).</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If called in Eager mode.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">get_output_shape_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Retrieves the output shape(s) of a layer at a given node.</span>

<span class="ss">        Args:</span>

<span class="ss">            node_index: Integer, index of the node</span>

<span class="ss">                from which to retrieve the attribute.</span>

<span class="ss">                E.g. `node_index=0` will correspond to the</span>

<span class="ss">                first time the layer was called.</span>

<span class="ss">        Returns:</span>

<span class="ss">            A shape tuple</span>

<span class="ss">            (or list of shape tuples if the layer has multiple outputs).</span>

<span class="ss">        Raises:</span>

<span class="ss">          RuntimeError: If called in Eager mode.</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span>

<span class="w">            </span><span class="n">node_index</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;output_shapes&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;output shape&quot;</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="get_weight_paths">get_weight_paths</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_weight_paths</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieve all the variables and their paths for the model.</p>
<p>The variable path (string) is a stable key to indentify a <code>tf.Variable</code>
instance owned by the model. It can be used to specify variable-specific
configurations (e.g. DTensor, quantization) from a global view.</p>
<p>This method returns a dict with weight object paths as keys
and the corresponding <code>tf.Variable</code> instances as values.</p>
<p>Note that if the model is a subclassed model and the weights haven't
been initialized, an empty dict will be returned.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A dict where keys are variable paths and values are <code>tf.Variable</code><br>instances.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">get_weight_paths</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Retrieve all the variables and their paths for the model.</span>

<span class="ss">        The variable path (string) is a stable key to indentify a `tf.Variable`</span>

<span class="ss">        instance owned by the model. It can be used to specify variable-specific</span>

<span class="ss">        configurations (e.g. DTensor, quantization) from a global view.</span>

<span class="ss">        This method returns a dict with weight object paths as keys</span>

<span class="ss">        and the corresponding `tf.Variable` instances as values.</span>

<span class="ss">        Note that if the model is a subclassed model and the weights haven&#39;t</span>

<span class="ss">        been initialized, an empty dict will be returned.</span>

<span class="ss">        Returns:</span>

<span class="ss">            A dict where keys are variable paths and values are `tf.Variable`</span>

<span class="ss">             instances.</span>

<span class="ss">        Example:</span>

<span class="ss">        ```python</span>

<span class="ss">        class SubclassModel(tf.keras.Model):</span>

<span class="ss">          def __init__(self, name=None):</span>

<span class="ss">            super().__init__(name=name)</span>

<span class="ss">            self.d1 = tf.keras.layers.Dense(10)</span>

<span class="ss">            self.d2 = tf.keras.layers.Dense(20)</span>

<span class="ss">          def call(self, inputs):</span>

<span class="ss">            x = self.d1(inputs)</span>

<span class="ss">            return self.d2(x)</span>

<span class="ss">        model = SubclassModel()</span>

<span class="ss">        model(tf.zeros((10, 10)))</span>

<span class="ss">        weight_paths = model.get_weight_paths()</span>

<span class="ss">        # weight_paths:</span>

<span class="ss">        # {</span>

<span class="ss">        #    &#39;d1.kernel&#39;: model.d1.kernel,</span>

<span class="ss">        #    &#39;d1.bias&#39;: model.d1.bias,</span>

<span class="ss">        #    &#39;d2.kernel&#39;: model.d2.kernel,</span>

<span class="ss">        #    &#39;d2.bias&#39;: model.d2.bias,</span>

<span class="ss">        # }</span>

<span class="ss">        # Functional model</span>

<span class="ss">        inputs = tf.keras.Input((10,), batch_size=10)</span>

<span class="ss">        x = tf.keras.layers.Dense(20, name=&#39;d1&#39;)(inputs)</span>

<span class="ss">        output = tf.keras.layers.Dense(30, name=&#39;d2&#39;)(x)</span>

<span class="ss">        model = tf.keras.Model(inputs, output)</span>

<span class="ss">        d1 = model.layers[1]</span>

<span class="ss">        d2 = model.layers[2]</span>

<span class="ss">        weight_paths = model.get_weight_paths()</span>

<span class="ss">        # weight_paths:</span>

<span class="ss">        # {</span>

<span class="ss">        #    &#39;d1.kernel&#39;: d1.kernel,</span>

<span class="ss">        #    &#39;d1.bias&#39;: d1.bias,</span>

<span class="ss">        #    &#39;d2.kernel&#39;: d2.kernel,</span>

<span class="ss">        #    &#39;d2.bias&#39;: d2.bias,</span>

<span class="ss">        # }</span>

<span class="ss">        ```</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">{}</span>

<span class="w">        </span><span class="p">(</span>

<span class="w">            </span><span class="n">descendants</span><span class="p">,</span>

<span class="w">            </span><span class="n">object_paths_dict</span><span class="p">,</span>

<span class="w">        </span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">__internal__</span><span class="p">.</span><span class="n">tracking</span><span class="p">.</span><span class="n">ObjectGraphView</span><span class="p">(</span>

<span class="w">            </span><span class="n">self</span>

<span class="w">        </span><span class="p">).</span><span class="n">breadth_first_traversal</span><span class="p">()</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">descendant</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="nl">descendants</span><span class="p">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">descendant</span><span class="p">,</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">Variable</span><span class="p">)</span><span class="err">:</span>

<span class="w">                </span><span class="n">trackable_references</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">object_paths_dict</span><span class="o">[</span><span class="n">descendant</span><span class="o">]</span>

<span class="w">                </span><span class="n">object_path</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">&quot;.&quot;</span><span class="p">.</span><span class="k">join</span><span class="p">(</span><span class="o">[</span><span class="n">t.name for t in trackable_references</span><span class="o">]</span><span class="p">)</span>

<span class="w">                </span><span class="k">result</span><span class="o">[</span><span class="n">object_path</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">descendant</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="k">result</span>
</code></pre></div>

</details>
<h4 id="get_weights">get_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_weights</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the weights of the model.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A flat list of Numpy arrays.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">def</span><span class="w"> </span><span class="nv">get_weights</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span>:

<span class="w">        </span><span class="s2">&quot;&quot;</span><span class="err">&quot;Retrieves the weights of the model.</span>

<span class="err">        Returns:</span>

<span class="err">            A flat list of Numpy arrays.</span>

<span class="w">        </span><span class="s2">&quot;&quot;</span><span class="err">&quot;</span>

<span class="err">        with self.distribute_strategy.scope():</span>

<span class="err">            return super().get_weights()</span>
</code></pre></div>

</details>
<h4 id="load_weights">load_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">load_weights</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filepath</span><span class="p">,</span>
    <span class="n">by_name</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">skip_mismatch</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Loads all layer weights, either from a TensorFlow or an HDF5 weight file.</p>
<p>If <code>by_name</code> is False weights are loaded based on the network's
topology. This means the architecture should be the same as when the
weights were saved.  Note that layers that don't have weights are not
taken into account in the topological ordering, so adding or removing
layers is fine as long as they don't have weights.</p>
<p>If <code>by_name</code> is True, weights are loaded into layers only if they share
the same name. This is useful for fine-tuning or transfer-learning
models where some of the layers have changed.</p>
<p>Only topological loading (<code>by_name=False</code>) is supported when loading
weights from the TensorFlow format. Note that topological loading
differs slightly between TensorFlow and HDF5 formats for user-defined
classes inheriting from <code>tf.keras.Model</code>: HDF5 loads based on a
flattened list of weights, while the TensorFlow format loads based on
the object-local names of attributes to which layers are assigned in the
<code>Model</code>'s constructor.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>filepath</td>
<td>None</td>
<td>String, path to the weights file to load. For weight files<br>in TensorFlow format, this is the file prefix (the same as was<br>passed to <code>save_weights</code>). This can also be a path to a<br>SavedModel saved from <code>model.save</code>.</td>
<td>None</td>
</tr>
<tr>
<td>by_name</td>
<td>None</td>
<td>Boolean, whether to load weights by name or by topological<br>order. Only topological loading is supported for weight files in<br>TensorFlow format.</td>
<td>None</td>
</tr>
<tr>
<td>skip_mismatch</td>
<td>None</td>
<td>Boolean, whether to skip loading of layers where<br>there is a mismatch in the number of weights, or a mismatch in<br>the shape of the weight (only valid when <code>by_name=True</code>).</td>
<td>None</td>
</tr>
<tr>
<td>options</td>
<td>None</td>
<td>Optional <code>tf.train.CheckpointOptions</code> object that specifies<br>options for loading weights.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>When loading a weight file in TensorFlow format, returns the same<br>status object as <code>tf.train.Checkpoint.restore</code>. When graph building,<br>restore ops are run automatically as soon as the network is built<br>(on first call for user-defined classes inheriting from <code>Model</code>,<br>immediately if it is already built).<br><br>When loading weights in HDF5 format, returns <code>None</code>.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ImportError</td>
<td>If <code>h5py</code> is not available and the weight file is in<br>HDF5 format.</td>
</tr>
<tr>
<td>ValueError</td>
<td>If <code>skip_mismatch</code> is set to <code>True</code> when <code>by_name</code> is<br><code>False</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="err">@</span><span class="n">traceback_utils</span><span class="o">.</span><span class="n">filter_traceback</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">load_weights</span><span class="p">(</span>

<span class="w">        </span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="n">by_name</span><span class="o">=</span><span class="n">False</span><span class="p">,</span><span class="w"> </span><span class="n">skip_mismatch</span><span class="o">=</span><span class="n">False</span><span class="p">,</span><span class="w"> </span><span class="n">options</span><span class="o">=</span><span class="n">None</span>

<span class="w">    </span><span class="p">):</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;Loads all layer weights, either from a TensorFlow or an HDF5 weight file.</span>

<span class="sd">        If `by_name` is False weights are loaded based on the network&#39;s</span>

<span class="sd">        topology. This means the architecture should be the same as when the</span>

<span class="sd">        weights were saved.  Note that layers that don&#39;t have weights are not</span>

<span class="sd">        taken into account in the topological ordering, so adding or removing</span>

<span class="sd">        layers is fine as long as they don&#39;t have weights.</span>

<span class="sd">        If `by_name` is True, weights are loaded into layers only if they share</span>

<span class="sd">        the same name. This is useful for fine-tuning or transfer-learning</span>

<span class="sd">        models where some of the layers have changed.</span>

<span class="sd">        Only topological loading (`by_name=False`) is supported when loading</span>

<span class="sd">        weights from the TensorFlow format. Note that topological loading</span>

<span class="sd">        differs slightly between TensorFlow and HDF5 formats for user-defined</span>

<span class="sd">        classes inheriting from `tf.keras.Model`: HDF5 loads based on a</span>

<span class="sd">        flattened list of weights, while the TensorFlow format loads based on</span>

<span class="sd">        the object-local names of attributes to which layers are assigned in the</span>

<span class="sd">        `Model`&#39;s constructor.</span>

<span class="sd">        Args:</span>

<span class="sd">            filepath: String, path to the weights file to load. For weight files</span>

<span class="sd">                in TensorFlow format, this is the file prefix (the same as was</span>

<span class="sd">                passed to `save_weights`). This can also be a path to a</span>

<span class="sd">                SavedModel saved from `model.save`.</span>

<span class="sd">            by_name: Boolean, whether to load weights by name or by topological</span>

<span class="sd">                order. Only topological loading is supported for weight files in</span>

<span class="sd">                TensorFlow format.</span>

<span class="sd">            skip_mismatch: Boolean, whether to skip loading of layers where</span>

<span class="sd">                there is a mismatch in the number of weights, or a mismatch in</span>

<span class="sd">                the shape of the weight (only valid when `by_name=True`).</span>

<span class="sd">            options: Optional `tf.train.CheckpointOptions` object that specifies</span>

<span class="sd">                options for loading weights.</span>

<span class="sd">        Returns:</span>

<span class="sd">            When loading a weight file in TensorFlow format, returns the same</span>

<span class="sd">            status object as `tf.train.Checkpoint.restore`. When graph building,</span>

<span class="sd">            restore ops are run automatically as soon as the network is built</span>

<span class="sd">            (on first call for user-defined classes inheriting from `Model`,</span>

<span class="sd">            immediately if it is already built).</span>

<span class="sd">            When loading weights in HDF5 format, returns `None`.</span>

<span class="sd">        Raises:</span>

<span class="sd">            ImportError: If `h5py` is not available and the weight file is in</span>

<span class="sd">              HDF5 format.</span>

<span class="sd">            ValueError: If `skip_mismatch` is set to `True` when `by_name` is</span>

<span class="sd">              `False`.</span>

<span class="sd">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">backend</span><span class="o">.</span><span class="n">is_tpu_strategy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="p">):</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="o">.</span><span class="n">extended</span><span class="o">.</span><span class="n">steps_per_run</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="p">(</span>

<span class="w">                </span><span class="ow">not</span><span class="w"> </span><span class="n">saving_utils</span><span class="o">.</span><span class="n">is_hdf5_filepath</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>

<span class="w">            </span><span class="p">):</span>

<span class="w">                </span><span class="n">spr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="o">.</span><span class="n">extended</span><span class="o">.</span><span class="n">steps_per_run</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                    </span><span class="s2">&quot;Load weights is not implemented with TPUStrategy &quot;</span>

<span class="w">                    </span><span class="s2">&quot;with `steps_per_run` greater than 1. The &quot;</span>

<span class="w">                    </span><span class="n">f</span><span class="s2">&quot;`steps_per_run` is {spr}&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">skip_mismatch</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">by_name</span><span class="p">:</span>

<span class="w">            </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                </span><span class="s2">&quot;When calling model.load_weights, skip_mismatch can only be &quot;</span>

<span class="w">                </span><span class="s2">&quot;set to True when by_name is True.&quot;</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">_detect_save_format</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">&quot;tf&quot;</span><span class="p">:</span>

<span class="w">            </span><span class="n">status</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_checkpoint</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="n">options</span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">by_name</span><span class="p">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">NotImplementedError</span><span class="p">(</span>

<span class="w">                    </span><span class="s2">&quot;Weights may only be loaded based on topology into Models &quot;</span>

<span class="w">                    </span><span class="s2">&quot;when loading TensorFlow-formatted weights &quot;</span>

<span class="w">                    </span><span class="s2">&quot;(got by_name=True to load_weights).&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>

<span class="w">                </span><span class="n">session</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">backend</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span>

<span class="w">                </span><span class="c1"># Restore existing variables (if any) immediately, and set up a</span>

<span class="w">                </span><span class="c1"># streaming restore for any variables created in the future.</span>

<span class="w">                </span><span class="n">tf</span><span class="o">.</span><span class="n">__internal__</span><span class="o">.</span><span class="n">tracking</span><span class="o">.</span><span class="n">streaming_restore</span><span class="p">(</span>

<span class="w">                    </span><span class="n">status</span><span class="o">=</span><span class="n">status</span><span class="p">,</span><span class="w"> </span><span class="n">session</span><span class="o">=</span><span class="n">session</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="n">status</span><span class="o">.</span><span class="n">assert_nontrivial_match</span><span class="p">()</span>

<span class="w">        </span><span class="k">else</span><span class="p">:</span>

<span class="w">            </span><span class="n">status</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">h5py</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">ImportError</span><span class="p">(</span>

<span class="w">                    </span><span class="s2">&quot;`load_weights` requires h5py package when loading weights &quot;</span>

<span class="w">                    </span><span class="s2">&quot;from HDF5. Try installing h5py.&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_is_graph_network</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">built</span><span class="p">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                    </span><span class="s2">&quot;Unable to load weights saved in HDF5 format into a &quot;</span>

<span class="w">                    </span><span class="s2">&quot;subclassed Model which has not created its variables yet. &quot;</span>

<span class="w">                    </span><span class="s2">&quot;Call the Model first, then load the weights.&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">_assert_weights_created</span><span class="p">()</span>

<span class="w">            </span><span class="n">with</span><span class="w"> </span><span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;r&quot;</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">f</span><span class="p">:</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="s2">&quot;layer_names&quot;</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">f</span><span class="o">.</span><span class="n">attrs</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="s2">&quot;model_weights&quot;</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">f</span><span class="p">:</span>

<span class="w">                    </span><span class="n">f</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f</span><span class="p">[</span><span class="s2">&quot;model_weights&quot;</span><span class="p">]</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">by_name</span><span class="p">:</span>

<span class="w">                    </span><span class="n">hdf5_format</span><span class="o">.</span><span class="n">load_weights_from_hdf5_group_by_name</span><span class="p">(</span>

<span class="w">                        </span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">skip_mismatch</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">                </span><span class="k">else</span><span class="p">:</span>

<span class="w">                    </span><span class="n">hdf5_format</span><span class="o">.</span><span class="n">load_weights_from_hdf5_group</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="p">)</span>

<span class="w">        </span><span class="c1"># Perform any layer defined finalization of the layer state.</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>

<span class="w">            </span><span class="n">layer</span><span class="o">.</span><span class="n">finalize_state</span><span class="p">()</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">status</span>
</code></pre></div>

</details>
<h4 id="make_predict_function">make_predict_function</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">make_predict_function</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">force</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a function that executes one step of inference.</p>
<p>This method can be overridden to support custom inference logic.
This method is called by <code>Model.predict</code> and <code>Model.predict_on_batch</code>.</p>
<p>Typically, this method directly controls <code>tf.function</code> and
<code>tf.distribute.Strategy</code> settings, and delegates the actual evaluation
logic to <code>Model.predict_step</code>.</p>
<p>This function is cached the first time <code>Model.predict</code> or
<code>Model.predict_on_batch</code> is called. The cache is cleared whenever
<code>Model.compile</code> is called. You can skip the cache and generate again the
function with <code>force=True</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>force</td>
<td>None</td>
<td>Whether to regenerate the predict function and skip the cached<br>function if available.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Function. The function created by this method should accept a<br><code>tf.data.Iterator</code>, and return the outputs of the <code>Model</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">make_predict_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">force</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Creates a function that executes one step of inference.</span>

<span class="s2">        This method can be overridden to support custom inference logic.</span>

<span class="s2">        This method is called by `Model.predict` and `Model.predict_on_batch`.</span>

<span class="s2">        Typically, this method directly controls `tf.function` and</span>

<span class="s2">        `tf.distribute.Strategy` settings, and delegates the actual evaluation</span>

<span class="s2">        logic to `Model.predict_step`.</span>

<span class="s2">        This function is cached the first time `Model.predict` or</span>

<span class="s2">        `Model.predict_on_batch` is called. The cache is cleared whenever</span>

<span class="s2">        `Model.compile` is called. You can skip the cache and generate again the</span>

<span class="s2">        function with `force=True`.</span>

<span class="s2">        Args:</span>

<span class="s2">          force: Whether to regenerate the predict function and skip the cached</span>

<span class="s2">            function if available.</span>

<span class="s2">        Returns:</span>

<span class="s2">          Function. The function created by this method should accept a</span>

<span class="s2">          `tf.data.Iterator`, and return the outputs of the `Model`.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">force</span><span class="o">:</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span>

<span class="w">        </span><span class="n">def</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single evaluation step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">            </span><span class="n">def</span><span class="w"> </span><span class="n">run_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">predict_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

<span class="w">                </span><span class="c1"># Ensure counter is updated only if `test_step` succeeds.</span>

<span class="w">                </span><span class="k">with</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_minimum_control_deps</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span><span class="o">:</span>

<span class="w">                    </span><span class="n">model</span><span class="p">.</span><span class="n">_predict_counter</span><span class="p">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_jit_compile</span><span class="o">:</span>

<span class="w">                </span><span class="n">run_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

<span class="w">                    </span><span class="n">run_step</span><span class="p">,</span><span class="w"> </span><span class="n">jit_compile</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"> </span><span class="n">reduce_retracing</span><span class="o">=</span><span class="no">True</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="k">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

<span class="w">            </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="k">data</span><span class="p">,))</span>

<span class="w">            </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">reduce_per_replica</span><span class="p">(</span>

<span class="w">                </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span><span class="w"> </span><span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;concat&quot;</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">        </span><span class="c1"># Special case if steps_per_execution is one.</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span>

<span class="w">            </span><span class="k">or</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span>

<span class="w">        </span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="n">def</span><span class="w"> </span><span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs an evaluation execution with a single step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span>

<span class="w">        </span><span class="k">else</span><span class="o">:</span>

<span class="w">            </span><span class="n">def</span><span class="w"> </span><span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs an evaluation execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">                </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span>

<span class="w">                </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">:</span>

<span class="w">                    </span><span class="n">tf</span><span class="p">.</span><span class="n">autograph</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="k">set</span><span class="n">_loop_options</span><span class="p">(</span>

<span class="w">                        </span><span class="n">shape_invariants</span><span class="o">=</span><span class="err">[</span>

<span class="w">                            </span><span class="p">(</span>

<span class="w">                                </span><span class="n">outputs</span><span class="p">,</span>

<span class="w">                                </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span>

<span class="w">                                    </span><span class="n">lambda</span><span class="w"> </span><span class="n">t</span><span class="o">:</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">get_tensor_spec</span><span class="p">(</span>

<span class="w">                                        </span><span class="n">t</span><span class="p">,</span><span class="w"> </span><span class="n">dynamic_batch</span><span class="o">=</span><span class="no">True</span>

<span class="w">                                    </span><span class="p">).</span><span class="n">shape</span><span class="p">,</span>

<span class="w">                                    </span><span class="n">outputs</span><span class="p">,</span>

<span class="w">                                </span><span class="p">),</span>

<span class="w">                            </span><span class="p">)</span>

<span class="w">                        </span><span class="err">]</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">                    </span><span class="n">step_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span>

<span class="w">                    </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span>

<span class="w">                        </span><span class="n">lambda</span><span class="w"> </span><span class="n">t1</span><span class="p">,</span><span class="w"> </span><span class="n">t2</span><span class="o">:</span><span class="w"> </span><span class="nf">concat</span><span class="p">(</span><span class="err">[</span><span class="n">t1</span><span class="p">,</span><span class="w"> </span><span class="n">t2</span><span class="err">]</span><span class="p">),</span><span class="w"> </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">step_outputs</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span>

<span class="w">            </span><span class="n">predict_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

<span class="w">                </span><span class="n">predict_function</span><span class="p">,</span><span class="w"> </span><span class="n">reduce_retracing</span><span class="o">=</span><span class="no">True</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">predict_function</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span>
</code></pre></div>

</details>
<h4 id="make_test_function">make_test_function</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">make_test_function</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">force</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a function that executes one step of evaluation.</p>
<p>This method can be overridden to support custom evaluation logic.
This method is called by <code>Model.evaluate</code> and <code>Model.test_on_batch</code>.</p>
<p>Typically, this method directly controls <code>tf.function</code> and
<code>tf.distribute.Strategy</code> settings, and delegates the actual evaluation
logic to <code>Model.test_step</code>.</p>
<p>This function is cached the first time <code>Model.evaluate</code> or
<code>Model.test_on_batch</code> is called. The cache is cleared whenever
<code>Model.compile</code> is called. You can skip the cache and generate again the
function with <code>force=True</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>force</td>
<td>None</td>
<td>Whether to regenerate the test function and skip the cached<br>function if available.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Function. The function created by this method should accept a<br><code>tf.data.Iterator</code>, and return a <code>dict</code> containing values that will<br>be passed to <code>tf.keras.Callbacks.on_test_batch_end</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">make_test_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">force</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Creates a function that executes one step of evaluation.</span>

<span class="s2">        This method can be overridden to support custom evaluation logic.</span>

<span class="s2">        This method is called by `Model.evaluate` and `Model.test_on_batch`.</span>

<span class="s2">        Typically, this method directly controls `tf.function` and</span>

<span class="s2">        `tf.distribute.Strategy` settings, and delegates the actual evaluation</span>

<span class="s2">        logic to `Model.test_step`.</span>

<span class="s2">        This function is cached the first time `Model.evaluate` or</span>

<span class="s2">        `Model.test_on_batch` is called. The cache is cleared whenever</span>

<span class="s2">        `Model.compile` is called. You can skip the cache and generate again the</span>

<span class="s2">        function with `force=True`.</span>

<span class="s2">        Args:</span>

<span class="s2">          force: Whether to regenerate the test function and skip the cached</span>

<span class="s2">            function if available.</span>

<span class="s2">        Returns:</span>

<span class="s2">          Function. The function created by this method should accept a</span>

<span class="s2">          `tf.data.Iterator`, and return a `dict` containing values that will</span>

<span class="s2">          be passed to `tf.keras.Callbacks.on_test_batch_end`.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">force</span><span class="o">:</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span>

<span class="w">        </span><span class="n">def</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single evaluation step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">            </span><span class="n">def</span><span class="w"> </span><span class="n">run_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">test_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

<span class="w">                </span><span class="c1"># Ensure counter is updated only if `test_step` succeeds.</span>

<span class="w">                </span><span class="k">with</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_minimum_control_deps</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span><span class="o">:</span>

<span class="w">                    </span><span class="n">model</span><span class="p">.</span><span class="n">_test_counter</span><span class="p">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_jit_compile</span><span class="o">:</span>

<span class="w">                </span><span class="n">run_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

<span class="w">                    </span><span class="n">run_step</span><span class="p">,</span><span class="w"> </span><span class="n">jit_compile</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"> </span><span class="n">reduce_retracing</span><span class="o">=</span><span class="no">True</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="k">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

<span class="w">            </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="k">data</span><span class="p">,))</span>

<span class="w">            </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">reduce_per_replica</span><span class="p">(</span>

<span class="w">                </span><span class="n">outputs</span><span class="p">,</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span>

<span class="w">                </span><span class="n">reduction</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">distribute_reduction_method</span><span class="p">,</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">        </span><span class="c1"># Special case if steps_per_execution is one.</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span>

<span class="w">            </span><span class="k">or</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span>

<span class="w">        </span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="n">def</span><span class="w"> </span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a test execution with a single step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span>

<span class="w">                </span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

<span class="w">                    </span><span class="n">test_function</span><span class="p">,</span><span class="w"> </span><span class="n">reduce_retracing</span><span class="o">=</span><span class="no">True</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span>

<span class="w">                    </span><span class="n">lambda</span><span class="w"> </span><span class="n">it</span><span class="o">:</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="p">.</span><span class="k">schedule</span><span class="p">(</span>

<span class="w">                        </span><span class="n">test_function</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">it</span><span class="p">,)</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="k">else</span><span class="o">:</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">test_function</span>

<span class="w">        </span><span class="c1"># If we&#39;re using a coordinator, use the value of</span>

<span class="w">        </span><span class="c1"># self._steps_per_execution at the time the function is</span>

<span class="w">        </span><span class="c1"># called/scheduled, and not when it is actually executed.</span>

<span class="w">        </span><span class="n">elif</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span>

<span class="w">            </span><span class="n">def</span><span class="w"> </span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">,</span><span class="w"> </span><span class="n">steps_per_execution</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a test execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">                </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">steps_per_execution</span><span class="p">)</span><span class="o">:</span>

<span class="w">                    </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span>

<span class="w">                </span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

<span class="w">                    </span><span class="n">test_function</span><span class="p">,</span><span class="w"> </span><span class="n">reduce_retracing</span><span class="o">=</span><span class="no">True</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="n">it</span><span class="o">:</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="p">.</span><span class="k">schedule</span><span class="p">(</span>

<span class="w">                </span><span class="n">test_function</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">it</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="k">value</span><span class="p">())</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="k">else</span><span class="o">:</span>

<span class="w">            </span><span class="n">def</span><span class="w"> </span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a test execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">                </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="o">:</span>

<span class="w">                    </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span>

<span class="w">                </span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

<span class="w">                    </span><span class="n">test_function</span><span class="p">,</span><span class="w"> </span><span class="n">reduce_retracing</span><span class="o">=</span><span class="no">True</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">test_function</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span>
</code></pre></div>

</details>
<h4 id="make_train_function">make_train_function</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">make_train_function</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">force</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a function that executes one step of training.</p>
<p>This method can be overridden to support custom training logic.
This method is called by <code>Model.fit</code> and <code>Model.train_on_batch</code>.</p>
<p>Typically, this method directly controls <code>tf.function</code> and
<code>tf.distribute.Strategy</code> settings, and delegates the actual training
logic to <code>Model.train_step</code>.</p>
<p>This function is cached the first time <code>Model.fit</code> or
<code>Model.train_on_batch</code> is called. The cache is cleared whenever
<code>Model.compile</code> is called. You can skip the cache and generate again the
function with <code>force=True</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>force</td>
<td>None</td>
<td>Whether to regenerate the train function and skip the cached<br>function if available.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Function. The function created by this method should accept a<br><code>tf.data.Iterator</code>, and return a <code>dict</code> containing values that will<br>be passed to <code>tf.keras.Callbacks.on_train_batch_end</code>, such as<br><code>{'loss': 0.2, 'accuracy': 0.7}</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">make_train_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">force</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Creates a function that executes one step of training.</span>

<span class="s2">        This method can be overridden to support custom training logic.</span>

<span class="s2">        This method is called by `Model.fit` and `Model.train_on_batch`.</span>

<span class="s2">        Typically, this method directly controls `tf.function` and</span>

<span class="s2">        `tf.distribute.Strategy` settings, and delegates the actual training</span>

<span class="s2">        logic to `Model.train_step`.</span>

<span class="s2">        This function is cached the first time `Model.fit` or</span>

<span class="s2">        `Model.train_on_batch` is called. The cache is cleared whenever</span>

<span class="s2">        `Model.compile` is called. You can skip the cache and generate again the</span>

<span class="s2">        function with `force=True`.</span>

<span class="s2">        Args:</span>

<span class="s2">          force: Whether to regenerate the train function and skip the cached</span>

<span class="s2">            function if available.</span>

<span class="s2">        Returns:</span>

<span class="s2">          Function. The function created by this method should accept a</span>

<span class="s2">          `tf.data.Iterator`, and return a `dict` containing values that will</span>

<span class="s2">          be passed to `tf.keras.Callbacks.on_train_batch_end`, such as</span>

<span class="s2">          `{&#39;loss&#39;: 0.2, &#39;accuracy&#39;: 0.7}`.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">force</span><span class="o">:</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span>

<span class="w">        </span><span class="n">def</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single training step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">            </span><span class="n">def</span><span class="w"> </span><span class="n">run_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">train_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

<span class="w">                </span><span class="c1"># Ensure counter is updated only if `train_step` succeeds.</span>

<span class="w">                </span><span class="k">with</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_minimum_control_deps</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span><span class="o">:</span>

<span class="w">                    </span><span class="n">model</span><span class="p">.</span><span class="n">_train_counter</span><span class="p">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_jit_compile</span><span class="o">:</span>

<span class="w">                </span><span class="n">run_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

<span class="w">                    </span><span class="n">run_step</span><span class="p">,</span><span class="w"> </span><span class="n">jit_compile</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"> </span><span class="n">reduce_retracing</span><span class="o">=</span><span class="no">True</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="k">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

<span class="w">            </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="k">data</span><span class="p">,))</span>

<span class="w">            </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">reduce_per_replica</span><span class="p">(</span>

<span class="w">                </span><span class="n">outputs</span><span class="p">,</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span>

<span class="w">                </span><span class="n">reduction</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">distribute_reduction_method</span><span class="p">,</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">        </span><span class="c1"># Special case if steps_per_execution is one.</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span>

<span class="w">            </span><span class="k">or</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span>

<span class="w">        </span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="n">def</span><span class="w"> </span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a training execution with a single step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span>

<span class="w">                </span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

<span class="w">                    </span><span class="n">train_function</span><span class="p">,</span><span class="w"> </span><span class="n">reduce_retracing</span><span class="o">=</span><span class="no">True</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">train_tf_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span>

<span class="w">                    </span><span class="n">lambda</span><span class="w"> </span><span class="n">it</span><span class="o">:</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="p">.</span><span class="k">schedule</span><span class="p">(</span>

<span class="w">                        </span><span class="n">train_function</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">it</span><span class="p">,)</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="k">else</span><span class="o">:</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span>

<span class="w">        </span><span class="c1"># If we&#39;re using a coordinator, use the value of</span>

<span class="w">        </span><span class="c1"># self._steps_per_execution at the time the function is</span>

<span class="w">        </span><span class="c1"># called/scheduled, and not when it is actually executed.</span>

<span class="w">        </span><span class="n">elif</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span>

<span class="w">            </span><span class="n">def</span><span class="w"> </span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">,</span><span class="w"> </span><span class="n">steps_per_execution</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a training execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">                </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">steps_per_execution</span><span class="p">)</span><span class="o">:</span>

<span class="w">                    </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span>

<span class="w">                </span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

<span class="w">                    </span><span class="n">train_function</span><span class="p">,</span><span class="w"> </span><span class="n">reduce_retracing</span><span class="o">=</span><span class="no">True</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">train_tf_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="n">it</span><span class="o">:</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="p">.</span><span class="k">schedule</span><span class="p">(</span>

<span class="w">                </span><span class="n">train_function</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">it</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="k">value</span><span class="p">())</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="k">else</span><span class="o">:</span>

<span class="w">            </span><span class="n">def</span><span class="w"> </span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a training execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">                </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="o">:</span>

<span class="w">                    </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span>

<span class="w">                </span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

<span class="w">                    </span><span class="n">train_function</span><span class="p">,</span><span class="w"> </span><span class="n">reduce_retracing</span><span class="o">=</span><span class="no">True</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">train_tf_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span>
</code></pre></div>

</details>
<h4 id="predict">predict</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Generates output predictions for the input samples.</p>
<p>Computation is done in batches. This method is designed for batch
processing of large numbers of inputs. It is not intended for use inside
of loops that iterate over your data and process small numbers of inputs
at a time.</p>
<p>For small numbers of inputs that fit in one batch,
directly use <code>__call__()</code> for faster execution, e.g.,
<code>model(x)</code>, or <code>model(x, training=False)</code> if you have layers such as
<code>tf.keras.layers.BatchNormalization</code> that behave differently during
inference. You may pair the individual model call with a <code>tf.function</code>
for additional performance inside your inner loop.
If you need access to numpy array values instead of tensors after your
model call, you can use <code>tensor.numpy()</code> to get the numpy array value of
an eager tensor.</p>
<p>Also, note the fact that test loss is not affected by
regularization layers like noise and dropout.</p>
<p>Note: See <a href="https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call">this FAQ entry</a>
for more details about the difference between <code>Model</code> methods
<code>predict()</code> and <code>__call__()</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input samples. It could be:<br>- A Numpy array (or array-like), or a list of arrays<br>  (in case the model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors<br>  (in case the model has multiple inputs).<br>- A <code>tf.data</code> dataset.<br>- A generator or <code>keras.utils.Sequence</code> instance.<br>A more detailed description of unpacking behavior for iterator<br>types (Dataset, generator, Sequence) is given in the <code>Unpacking&lt;br&gt;behavior for iterator-like inputs</code> section of <code>Model.fit</code>.</td>
<td>None</td>
</tr>
<tr>
<td>batch_size</td>
<td>None</td>
<td>Integer or <code>None</code>.<br>Number of samples per batch.<br>If unspecified, <code>batch_size</code> will default to 32.<br>Do not specify the <code>batch_size</code> if your data is in the<br>form of dataset, generators, or <code>keras.utils.Sequence</code> instances<br>(since they generate batches).</td>
<td>None</td>
</tr>
<tr>
<td>verbose</td>
<td>None</td>
<td><code>"auto"</code>, 0, 1, or 2. Verbosity mode.<br>0 = silent, 1 = progress bar, 2 = single line.<br><code>"auto"</code> defaults to 1 for most cases, and to 2 when used with<br><code>ParameterServerStrategy</code>. Note that the progress bar is not<br>particularly useful when logged to a file, so <code>verbose=2</code> is<br>recommended when not running interactively (e.g. in a production<br>environment).</td>
<td>None</td>
</tr>
<tr>
<td>steps</td>
<td>None</td>
<td>Total number of steps (batches of samples)<br>before declaring the prediction round finished.<br>Ignored with the default value of <code>None</code>. If x is a <code>tf.data</code><br>dataset and <code>steps</code> is None, <code>predict()</code> will<br>run until the input dataset is exhausted.</td>
<td>None</td>
</tr>
<tr>
<td>callbacks</td>
<td>None</td>
<td>List of <code>keras.callbacks.Callback</code> instances.<br>List of callbacks to apply during prediction.<br>See <a href="&lt;br&gt;https://www.tensorflow.org/api_docs/python/tf/keras/callbacks">callbacks</a>.</td>
<td>None</td>
</tr>
<tr>
<td>max_queue_size</td>
<td>None</td>
<td>Integer. Used for generator or<br><code>keras.utils.Sequence</code> input only. Maximum size for the<br>generator queue. If unspecified, <code>max_queue_size</code> will default<br>to 10.</td>
<td>None</td>
</tr>
<tr>
<td>workers</td>
<td>None</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code> input<br>only. Maximum number of processes to spin up when using<br>process-based threading. If unspecified, <code>workers</code> will default<br>to 1.</td>
<td>None</td>
</tr>
<tr>
<td>use_multiprocessing</td>
<td>None</td>
<td>Boolean. Used for generator or<br><code>keras.utils.Sequence</code> input only. If <code>True</code>, use process-based<br>threading. If unspecified, <code>use_multiprocessing</code> will default to<br><code>False</code>. Note that because this implementation relies on<br>multiprocessing, you should not pass non-picklable arguments to<br>the generator as they can't be passed easily to children<br>processes.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Numpy array(s) of predictions.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.predict</code> is wrapped in a <code>tf.function</code>.</td>
</tr>
<tr>
<td>ValueError</td>
<td>In case of mismatch between the provided<br>input data and the model's expectations,<br>or in case a stateful model receives a number of samples<br>that is not a multiple of the batch size.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@traceback_utils.filter_traceback</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">x</span><span class="p">,</span>

<span class="w">        </span><span class="n">batch_size</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">verbose</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>

<span class="w">        </span><span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

<span class="w">        </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="no">False</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Generates output predictions for the input samples.</span>

<span class="s2">        Computation is done in batches. This method is designed for batch</span>

<span class="s2">        processing of large numbers of inputs. It is not intended for use inside</span>

<span class="s2">        of loops that iterate over your data and process small numbers of inputs</span>

<span class="s2">        at a time.</span>

<span class="s2">        For small numbers of inputs that fit in one batch,</span>

<span class="s2">        directly use `__call__()` for faster execution, e.g.,</span>

<span class="s2">        `model(x)`, or `model(x, training=False)` if you have layers such as</span>

<span class="s2">        `tf.keras.layers.BatchNormalization` that behave differently during</span>

<span class="s2">        inference. You may pair the individual model call with a `tf.function`</span>

<span class="s2">        for additional performance inside your inner loop.</span>

<span class="s2">        If you need access to numpy array values instead of tensors after your</span>

<span class="s2">        model call, you can use `tensor.numpy()` to get the numpy array value of</span>

<span class="s2">        an eager tensor.</span>

<span class="s2">        Also, note the fact that test loss is not affected by</span>

<span class="s2">        regularization layers like noise and dropout.</span>

<span class="s2">        Note: See [this FAQ entry](</span>

<span class="s2">        https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call)</span>

<span class="s2">        for more details about the difference between `Model` methods</span>

<span class="s2">        `predict()` and `__call__()`.</span>

<span class="s2">        Args:</span>

<span class="s2">            x: Input samples. It could be:</span>

<span class="s2">              - A Numpy array (or array-like), or a list of arrays</span>

<span class="s2">                (in case the model has multiple inputs).</span>

<span class="s2">              - A TensorFlow tensor, or a list of tensors</span>

<span class="s2">                (in case the model has multiple inputs).</span>

<span class="s2">              - A `tf.data` dataset.</span>

<span class="s2">              - A generator or `keras.utils.Sequence` instance.</span>

<span class="s2">              A more detailed description of unpacking behavior for iterator</span>

<span class="s2">              types (Dataset, generator, Sequence) is given in the `Unpacking</span>

<span class="s2">              behavior for iterator-like inputs` section of `Model.fit`.</span>

<span class="s2">            batch_size: Integer or `None`.</span>

<span class="s2">                Number of samples per batch.</span>

<span class="s2">                If unspecified, `batch_size` will default to 32.</span>

<span class="s2">                Do not specify the `batch_size` if your data is in the</span>

<span class="s2">                form of dataset, generators, or `keras.utils.Sequence` instances</span>

<span class="s2">                (since they generate batches).</span>

<span class="s2">            verbose: `&quot;</span><span class="n">auto</span><span class="s2">&quot;`, 0, 1, or 2. Verbosity mode.</span>

<span class="s2">                0 = silent, 1 = progress bar, 2 = single line.</span>

<span class="s2">                `&quot;</span><span class="n">auto</span><span class="s2">&quot;` defaults to 1 for most cases, and to 2 when used with</span>

<span class="s2">                `ParameterServerStrategy`. Note that the progress bar is not</span>

<span class="s2">                particularly useful when logged to a file, so `verbose=2` is</span>

<span class="s2">                recommended when not running interactively (e.g. in a production</span>

<span class="s2">                environment).</span>

<span class="s2">            steps: Total number of steps (batches of samples)</span>

<span class="s2">                before declaring the prediction round finished.</span>

<span class="s2">                Ignored with the default value of `None`. If x is a `tf.data`</span>

<span class="s2">                dataset and `steps` is None, `predict()` will</span>

<span class="s2">                run until the input dataset is exhausted.</span>

<span class="s2">            callbacks: List of `keras.callbacks.Callback` instances.</span>

<span class="s2">                List of callbacks to apply during prediction.</span>

<span class="s2">                See [callbacks](</span>

<span class="s2">                https://www.tensorflow.org/api_docs/python/tf/keras/callbacks).</span>

<span class="s2">            max_queue_size: Integer. Used for generator or</span>

<span class="s2">                `keras.utils.Sequence` input only. Maximum size for the</span>

<span class="s2">                generator queue. If unspecified, `max_queue_size` will default</span>

<span class="s2">                to 10.</span>

<span class="s2">            workers: Integer. Used for generator or `keras.utils.Sequence` input</span>

<span class="s2">                only. Maximum number of processes to spin up when using</span>

<span class="s2">                process-based threading. If unspecified, `workers` will default</span>

<span class="s2">                to 1.</span>

<span class="s2">            use_multiprocessing: Boolean. Used for generator or</span>

<span class="s2">                `keras.utils.Sequence` input only. If `True`, use process-based</span>

<span class="s2">                threading. If unspecified, `use_multiprocessing` will default to</span>

<span class="s2">                `False`. Note that because this implementation relies on</span>

<span class="s2">                multiprocessing, you should not pass non-picklable arguments to</span>

<span class="s2">                the generator as they can&#39;t be passed easily to children</span>

<span class="s2">                processes.</span>

<span class="s2">        See the discussion of `Unpacking behavior for iterator-like inputs` for</span>

<span class="s2">        `Model.fit`. Note that Model.predict uses the same interpretation rules</span>

<span class="s2">        as `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for</span>

<span class="s2">        all three methods.</span>

<span class="s2">        Returns:</span>

<span class="s2">            Numpy array(s) of predictions.</span>

<span class="s2">        Raises:</span>

<span class="s2">            RuntimeError: If `model.predict` is wrapped in a `tf.function`.</span>

<span class="s2">            ValueError: In case of mismatch between the provided</span>

<span class="s2">                input data and the model&#39;s expectations,</span>

<span class="s2">                or in case a stateful model receives a number of samples</span>

<span class="s2">                that is not a multiple of the batch size.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">base_layer</span><span class="p">.</span><span class="n">keras_api_gauge</span><span class="p">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s2">&quot;predict&quot;</span><span class="p">).</span><span class="kt">set</span><span class="p">(</span><span class="no">True</span><span class="p">)</span>

<span class="w">        </span><span class="n">version_utils</span><span class="p">.</span><span class="n">disallow_legacy_graph</span><span class="p">(</span><span class="s2">&quot;Model&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;predict&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s2">&quot;predict&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s2">&quot;predict&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="c1"># TODO(yashkatariya): Cache model on the coordinator for faster</span>

<span class="w">        </span><span class="c1"># prediction.  If running under PSS, then swap it with OneDeviceStrategy</span>

<span class="w">        </span><span class="c1"># so that execution will run on the coordinator.</span>

<span class="w">        </span><span class="n">original_pss_strategy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">_should_use_with_coordinator</span><span class="o">:</span>

<span class="w">            </span><span class="n">original_pss_strategy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">_distribution_strategy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span>

<span class="w">        </span><span class="c1"># Cluster coordinator is set by `.fit()` and `.evaluate()` which is not</span>

<span class="w">        </span><span class="c1"># needed in `.predict()` because all the predictions happen on the</span>

<span class="w">        </span><span class="c1"># coordinator/locally.</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span>

<span class="w">        </span><span class="n">verbose</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">_get_verbosity</span><span class="p">(</span><span class="n">verbose</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">)</span>

<span class="w">        </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span>

<span class="w">            </span><span class="c1"># Creates a `tf.data.Dataset` and handles batch and epoch iteration.</span>

<span class="w">            </span><span class="n">dataset_types</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="k">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">,</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">_in_multi_worker_mode</span><span class="p">()</span>

<span class="w">                </span><span class="k">or</span><span class="w"> </span><span class="n">_is_tpu_multi_host</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">)</span>

<span class="w">            </span><span class="p">)</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">dataset_types</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">try</span><span class="o">:</span>

<span class="w">                    </span><span class="k">options</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">data</span><span class="p">.</span><span class="k">Options</span><span class="p">()</span>

<span class="w">                    </span><span class="n">data_option</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">data</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">AutoShardPolicy</span><span class="p">.</span><span class="k">DATA</span>

<span class="w">                    </span><span class="k">options</span><span class="p">.</span><span class="n">experimental_distribute</span><span class="p">.</span><span class="n">auto_shard_policy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span>

<span class="w">                        </span><span class="n">data_option</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">                    </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">.</span><span class="n">with_options</span><span class="p">(</span><span class="k">options</span><span class="p">)</span>

<span class="w">                </span><span class="k">except</span><span class="w"> </span><span class="n">ValueError</span><span class="o">:</span>

<span class="w">                    </span><span class="k">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span>

<span class="w">                        </span><span class="s2">&quot;Using Model.predict with MultiWorkerMirroredStrategy &quot;</span>

<span class="w">                        </span><span class="s2">&quot;or TPUStrategy and AutoShardPolicy.FILE might lead to &quot;</span>

<span class="w">                        </span><span class="s2">&quot;out-of-order result. Consider setting it to &quot;</span>

<span class="w">                        </span><span class="s2">&quot;AutoShardPolicy.DATA.&quot;</span><span class="p">,</span>

<span class="w">                        </span><span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">            </span><span class="n">data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">get_data_handler</span><span class="p">(</span>

<span class="w">                </span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>

<span class="w">                </span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>

<span class="w">                </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>

<span class="w">                </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

<span class="w">                </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">                </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

<span class="w">                </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

<span class="w">                </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

<span class="w">                </span><span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span>

<span class="w">                </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">,</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">            </span><span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span><span class="w"> </span><span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">callbacks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">(</span>

<span class="w">                    </span><span class="n">callbacks</span><span class="p">,</span>

<span class="w">                    </span><span class="n">add_history</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

<span class="w">                    </span><span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>

<span class="w">                    </span><span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span>

<span class="w">                    </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>

<span class="w">                    </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">                    </span><span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="p">.</span><span class="n">inferred_steps</span><span class="p">,</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">make_predict_function</span><span class="p">()</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">_predict_counter</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="w">            </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_begin</span><span class="p">()</span>

<span class="w">            </span><span class="n">batch_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span>

<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">enumerate_epochs</span><span class="p">()</span><span class="o">:</span><span class="w">  </span><span class="c1"># Single epoch.</span>

<span class="w">                </span><span class="k">with</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">catch_stop_iteration</span><span class="p">()</span><span class="o">:</span>

<span class="w">                    </span><span class="k">for</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">steps</span><span class="p">()</span><span class="o">:</span>

<span class="w">                        </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>

<span class="w">                        </span><span class="n">tmp_batch_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

<span class="w">                        </span><span class="k">if</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">should_sync</span><span class="o">:</span>

<span class="w">                            </span><span class="k">context</span><span class="p">.</span><span class="n">async_wait</span><span class="p">()</span>

<span class="w">                        </span><span class="n">batch_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span>

<span class="w">                            </span><span class="n">tmp_batch_outputs</span><span class="w">  </span><span class="c1"># No error, now safe to assign.</span>

<span class="w">                        </span><span class="p">)</span>

<span class="w">                        </span><span class="k">if</span><span class="w"> </span><span class="n">outputs</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="o">:</span>

<span class="w">                            </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span>

<span class="w">                                </span><span class="n">lambda</span><span class="w"> </span><span class="n">batch_output</span><span class="o">:</span><span class="w"> </span><span class="err">[</span><span class="n">batch_output</span><span class="err">]</span><span class="p">,</span>

<span class="w">                                </span><span class="n">batch_outputs</span><span class="p">,</span>

<span class="w">                            </span><span class="p">)</span>

<span class="w">                        </span><span class="k">else</span><span class="o">:</span>

<span class="w">                            </span><span class="n">tf</span><span class="p">.</span><span class="n">__internal__</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure_up_to</span><span class="p">(</span>

<span class="w">                                </span><span class="n">batch_outputs</span><span class="p">,</span>

<span class="w">                                </span><span class="n">lambda</span><span class="w"> </span><span class="n">output</span><span class="p">,</span><span class="w"> </span><span class="n">batch_output</span><span class="o">:</span><span class="w"> </span><span class="n">output</span><span class="p">.</span><span class="n">append</span><span class="p">(</span>

<span class="w">                                    </span><span class="n">batch_output</span>

<span class="w">                                </span><span class="p">),</span>

<span class="w">                                </span><span class="n">outputs</span><span class="p">,</span>

<span class="w">                                </span><span class="n">batch_outputs</span><span class="p">,</span>

<span class="w">                            </span><span class="p">)</span>

<span class="w">                        </span><span class="n">end_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">step_increment</span>

<span class="w">                        </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_batch_end</span><span class="p">(</span>

<span class="w">                            </span><span class="n">end_step</span><span class="p">,</span><span class="w"> </span><span class="err">{</span><span class="s2">&quot;outputs&quot;</span><span class="o">:</span><span class="w"> </span><span class="n">batch_outputs</span><span class="err">}</span>

<span class="w">                        </span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">batch_outputs</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="o">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                    </span><span class="s2">&quot;Unexpected result of `predict_function` &quot;</span>

<span class="w">                    </span><span class="s2">&quot;(Empty batch_outputs). Please use &quot;</span>

<span class="w">                    </span><span class="s2">&quot;`Model.compile(..., run_eagerly=True)`, or &quot;</span>

<span class="w">                    </span><span class="s2">&quot;`tf.config.run_functions_eagerly(True)` for more &quot;</span>

<span class="w">                    </span><span class="s2">&quot;information of where went wrong, or file a &quot;</span>

<span class="w">                    </span><span class="s2">&quot;issue/bug to `tf.keras`.&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_end</span><span class="p">()</span>

<span class="w">        </span><span class="n">all_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">__internal__</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure_up_to</span><span class="p">(</span>

<span class="w">            </span><span class="n">batch_outputs</span><span class="p">,</span><span class="w"> </span><span class="n">potentially_ragged_concat</span><span class="p">,</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">        </span><span class="p">)</span>

<span class="w">        </span><span class="c1"># If originally PSS strategy was used, then replace it back since</span>

<span class="w">        </span><span class="c1"># predict is running under `OneDeviceStrategy` after the swap and once</span>

<span class="w">        </span><span class="c1"># its done we need to replace it back to PSS again.</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">original_pss_strategy</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="o">:</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">_distribution_strategy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">original_pss_strategy</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="n">all_outputs</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="predict_generator">predict_generator</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_generator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>

<p>Generates predictions for the input samples from a data generator.</p>
<p>DEPRECATED:
  <code>Model.predict</code> now supports generators, so there is no longer any
  need to use this endpoint.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_generate_docs</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">predict_generator</span><span class="p">(</span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">generator</span><span class="p">,</span>

<span class="w">        </span><span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

<span class="w">        </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="k">False</span><span class="p">,</span>

<span class="w">        </span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Generates predictions for the input samples from a data generator.</span>

<span class="ss">        DEPRECATED:</span>

<span class="ss">          `Model.predict` now supports generators, so there is no longer any</span>

<span class="ss">          need to use this endpoint.</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span>

<span class="w">            </span><span class="ss">&quot;`Model.predict_generator` is deprecated and &quot;</span>

<span class="w">            </span><span class="ss">&quot;will be removed in a future version. &quot;</span>

<span class="w">            </span><span class="ss">&quot;Please use `Model.predict`, which supports generators.&quot;</span><span class="p">,</span>

<span class="w">            </span><span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>

<span class="w">        </span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span>

<span class="w">            </span><span class="n">generator</span><span class="p">,</span>

<span class="w">            </span><span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>

<span class="w">            </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

<span class="w">            </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

<span class="w">            </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

<span class="w">            </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>

<span class="w">            </span><span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="predict_on_batch">predict_on_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns predictions for a single batch of samples.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input data. It could be:<br>- A Numpy array (or array-like), or a list of arrays (in case the<br>    model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors (in case the model has<br>    multiple inputs).</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Numpy array(s) of predictions.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.predict_on_batch</code> is wrapped in a<br><code>tf.function</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">def</span><span class="w"> </span><span class="nv">predict_on_batch</span><span class="ss">(</span><span class="nv">self</span>,<span class="w"> </span><span class="nv">x</span><span class="ss">)</span>:

<span class="w">        </span><span class="s2">&quot;&quot;</span><span class="err">&quot;Returns predictions for a single batch of samples.</span>

<span class="err">        Args:</span>

<span class="err">            x: Input data. It could be:</span>

<span class="err">              - A Numpy array (or array-like), or a list of arrays (in case the</span>

<span class="err">                  model has multiple inputs).</span>

<span class="err">              - A TensorFlow tensor, or a list of tensors (in case the model has</span>

<span class="err">                  multiple inputs).</span>

<span class="err">        Returns:</span>

<span class="err">            Numpy array(s) of predictions.</span>

<span class="err">        Raises:</span>

<span class="err">            RuntimeError: If `model.predict_on_batch` is wrapped in a</span>

<span class="err">              `tf.function`.</span>

<span class="w">        </span><span class="s2">&quot;&quot;</span><span class="err">&quot;</span>

<span class="w">        </span><span class="nv">self</span>.<span class="nv">_check_call_args</span><span class="ss">(</span><span class="s2">&quot;predict_on_batch&quot;</span><span class="ss">)</span>

<span class="w">        </span><span class="nv">_disallow_inside_tf_function</span><span class="ss">(</span><span class="s2">&quot;predict_on_batch&quot;</span><span class="ss">)</span>

<span class="w">        </span><span class="nv">with</span><span class="w"> </span><span class="nv">self</span>.<span class="nv">distribute_strategy</span>.<span class="nv">scope</span><span class="ss">()</span>:

<span class="w">            </span><span class="nv">iterator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">data_adapter</span>.<span class="nv">single_batch_iterator</span><span class="ss">(</span>

<span class="w">                </span><span class="nv">self</span>.<span class="nv">distribute_strategy</span>,<span class="w"> </span><span class="nv">x</span>

<span class="w">            </span><span class="ss">)</span>

<span class="w">            </span><span class="nv">self</span>.<span class="nv">predict_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">self</span>.<span class="nv">make_predict_function</span><span class="ss">()</span>

<span class="w">            </span><span class="nv">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">self</span>.<span class="nv">predict_function</span><span class="ss">(</span><span class="nv">iterator</span><span class="ss">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="nv">tf_utils</span>.<span class="nv">sync_to_numpy_or_python_type</span><span class="ss">(</span><span class="nv">outputs</span><span class="ss">)</span>
</code></pre></div>

</details>
<h4 id="predict_step">predict_step</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span>
<span class="p">)</span>
</code></pre></div>

<p>The logic for one inference step.</p>
<p>This method can be overridden to support custom inference logic.
This method is called by <code>Model.make_predict_function</code>.</p>
<p>This method should contain the mathematical logic for one step of
inference.  This typically includes the forward pass.</p>
<p>Configuration details for <em>how</em> this logic is run (e.g. <code>tf.function</code>
and <code>tf.distribute.Strategy</code> settings), should be left to
<code>Model.make_predict_function</code>, which can also be overridden.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>data</td>
<td>None</td>
<td>A nested structure of <code>Tensor</code>s.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>The result of one inference step, typically the output of calling the<br><code>Model</code> on data.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">predict_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">data</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">The logic for one inference step.</span>

<span class="s2">        This method can be overridden to support custom inference logic.</span>

<span class="s2">        This method is called by `Model.make_predict_function`.</span>

<span class="s2">        This method should contain the mathematical logic for one step of</span>

<span class="s2">        inference.  This typically includes the forward pass.</span>

<span class="s2">        Configuration details for *how* this logic is run (e.g. `tf.function`</span>

<span class="s2">        and `tf.distribute.Strategy` settings), should be left to</span>

<span class="s2">        `Model.make_predict_function`, which can also be overridden.</span>

<span class="s2">        Args:</span>

<span class="s2">          data: A nested structure of `Tensor`s.</span>

<span class="s2">        Returns:</span>

<span class="s2">          The result of one inference step, typically the output of calling the</span>

<span class="s2">          `Model` on data.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">_</span><span class="p">,</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">training</span><span class="o">=</span><span class="no">False</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="reset_metrics">reset_metrics</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">reset_metrics</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Resets the state of all the metrics in the model.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">def</span><span class="w"> </span><span class="nv">reset_metrics</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span>:

<span class="w">        </span><span class="s2">&quot;&quot;</span><span class="err">&quot;Resets the state of all the metrics in the model.</span>

<span class="err">        Examples:</span>

<span class="err">        &gt;&gt;&gt; inputs = tf.keras.layers.Input(shape=(3,))</span>

<span class="err">        &gt;&gt;&gt; outputs = tf.keras.layers.Dense(2)(inputs)</span>

<span class="err">        &gt;&gt;&gt; model = tf.keras.models.Model(inputs=inputs, outputs=outputs)</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="nv">model</span>.<span class="nv">compile</span><span class="ss">(</span><span class="nv">optimizer</span><span class="o">=</span><span class="s2">&quot;Adam&quot;</span>,<span class="w"> </span><span class="nv">loss</span><span class="o">=</span><span class="s2">&quot;mse&quot;</span>,<span class="w"> </span><span class="nv">metrics</span><span class="o">=</span>[<span class="s2">&quot;mae&quot;</span>]<span class="ss">)</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="nv">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">np</span>.<span class="k">random</span>.<span class="k">random</span><span class="ss">((</span><span class="mi">2</span>,<span class="w"> </span><span class="mi">3</span><span class="ss">))</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="nv">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">np</span>.<span class="k">random</span>.<span class="nv">randint</span><span class="ss">(</span><span class="mi">0</span>,<span class="w"> </span><span class="mi">2</span>,<span class="w"> </span><span class="ss">(</span><span class="mi">2</span>,<span class="w"> </span><span class="mi">2</span><span class="ss">))</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="nv">_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">model</span>.<span class="nv">fit</span><span class="ss">(</span><span class="nv">x</span>,<span class="w"> </span><span class="nv">y</span>,<span class="w"> </span><span class="nv">verbose</span><span class="o">=</span><span class="mi">0</span><span class="ss">)</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="nv">assert</span><span class="w"> </span><span class="nv">all</span><span class="ss">(</span><span class="nv">float</span><span class="ss">(</span><span class="nv">m</span>.<span class="nb">result</span><span class="ss">())</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nv">m</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">model</span>.<span class="nv">metrics</span><span class="ss">)</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="nv">model</span>.<span class="nv">reset_metrics</span><span class="ss">()</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="nv">assert</span><span class="w"> </span><span class="nv">all</span><span class="ss">(</span><span class="nv">float</span><span class="ss">(</span><span class="nv">m</span>.<span class="nb">result</span><span class="ss">())</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nv">m</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">model</span>.<span class="nv">metrics</span><span class="ss">)</span>

<span class="w">        </span><span class="s2">&quot;&quot;</span><span class="err">&quot;</span>

<span class="err">        for m in self.metrics:</span>

<span class="err">            m.reset_state()</span>
</code></pre></div>

</details>
<h4 id="reset_states">reset_states</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">reset_states</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">def</span><span class="w"> </span><span class="nv">reset_states</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span>:

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="nv">layer</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">self</span>.<span class="nv">layers</span>:

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="nv">hasattr</span><span class="ss">(</span><span class="nv">layer</span>,<span class="w"> </span><span class="s2">&quot;reset_states&quot;</span><span class="ss">)</span><span class="w"> </span><span class="nv">and</span><span class="w"> </span><span class="nv">getattr</span><span class="ss">(</span>

<span class="w">                </span><span class="nv">layer</span>,<span class="w"> </span><span class="s2">&quot;stateful&quot;</span>,<span class="w"> </span><span class="nv">False</span>

<span class="w">            </span><span class="ss">)</span>:

<span class="w">                </span><span class="nv">layer</span>.<span class="nv">reset_states</span><span class="ss">()</span>
</code></pre></div>

</details>
<h4 id="save">save</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filepath</span><span class="p">,</span>
    <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">include_optimizer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">save_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">signatures</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">save_traces</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</code></pre></div>

<p>Saves the model to Tensorflow SavedModel or a single HDF5 file.</p>
<p>Please see <code>tf.keras.models.save_model</code> or the
<a href="https://keras.io/guides/serialization_and_saving/">Serialization and Saving guide</a>
for details.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>filepath</td>
<td>None</td>
<td>String, PathLike, path to SavedModel or H5 file to save<br>the model.</td>
<td>None</td>
</tr>
<tr>
<td>overwrite</td>
<td>None</td>
<td>Whether to silently overwrite any existing file at the<br>target location, or provide the user with a manual prompt.</td>
<td>None</td>
</tr>
<tr>
<td>include_optimizer</td>
<td>None</td>
<td>If True, save optimizer's state together.</td>
<td>None</td>
</tr>
<tr>
<td>save_format</td>
<td>None</td>
<td>Either <code>'tf'</code> or <code>'h5'</code>, indicating whether to save the<br>model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF<br>2.X, and 'h5' in TF 1.X.</td>
<td>None</td>
</tr>
<tr>
<td>signatures</td>
<td>None</td>
<td>Signatures to save with the SavedModel. Applicable to<br>the 'tf' format only. Please see the <code>signatures</code> argument in<br><code>tf.saved_model.save</code> for details.</td>
<td>None</td>
</tr>
<tr>
<td>options</td>
<td>None</td>
<td>(only applies to SavedModel format)<br><code>tf.saved_model.SaveOptions</code> object that specifies options for<br>saving to SavedModel.</td>
<td>None</td>
</tr>
<tr>
<td>save_traces</td>
<td>None</td>
<td>(only applies to SavedModel format) When enabled, the<br>SavedModel will store the function traces for each layer. This<br>can be disabled, so that only the configs of each layer are<br>stored.  Defaults to <code>True</code>. Disabling this will decrease<br>serialization time and reduce file size, but it requires that<br>all custom layers/models implement a <code>get_config()</code> method.</td>
<td>None</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@traceback_utils.filter_traceback</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">save</span><span class="p">(</span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">filepath</span><span class="p">,</span>

<span class="w">        </span><span class="n">overwrite</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

<span class="w">        </span><span class="n">include_optimizer</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

<span class="w">        </span><span class="n">save_format</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">signatures</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="k">options</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">save_traces</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Saves the model to Tensorflow SavedModel or a single HDF5 file.</span>

<span class="s2">        Please see `tf.keras.models.save_model` or the</span>

<span class="s2">        [Serialization and Saving guide](</span>

<span class="s2">        https://keras.io/guides/serialization_and_saving/)</span>

<span class="s2">        for details.</span>

<span class="s2">        Args:</span>

<span class="s2">            filepath: String, PathLike, path to SavedModel or H5 file to save</span>

<span class="s2">                the model.</span>

<span class="s2">            overwrite: Whether to silently overwrite any existing file at the</span>

<span class="s2">                target location, or provide the user with a manual prompt.</span>

<span class="s2">            include_optimizer: If True, save optimizer&#39;s state together.</span>

<span class="s2">            save_format: Either `&#39;tf&#39;` or `&#39;h5&#39;`, indicating whether to save the</span>

<span class="s2">                model to Tensorflow SavedModel or HDF5. Defaults to &#39;tf&#39; in TF</span>

<span class="s2">                2.X, and &#39;h5&#39; in TF 1.X.</span>

<span class="s2">            signatures: Signatures to save with the SavedModel. Applicable to</span>

<span class="s2">                the &#39;tf&#39; format only. Please see the `signatures` argument in</span>

<span class="s2">                `tf.saved_model.save` for details.</span>

<span class="s2">            options: (only applies to SavedModel format)</span>

<span class="s2">                `tf.saved_model.SaveOptions` object that specifies options for</span>

<span class="s2">                saving to SavedModel.</span>

<span class="s2">            save_traces: (only applies to SavedModel format) When enabled, the</span>

<span class="s2">                SavedModel will store the function traces for each layer. This</span>

<span class="s2">                can be disabled, so that only the configs of each layer are</span>

<span class="s2">                stored.  Defaults to `True`. Disabling this will decrease</span>

<span class="s2">                serialization time and reduce file size, but it requires that</span>

<span class="s2">                all custom layers/models implement a `get_config()` method.</span>

<span class="s2">        Example:</span>

<span class="s2">        ```python</span>

<span class="s2">        from keras.models import load_model</span>

<span class="s2">        model.save(&#39;my_model.h5&#39;)  # creates a HDF5 file &#39;my_model.h5&#39;</span>

<span class="s2">        del model  # deletes the existing model</span>

<span class="s2">        # returns a compiled model</span>

<span class="s2">        # identical to the previous one</span>

<span class="s2">        model = load_model(&#39;my_model.h5&#39;)</span>

<span class="s2">        ```</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">save</span><span class="p">.</span><span class="n">save_model</span><span class="p">(</span>

<span class="w">            </span><span class="n">self</span><span class="p">,</span>

<span class="w">            </span><span class="n">filepath</span><span class="p">,</span>

<span class="w">            </span><span class="n">overwrite</span><span class="p">,</span>

<span class="w">            </span><span class="n">include_optimizer</span><span class="p">,</span>

<span class="w">            </span><span class="n">save_format</span><span class="p">,</span>

<span class="w">            </span><span class="n">signatures</span><span class="p">,</span>

<span class="w">            </span><span class="k">options</span><span class="p">,</span>

<span class="w">            </span><span class="n">save_traces</span><span class="p">,</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="save_spec">save_spec</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save_spec</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">dynamic_batch</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns the <code>tf.TensorSpec</code> of call inputs as a tuple <code>(args, kwargs)</code>.</p>
<p>This value is automatically defined after calling the model for the
first time. Afterwards, you can use it when exporting the model for
serving:</p>
<div class="codehilite"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

<span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">serve</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
  <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
  <span class="c1"># Apply postprocessing steps, or add additional outputs.</span>
  <span class="o">...</span>
  <span class="k">return</span> <span class="n">outputs</span>

<span class="c1"># arg_specs is `[tf.TensorSpec(...), ...]`. kwarg_specs, in this</span>
<span class="c1"># example, is an empty dict since functional models do not use keyword</span>
<span class="c1"># arguments.</span>
<span class="n">arg_specs</span><span class="p">,</span> <span class="n">kwarg_specs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">save_spec</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">signatures</span><span class="o">=</span><span class="p">{</span>
  <span class="s1">&#39;serving_default&#39;</span><span class="p">:</span> <span class="n">serve</span><span class="o">.</span><span class="n">get_concrete_function</span><span class="p">(</span><span class="o">*</span><span class="n">arg_specs</span><span class="p">,</span>
                                                 <span class="o">**</span><span class="n">kwarg_specs</span><span class="p">)</span>
<span class="p">})</span>
</code></pre></div>

<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>dynamic_batch</td>
<td>None</td>
<td>Whether to set the batch sizes of all the returned<br><code>tf.TensorSpec</code> to <code>None</code>. (Note that when defining functional or<br>Sequential models with <code>tf.keras.Input([...], batch_size=X)</code>, the<br>batch size will always be preserved). Defaults to <code>True</code>.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>If the model inputs are defined, returns a tuple <code>(args, kwargs)</code>. All<br>elements in <code>args</code> and <code>kwargs</code> are <code>tf.TensorSpec</code>.<br>If the model inputs are not defined, returns <code>None</code>.<br>The model inputs are automatically set when calling the model,<br><code>model.fit</code>, <code>model.evaluate</code> or <code>model.predict</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">save_spec</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">dynamic_batch</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns the `tf.TensorSpec` of call inputs as a tuple `(args, kwargs)`.</span>

<span class="s2">        This value is automatically defined after calling the model for the</span>

<span class="s2">        first time. Afterwards, you can use it when exporting the model for</span>

<span class="s2">        serving:</span>

<span class="s2">        ```python</span>

<span class="s2">        model = tf.keras.Model(...)</span>

<span class="s2">        @tf.function</span>

<span class="s2">        def serve(*args, **kwargs):</span>

<span class="s2">          outputs = model(*args, **kwargs)</span>

<span class="s2">          # Apply postprocessing steps, or add additional outputs.</span>

<span class="s2">          ...</span>

<span class="s2">          return outputs</span>

<span class="s2">        # arg_specs is `[tf.TensorSpec(...), ...]`. kwarg_specs, in this</span>

<span class="s2">        # example, is an empty dict since functional models do not use keyword</span>

<span class="s2">        # arguments.</span>

<span class="s2">        arg_specs, kwarg_specs = model.save_spec()</span>

<span class="s2">        model.save(path, signatures={</span>

<span class="s2">          &#39;serving_default&#39;: serve.get_concrete_function(*arg_specs,</span>

<span class="s2">                                                         **kwarg_specs)</span>

<span class="s2">        })</span>

<span class="s2">        ```</span>

<span class="s2">        Args:</span>

<span class="s2">          dynamic_batch: Whether to set the batch sizes of all the returned</span>

<span class="s2">            `tf.TensorSpec` to `None`. (Note that when defining functional or</span>

<span class="s2">            Sequential models with `tf.keras.Input([...], batch_size=X)`, the</span>

<span class="s2">            batch size will always be preserved). Defaults to `True`.</span>

<span class="s2">        Returns:</span>

<span class="s2">          If the model inputs are defined, returns a tuple `(args, kwargs)`. All</span>

<span class="s2">          elements in `args` and `kwargs` are `tf.TensorSpec`.</span>

<span class="s2">          If the model inputs are not defined, returns `None`.</span>

<span class="s2">          The model inputs are automatically set when calling the model,</span>

<span class="s2">          `model.fit`, `model.evaluate` or `model.predict`.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_save_spec</span><span class="p">(</span><span class="n">dynamic_batch</span><span class="p">,</span><span class="w"> </span><span class="n">inputs_only</span><span class="o">=</span><span class="no">False</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="save_weights">save_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save_weights</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filepath</span><span class="p">,</span>
    <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">save_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Saves all layer weights.</p>
<p>Either saves in HDF5 or in TensorFlow format based on the <code>save_format</code>
argument.</p>
<p>When saving in HDF5 format, the weight file has:
  - <code>layer_names</code> (attribute), a list of strings
      (ordered names of model layers).
  - For every layer, a <code>group</code> named <code>layer.name</code>
      - For every such layer group, a group attribute <code>weight_names</code>,
          a list of strings
          (ordered names of weights tensor of the layer).
      - For every weight in the layer, a dataset
          storing the weight value, named after the weight tensor.</p>
<p>When saving in TensorFlow format, all objects referenced by the network
are saved in the same format as <code>tf.train.Checkpoint</code>, including any
<code>Layer</code> instances or <code>Optimizer</code> instances assigned to object
attributes. For networks constructed from inputs and outputs using
<code>tf.keras.Model(inputs, outputs)</code>, <code>Layer</code> instances used by the network
are tracked/saved automatically. For user-defined classes which inherit
from <code>tf.keras.Model</code>, <code>Layer</code> instances must be assigned to object
attributes, typically in the constructor. See the documentation of
<code>tf.train.Checkpoint</code> and <code>tf.keras.Model</code> for details.</p>
<p>While the formats are the same, do not mix <code>save_weights</code> and
<code>tf.train.Checkpoint</code>. Checkpoints saved by <code>Model.save_weights</code> should
be loaded using <code>Model.load_weights</code>. Checkpoints saved using
<code>tf.train.Checkpoint.save</code> should be restored using the corresponding
<code>tf.train.Checkpoint.restore</code>. Prefer <code>tf.train.Checkpoint</code> over
<code>save_weights</code> for training checkpoints.</p>
<p>The TensorFlow format matches objects and variables by starting at a
root object, <code>self</code> for <code>save_weights</code>, and greedily matching attribute
names. For <code>Model.save</code> this is the <code>Model</code>, and for <code>Checkpoint.save</code>
this is the <code>Checkpoint</code> even if the <code>Checkpoint</code> has a model attached.
This means saving a <code>tf.keras.Model</code> using <code>save_weights</code> and loading
into a <code>tf.train.Checkpoint</code> with a <code>Model</code> attached (or vice versa)
will not match the <code>Model</code>'s variables. See the
<a href="https://www.tensorflow.org/guide/checkpoint">guide to training checkpoints</a> for details on
the TensorFlow format.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>filepath</td>
<td>None</td>
<td>String or PathLike, path to the file to save the weights<br>to. When saving in TensorFlow format, this is the prefix used<br>for checkpoint files (multiple files are generated). Note that<br>the '.h5' suffix causes weights to be saved in HDF5 format.</td>
<td>None</td>
</tr>
<tr>
<td>overwrite</td>
<td>None</td>
<td>Whether to silently overwrite any existing file at the<br>target location, or provide the user with a manual prompt.</td>
<td>None</td>
</tr>
<tr>
<td>save_format</td>
<td>None</td>
<td>Either 'tf' or 'h5'. A <code>filepath</code> ending in '.h5' or<br>'.keras' will default to HDF5 if <code>save_format</code> is <code>None</code>.<br>Otherwise <code>None</code> defaults to 'tf'.</td>
<td>None</td>
</tr>
<tr>
<td>options</td>
<td>None</td>
<td>Optional <code>tf.train.CheckpointOptions</code> object that specifies<br>options for saving weights.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ImportError</td>
<td>If <code>h5py</code> is not available when attempting to save in<br>HDF5 format.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="err">@</span><span class="n">traceback_utils</span><span class="o">.</span><span class="n">filter_traceback</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">save_weights</span><span class="p">(</span>

<span class="w">        </span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="n">overwrite</span><span class="o">=</span><span class="n">True</span><span class="p">,</span><span class="w"> </span><span class="n">save_format</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"> </span><span class="n">options</span><span class="o">=</span><span class="n">None</span>

<span class="w">    </span><span class="p">):</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;Saves all layer weights.</span>

<span class="sd">        Either saves in HDF5 or in TensorFlow format based on the `save_format`</span>

<span class="sd">        argument.</span>

<span class="sd">        When saving in HDF5 format, the weight file has:</span>

<span class="sd">          - `layer_names` (attribute), a list of strings</span>

<span class="sd">              (ordered names of model layers).</span>

<span class="sd">          - For every layer, a `group` named `layer.name`</span>

<span class="sd">              - For every such layer group, a group attribute `weight_names`,</span>

<span class="sd">                  a list of strings</span>

<span class="sd">                  (ordered names of weights tensor of the layer).</span>

<span class="sd">              - For every weight in the layer, a dataset</span>

<span class="sd">                  storing the weight value, named after the weight tensor.</span>

<span class="sd">        When saving in TensorFlow format, all objects referenced by the network</span>

<span class="sd">        are saved in the same format as `tf.train.Checkpoint`, including any</span>

<span class="sd">        `Layer` instances or `Optimizer` instances assigned to object</span>

<span class="sd">        attributes. For networks constructed from inputs and outputs using</span>

<span class="sd">        `tf.keras.Model(inputs, outputs)`, `Layer` instances used by the network</span>

<span class="sd">        are tracked/saved automatically. For user-defined classes which inherit</span>

<span class="sd">        from `tf.keras.Model`, `Layer` instances must be assigned to object</span>

<span class="sd">        attributes, typically in the constructor. See the documentation of</span>

<span class="sd">        `tf.train.Checkpoint` and `tf.keras.Model` for details.</span>

<span class="sd">        While the formats are the same, do not mix `save_weights` and</span>

<span class="sd">        `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should</span>

<span class="sd">        be loaded using `Model.load_weights`. Checkpoints saved using</span>

<span class="sd">        `tf.train.Checkpoint.save` should be restored using the corresponding</span>

<span class="sd">        `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over</span>

<span class="sd">        `save_weights` for training checkpoints.</span>

<span class="sd">        The TensorFlow format matches objects and variables by starting at a</span>

<span class="sd">        root object, `self` for `save_weights`, and greedily matching attribute</span>

<span class="sd">        names. For `Model.save` this is the `Model`, and for `Checkpoint.save`</span>

<span class="sd">        this is the `Checkpoint` even if the `Checkpoint` has a model attached.</span>

<span class="sd">        This means saving a `tf.keras.Model` using `save_weights` and loading</span>

<span class="sd">        into a `tf.train.Checkpoint` with a `Model` attached (or vice versa)</span>

<span class="sd">        will not match the `Model`&#39;s variables. See the</span>

<span class="sd">        [guide to training checkpoints](</span>

<span class="sd">        https://www.tensorflow.org/guide/checkpoint) for details on</span>

<span class="sd">        the TensorFlow format.</span>

<span class="sd">        Args:</span>

<span class="sd">            filepath: String or PathLike, path to the file to save the weights</span>

<span class="sd">                to. When saving in TensorFlow format, this is the prefix used</span>

<span class="sd">                for checkpoint files (multiple files are generated). Note that</span>

<span class="sd">                the &#39;.h5&#39; suffix causes weights to be saved in HDF5 format.</span>

<span class="sd">            overwrite: Whether to silently overwrite any existing file at the</span>

<span class="sd">                target location, or provide the user with a manual prompt.</span>

<span class="sd">            save_format: Either &#39;tf&#39; or &#39;h5&#39;. A `filepath` ending in &#39;.h5&#39; or</span>

<span class="sd">                &#39;.keras&#39; will default to HDF5 if `save_format` is `None`.</span>

<span class="sd">                Otherwise `None` defaults to &#39;tf&#39;.</span>

<span class="sd">            options: Optional `tf.train.CheckpointOptions` object that specifies</span>

<span class="sd">                options for saving weights.</span>

<span class="sd">        Raises:</span>

<span class="sd">            ImportError: If `h5py` is not available when attempting to save in</span>

<span class="sd">                HDF5 format.</span>

<span class="sd">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">_assert_weights_created</span><span class="p">()</span>

<span class="w">        </span><span class="n">filepath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">io_utils</span><span class="o">.</span><span class="n">path_to_string</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>

<span class="w">        </span><span class="n">filepath_is_h5</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">saving_utils</span><span class="o">.</span><span class="n">is_hdf5_filepath</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">filepath_is_h5</span><span class="p">:</span>

<span class="w">                </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;h5&quot;</span>

<span class="w">            </span><span class="k">else</span><span class="p">:</span>

<span class="w">                </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;tf&quot;</span>

<span class="w">        </span><span class="k">else</span><span class="p">:</span>

<span class="w">            </span><span class="n">user_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">save_format</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">user_format</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="p">(</span><span class="s2">&quot;tensorflow&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;tf&quot;</span><span class="p">):</span>

<span class="w">                </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;tf&quot;</span>

<span class="w">            </span><span class="k">elif</span><span class="w"> </span><span class="n">user_format</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="p">(</span><span class="s2">&quot;hdf5&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;h5&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;keras&quot;</span><span class="p">):</span>

<span class="w">                </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;h5&quot;</span>

<span class="w">            </span><span class="k">else</span><span class="p">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                    </span><span class="n">f</span><span class="s2">&quot;Unknown format. Received: `save_format`={save_format}. &quot;</span>

<span class="w">                    </span><span class="s1">&#39;Was expecting one of {&quot;tf&quot;, &quot;h5&quot;}.&#39;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">&quot;tf&quot;</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">filepath_is_h5</span><span class="p">:</span>

<span class="w">            </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                </span><span class="s1">&#39;save_weights got save_format=&quot;tf&quot;/&quot;tensorflow&quot;, but the &#39;</span>

<span class="w">                </span><span class="n">f</span><span class="s2">&quot;filepath ({filepath}) looks like an HDF5 file. &quot;</span>

<span class="w">                </span><span class="s1">&#39;Omit the &quot;.h5&quot;/&quot;.keras&quot; when saving in TensorFlow format.&#39;</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">&quot;h5&quot;</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">h5py</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">            </span><span class="n">raise</span><span class="w"> </span><span class="n">ImportError</span><span class="p">(</span>

<span class="w">                </span><span class="s2">&quot;`save_weights` requires h5py when saving in hdf5, but h5py is &quot;</span>

<span class="w">                </span><span class="s2">&quot;not available. Try installing h5py package.&quot;</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">&quot;tf&quot;</span><span class="p">:</span>

<span class="w">            </span><span class="n">check_filepath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">filepath</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s2">&quot;.index&quot;</span>

<span class="w">        </span><span class="k">else</span><span class="p">:</span>

<span class="w">            </span><span class="n">check_filepath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">filepath</span>

<span class="w">        </span><span class="c1"># If file exists and should not be overwritten:</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">overwrite</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">check_filepath</span><span class="p">):</span>

<span class="w">            </span><span class="n">proceed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">io_utils</span><span class="o">.</span><span class="n">ask_to_proceed_with_overwrite</span><span class="p">(</span><span class="n">check_filepath</span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">proceed</span><span class="p">:</span>

<span class="w">                </span><span class="k">return</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">&quot;h5&quot;</span><span class="p">:</span>

<span class="w">            </span><span class="n">with</span><span class="w"> </span><span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;w&quot;</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">f</span><span class="p">:</span>

<span class="w">                </span><span class="n">hdf5_format</span><span class="o">.</span><span class="n">save_weights_to_hdf5_group</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="p">)</span>

<span class="w">        </span><span class="k">else</span><span class="p">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>

<span class="w">                </span><span class="c1"># Call `get_session` to initialize any uninitialized variables.</span>

<span class="w">                </span><span class="n">backend</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">_checkpoint</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">)</span>

<span class="w">            </span><span class="c1"># Record this checkpoint so it&#39;s visible from</span>

<span class="w">            </span><span class="c1"># tf.train.latest_checkpoint.</span>

<span class="w">            </span><span class="n">tf</span><span class="o">.</span><span class="n">__internal__</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">update_checkpoint_state</span><span class="p">(</span>

<span class="w">                </span><span class="n">save_dir</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">filepath</span><span class="p">),</span>

<span class="w">                </span><span class="n">model_checkpoint_path</span><span class="o">=</span><span class="n">filepath</span><span class="p">,</span>

<span class="w">                </span><span class="n">save_relative_paths</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

<span class="w">                </span><span class="n">all_model_checkpoint_paths</span><span class="o">=</span><span class="p">[</span><span class="n">filepath</span><span class="p">],</span>

<span class="w">            </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="set_weights">set_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">set_weights</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">weights</span>
<span class="p">)</span>
</code></pre></div>

<p>Sets the weights of the layer, from NumPy arrays.</p>
<p>The weights of a layer represent the state of the layer. This function
sets the weight values from numpy arrays. The weight values should be
passed in the order they are created by the layer. Note that the layer's
weights must be instantiated before calling this function, by calling
the layer.</p>
<p>For example, a <code>Dense</code> layer returns a list of two values: the kernel
matrix and the bias vector. These can be used to set the weights of
another <code>Dense</code> layer:</p>
<blockquote>
<blockquote>
<blockquote>
<p>layer_a = tf.keras.layers.Dense(1,
...   kernel_initializer=tf.constant_initializer(1.))
a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))
layer_a.get_weights()
[array([[1.],
       [1.],
       [1.]], dtype=float32), array([0.], dtype=float32)]
layer_b = tf.keras.layers.Dense(1,
...   kernel_initializer=tf.constant_initializer(2.))
b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))
layer_b.get_weights()
[array([[2.],
       [2.],
       [2.]], dtype=float32), array([0.], dtype=float32)]
layer_b.set_weights(layer_a.get_weights())
layer_b.get_weights()
[array([[1.],
       [1.],
       [1.]], dtype=float32), array([0.], dtype=float32)]</p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>weights</td>
<td>None</td>
<td>a list of NumPy arrays. The number<br>of arrays and their shape must match<br>number of the dimensions of the weights<br>of the layer (i.e. it should match the<br>output of <code>get_weights</code>).</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>If the provided weights list does not match the<br>layer's specifications.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">set_weights</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span><span class="w"> </span><span class="n">weights</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s">&quot;&quot;&quot;Sets the weights of the layer, from NumPy arrays.</span>

<span class="w">        </span><span class="n">The</span><span class="w"> </span><span class="n">weights</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="n">represent</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">state</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">layer</span><span class="p">.</span><span class="w"> </span><span class="n">This</span><span class="w"> </span><span class="n">function</span>

<span class="w">        </span><span class="n">sets</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">weight</span><span class="w"> </span><span class="n">values</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="n">numpy</span><span class="w"> </span><span class="n">arrays</span><span class="p">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">weight</span><span class="w"> </span><span class="n">values</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">be</span>

<span class="w">        </span><span class="n">passed</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">order</span><span class="w"> </span><span class="n">they</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">created</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">layer</span><span class="p">.</span><span class="w"> </span><span class="n">Note</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">layer</span><span class="err">&#39;</span><span class="n">s</span>

<span class="w">        </span><span class="n">weights</span><span class="w"> </span><span class="n">must</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">instantiated</span><span class="w"> </span><span class="n">before</span><span class="w"> </span><span class="n">calling</span><span class="w"> </span><span class="n">this</span><span class="w"> </span><span class="n">function</span><span class="p">,</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">calling</span>

<span class="w">        </span><span class="n">the</span><span class="w"> </span><span class="n">layer</span><span class="p">.</span>

<span class="w">        </span><span class="n">For</span><span class="w"> </span><span class="n">example</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="err">`</span><span class="n">Dense</span><span class="err">`</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="n">returns</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">two</span><span class="w"> </span><span class="n">values</span><span class="o">:</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">kernel</span>

<span class="w">        </span><span class="n">matrix</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">bias</span><span class="w"> </span><span class="n">vector</span><span class="p">.</span><span class="w"> </span><span class="n">These</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">used</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">weights</span><span class="w"> </span><span class="n">of</span>

<span class="w">        </span><span class="n">another</span><span class="w"> </span><span class="err">`</span><span class="n">Dense</span><span class="err">`</span><span class="w"> </span><span class="n">layer</span><span class="o">:</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">layer_a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="p">...</span><span class="w">   </span><span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">constant_initializer</span><span class="p">(</span><span class="mf">1.</span><span class="p">))</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">a_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">layer_a</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">convert_to_tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span><span class="w"> </span><span class="mf">2.</span><span class="p">,</span><span class="w"> </span><span class="mf">3.</span><span class="p">]]))</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">layer_a</span><span class="p">.</span><span class="n">get_weights</span><span class="p">()</span>

<span class="w">        </span><span class="p">[</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">],</span>

<span class="w">               </span><span class="p">[</span><span class="mf">1.</span><span class="p">],</span>

<span class="w">               </span><span class="p">[</span><span class="mf">1.</span><span class="p">]],</span><span class="w"> </span><span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span><span class="w"> </span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">],</span><span class="w"> </span><span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)]</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">layer_b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="p">...</span><span class="w">   </span><span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">constant_initializer</span><span class="p">(</span><span class="mf">2.</span><span class="p">))</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">b_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">layer_b</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">convert_to_tensor</span><span class="p">([[</span><span class="mf">10.</span><span class="p">,</span><span class="w"> </span><span class="mf">20.</span><span class="p">,</span><span class="w"> </span><span class="mf">30.</span><span class="p">]]))</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">layer_b</span><span class="p">.</span><span class="n">get_weights</span><span class="p">()</span>

<span class="w">        </span><span class="p">[</span><span class="n">array</span><span class="p">([[</span><span class="mf">2.</span><span class="p">],</span>

<span class="w">               </span><span class="p">[</span><span class="mf">2.</span><span class="p">],</span>

<span class="w">               </span><span class="p">[</span><span class="mf">2.</span><span class="p">]],</span><span class="w"> </span><span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span><span class="w"> </span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">],</span><span class="w"> </span><span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)]</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">layer_b</span><span class="p">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">layer_a</span><span class="p">.</span><span class="n">get_weights</span><span class="p">())</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">layer_b</span><span class="p">.</span><span class="n">get_weights</span><span class="p">()</span>

<span class="w">        </span><span class="p">[</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">],</span>

<span class="w">               </span><span class="p">[</span><span class="mf">1.</span><span class="p">],</span>

<span class="w">               </span><span class="p">[</span><span class="mf">1.</span><span class="p">]],</span><span class="w"> </span><span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span><span class="w"> </span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">],</span><span class="w"> </span><span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)]</span>

<span class="w">        </span><span class="nl">Args</span><span class="p">:</span>

<span class="w">          </span><span class="nl">weights</span><span class="p">:</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">NumPy</span><span class="w"> </span><span class="n">arrays</span><span class="p">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">number</span>

<span class="w">            </span><span class="n">of</span><span class="w"> </span><span class="n">arrays</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">their</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="n">must</span><span class="w"> </span><span class="n">match</span>

<span class="w">            </span><span class="n">number</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">dimensions</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">weights</span>

<span class="w">            </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="p">.</span><span class="n">e</span><span class="p">.</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">match</span><span class="w"> </span><span class="n">the</span>

<span class="w">            </span><span class="n">output</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="err">`</span><span class="n">get_weights</span><span class="err">`</span><span class="p">).</span>

<span class="w">        </span><span class="nl">Raises</span><span class="p">:</span>

<span class="w">          </span><span class="nl">ValueError</span><span class="p">:</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">provided</span><span class="w"> </span><span class="n">weights</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">does</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">match</span><span class="w"> </span><span class="n">the</span>

<span class="w">            </span><span class="n">layer</span><span class="err">&#39;</span><span class="n">s</span><span class="w"> </span><span class="n">specifications</span><span class="p">.</span>

<span class="w">        </span><span class="s">&quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">params</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">weights</span>

<span class="w">        </span><span class="n">expected_num_weights</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">param</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">params</span><span class="o">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span><span class="w"> </span><span class="n">base_layer_utils</span><span class="p">.</span><span class="n">TrackableWeightHandler</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">expected_num_weights</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">param</span><span class="p">.</span><span class="n">num_tensors</span>

<span class="w">            </span><span class="nl">else</span><span class="p">:</span>

<span class="w">                </span><span class="n">expected_num_weights</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="mi">1</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">expected_num_weights</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                </span><span class="err">&#39;</span><span class="n">You</span><span class="w"> </span><span class="n">called</span><span class="w"> </span><span class="err">`</span><span class="n">set_weights</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span><span class="err">`</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="s">&quot;%s&quot;</span><span class="w"> </span><span class="err">&#39;</span>

<span class="w">                </span><span class="s">&quot;with a weight list of length %s, but the layer was &quot;</span>

<span class="w">                </span><span class="s">&quot;expecting %s weights. Provided weights: %s...&quot;</span>

<span class="w">                </span><span class="o">%</span><span class="w"> </span><span class="p">(</span>

<span class="w">                    </span><span class="nb">self</span><span class="p">.</span><span class="n">name</span><span class="p">,</span>

<span class="w">                    </span><span class="n">len</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span>

<span class="w">                    </span><span class="n">expected_num_weights</span><span class="p">,</span>

<span class="w">                    </span><span class="n">str</span><span class="p">(</span><span class="n">weights</span><span class="p">)[</span><span class="o">:</span><span class="mi">50</span><span class="p">],</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="n">weight_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>

<span class="w">        </span><span class="n">weight_value_tuples</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[]</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">param</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">params</span><span class="o">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span><span class="w"> </span><span class="n">base_layer_utils</span><span class="p">.</span><span class="n">TrackableWeightHandler</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">num_tensors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">param</span><span class="p">.</span><span class="n">num_tensors</span>

<span class="w">                </span><span class="n">tensors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">weights</span><span class="p">[</span><span class="n">weight_index</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">weight_index</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">num_tensors</span><span class="p">]</span>

<span class="w">                </span><span class="n">param</span><span class="p">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span>

<span class="w">                </span><span class="n">weight_index</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">num_tensors</span>

<span class="w">            </span><span class="nl">else</span><span class="p">:</span>

<span class="w">                </span><span class="n">weight</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">weights</span><span class="p">[</span><span class="n">weight_index</span><span class="p">]</span>

<span class="w">                </span><span class="n">weight_shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">weight</span><span class="p">.</span><span class="n">shape</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">hasattr</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;shape&quot;</span><span class="p">)</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">()</span>

<span class="w">                </span><span class="n">ref_shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">param</span><span class="p">.</span><span class="n">shape</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">ref_shape</span><span class="p">.</span><span class="n">is_compatible_with</span><span class="p">(</span><span class="n">weight_shape</span><span class="p">)</span><span class="o">:</span>

<span class="w">                    </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                        </span><span class="n">f</span><span class="s">&quot;Layer {self.name} weight shape {ref_shape} &quot;</span>

<span class="w">                        </span><span class="s">&quot;is not compatible with provided weight &quot;</span>

<span class="w">                        </span><span class="n">f</span><span class="s">&quot;shape {weight_shape}.&quot;</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">                </span><span class="n">weight_value_tuples</span><span class="p">.</span><span class="n">append</span><span class="p">((</span><span class="n">param</span><span class="p">,</span><span class="w"> </span><span class="n">weight</span><span class="p">))</span>

<span class="w">                </span><span class="n">weight_index</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="mi">1</span>

<span class="w">        </span><span class="n">backend</span><span class="p">.</span><span class="n">batch_set_value</span><span class="p">(</span><span class="n">weight_value_tuples</span><span class="p">)</span>

<span class="w">        </span><span class="cp"># Perform any layer defined finalization of the layer state.</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">_flatten_layers</span><span class="p">()</span><span class="o">:</span>

<span class="w">            </span><span class="n">layer</span><span class="p">.</span><span class="n">finalize_state</span><span class="p">()</span>
</code></pre></div>

</details>
<h4 id="summary">summary</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">summary</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">line_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">positions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">print_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">expand_nested</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">show_trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">layer_range</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Prints a string summary of the network.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>line_length</td>
<td>None</td>
<td>Total length of printed lines<br>(e.g. set this to adapt the display to different<br>terminal window sizes).</td>
<td>None</td>
</tr>
<tr>
<td>positions</td>
<td>None</td>
<td>Relative or absolute positions of log elements<br>in each line. If not provided,<br>defaults to <code>[.33, .55, .67, 1.]</code>.</td>
<td>None</td>
</tr>
<tr>
<td>print_fn</td>
<td>None</td>
<td>Print function to use. Defaults to <code>print</code>.<br>It will be called on each line of the summary.<br>You can set it to a custom function<br>in order to capture the string summary.</td>
<td><code>print</code></td>
</tr>
<tr>
<td>expand_nested</td>
<td>None</td>
<td>Whether to expand the nested models.<br>If not provided, defaults to <code>False</code>.</td>
<td>None</td>
</tr>
<tr>
<td>show_trainable</td>
<td>None</td>
<td>Whether to show if a layer is trainable.<br>If not provided, defaults to <code>False</code>.</td>
<td>None</td>
</tr>
<tr>
<td>layer_range</td>
<td>None</td>
<td>a list or tuple of 2 strings,<br>which is the starting layer name and ending layer name<br>(both inclusive) indicating the range of layers to be printed<br>in summary. It also accepts regex patterns instead of exact<br>name. In such case, start predicate will be the first element<br>it matches to <code>layer_range[0]</code> and the end predicate will be<br>the last element it matches to <code>layer_range[1]</code>.<br>By default <code>None</code> which considers all layers of model.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>if <code>summary()</code> is called before the model is built.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">summary</span><span class="p">(</span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">line_length</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">positions</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">print_fn</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">expand_nested</span><span class="o">=</span><span class="no">False</span><span class="p">,</span>

<span class="w">        </span><span class="n">show_trainable</span><span class="o">=</span><span class="no">False</span><span class="p">,</span>

<span class="w">        </span><span class="n">layer_range</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Prints a string summary of the network.</span>

<span class="s2">        Args:</span>

<span class="s2">            line_length: Total length of printed lines</span>

<span class="s2">                (e.g. set this to adapt the display to different</span>

<span class="s2">                terminal window sizes).</span>

<span class="s2">            positions: Relative or absolute positions of log elements</span>

<span class="s2">                in each line. If not provided,</span>

<span class="s2">                defaults to `[.33, .55, .67, 1.]`.</span>

<span class="s2">            print_fn: Print function to use. Defaults to `print`.</span>

<span class="s2">                It will be called on each line of the summary.</span>

<span class="s2">                You can set it to a custom function</span>

<span class="s2">                in order to capture the string summary.</span>

<span class="s2">            expand_nested: Whether to expand the nested models.</span>

<span class="s2">                If not provided, defaults to `False`.</span>

<span class="s2">            show_trainable: Whether to show if a layer is trainable.</span>

<span class="s2">                If not provided, defaults to `False`.</span>

<span class="s2">            layer_range: a list or tuple of 2 strings,</span>

<span class="s2">                which is the starting layer name and ending layer name</span>

<span class="s2">                (both inclusive) indicating the range of layers to be printed</span>

<span class="s2">                in summary. It also accepts regex patterns instead of exact</span>

<span class="s2">                name. In such case, start predicate will be the first element</span>

<span class="s2">                it matches to `layer_range[0]` and the end predicate will be</span>

<span class="s2">                the last element it matches to `layer_range[1]`.</span>

<span class="s2">                By default `None` which considers all layers of model.</span>

<span class="s2">        Raises:</span>

<span class="s2">            ValueError: if `summary()` is called before the model is built.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">built</span><span class="o">:</span>

<span class="w">            </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                </span><span class="s2">&quot;This model has not yet been built. &quot;</span>

<span class="w">                </span><span class="s2">&quot;Build the model first by calling `build()` or by calling &quot;</span>

<span class="w">                </span><span class="s2">&quot;the model on a batch of data.&quot;</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="n">layer_utils</span><span class="p">.</span><span class="n">print_summary</span><span class="p">(</span>

<span class="w">            </span><span class="n">self</span><span class="p">,</span>

<span class="w">            </span><span class="n">line_length</span><span class="o">=</span><span class="n">line_length</span><span class="p">,</span>

<span class="w">            </span><span class="n">positions</span><span class="o">=</span><span class="n">positions</span><span class="p">,</span>

<span class="w">            </span><span class="n">print_fn</span><span class="o">=</span><span class="n">print_fn</span><span class="p">,</span>

<span class="w">            </span><span class="n">expand_nested</span><span class="o">=</span><span class="n">expand_nested</span><span class="p">,</span>

<span class="w">            </span><span class="n">show_trainable</span><span class="o">=</span><span class="n">show_trainable</span><span class="p">,</span>

<span class="w">            </span><span class="n">layer_range</span><span class="o">=</span><span class="n">layer_range</span><span class="p">,</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="test_on_batch">test_on_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">test_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">reset_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Test the model on a single batch of samples.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input data. It could be:<br>- A Numpy array (or array-like), or a list of arrays (in case the<br>    model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors (in case the model has<br>    multiple inputs).<br>- A dict mapping input names to the corresponding array/tensors,<br>    if the model has named inputs.</td>
<td>None</td>
</tr>
<tr>
<td>y</td>
<td>None</td>
<td>Target data. Like the input data <code>x</code>, it could be either Numpy<br>array(s) or TensorFlow tensor(s). It should be consistent with <code>x</code><br>(you cannot have Numpy inputs and tensor targets, or inversely).</td>
<td>None</td>
</tr>
<tr>
<td>sample_weight</td>
<td>None</td>
<td>Optional array of the same length as x, containing<br>weights to apply to the model's loss for each sample. In the case<br>of temporal data, you can pass a 2D array with shape (samples,<br>sequence_length), to apply a different weight to every timestep of<br>every sample.</td>
<td>None</td>
</tr>
<tr>
<td>reset_metrics</td>
<td>None</td>
<td>If <code>True</code>, the metrics returned will be only for this<br>batch. If <code>False</code>, the metrics will be statefully accumulated<br>across batches.</td>
<td>None</td>
</tr>
<tr>
<td>return_dict</td>
<td>None</td>
<td>If <code>True</code>, loss and metric results are returned as a<br>dict, with each key being the name of the metric. If <code>False</code>, they<br>are returned as a list.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Scalar test loss (if the model has a single output and no metrics)<br>or list of scalars (if the model has multiple outputs<br>and/or metrics). The attribute <code>model.metrics_names</code> will give you<br>the display labels for the scalar outputs.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.test_on_batch</code> is wrapped in a<br><code>tf.function</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">test_on_batch</span><span class="p">(</span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">x</span><span class="p">,</span>

<span class="w">        </span><span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">reset_metrics</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

<span class="w">        </span><span class="n">return_dict</span><span class="o">=</span><span class="no">False</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Test the model on a single batch of samples.</span>

<span class="s2">        Args:</span>

<span class="s2">            x: Input data. It could be:</span>

<span class="s2">              - A Numpy array (or array-like), or a list of arrays (in case the</span>

<span class="s2">                  model has multiple inputs).</span>

<span class="s2">              - A TensorFlow tensor, or a list of tensors (in case the model has</span>

<span class="s2">                  multiple inputs).</span>

<span class="s2">              - A dict mapping input names to the corresponding array/tensors,</span>

<span class="s2">                  if the model has named inputs.</span>

<span class="s2">            y: Target data. Like the input data `x`, it could be either Numpy</span>

<span class="s2">              array(s) or TensorFlow tensor(s). It should be consistent with `x`</span>

<span class="s2">              (you cannot have Numpy inputs and tensor targets, or inversely).</span>

<span class="s2">            sample_weight: Optional array of the same length as x, containing</span>

<span class="s2">              weights to apply to the model&#39;s loss for each sample. In the case</span>

<span class="s2">              of temporal data, you can pass a 2D array with shape (samples,</span>

<span class="s2">              sequence_length), to apply a different weight to every timestep of</span>

<span class="s2">              every sample.</span>

<span class="s2">            reset_metrics: If `True`, the metrics returned will be only for this</span>

<span class="s2">              batch. If `False`, the metrics will be statefully accumulated</span>

<span class="s2">              across batches.</span>

<span class="s2">            return_dict: If `True`, loss and metric results are returned as a</span>

<span class="s2">              dict, with each key being the name of the metric. If `False`, they</span>

<span class="s2">              are returned as a list.</span>

<span class="s2">        Returns:</span>

<span class="s2">            Scalar test loss (if the model has a single output and no metrics)</span>

<span class="s2">            or list of scalars (if the model has multiple outputs</span>

<span class="s2">            and/or metrics). The attribute `model.metrics_names` will give you</span>

<span class="s2">            the display labels for the scalar outputs.</span>

<span class="s2">        Raises:</span>

<span class="s2">            RuntimeError: If `model.test_on_batch` is wrapped in a</span>

<span class="s2">              `tf.function`.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s2">&quot;test_on_batch&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s2">&quot;test_on_batch&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">reset_metrics</span><span class="o">:</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span>

<span class="w">            </span><span class="n">iterator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">single_batch_iterator</span><span class="p">(</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">make_test_function</span><span class="p">()</span>

<span class="w">            </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

<span class="w">        </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">return_dict</span><span class="o">:</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="k">logs</span>

<span class="w">        </span><span class="k">else</span><span class="o">:</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">flatten_metrics_in_order</span><span class="p">(</span><span class="k">logs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="test_step">test_step</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span>
<span class="p">)</span>
</code></pre></div>

<p>The logic for one evaluation step.</p>
<p>This method can be overridden to support custom evaluation logic.
This method is called by <code>Model.make_test_function</code>.</p>
<p>This function should contain the mathematical logic for one step of
evaluation.
This typically includes the forward pass, loss calculation, and metrics
updates.</p>
<p>Configuration details for <em>how</em> this logic is run (e.g. <code>tf.function</code>
and <code>tf.distribute.Strategy</code> settings), should be left to
<code>Model.make_test_function</code>, which can also be overridden.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>data</td>
<td>None</td>
<td>A nested structure of <code>Tensor</code>s.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A <code>dict</code> containing values that will be passed to<br><code>tf.keras.callbacks.CallbackList.on_train_batch_end</code>. Typically, the<br>values of the <code>Model</code>'s metrics are returned.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">test_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">data</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">The logic for one evaluation step.</span>

<span class="s2">        This method can be overridden to support custom evaluation logic.</span>

<span class="s2">        This method is called by `Model.make_test_function`.</span>

<span class="s2">        This function should contain the mathematical logic for one step of</span>

<span class="s2">        evaluation.</span>

<span class="s2">        This typically includes the forward pass, loss calculation, and metrics</span>

<span class="s2">        updates.</span>

<span class="s2">        Configuration details for *how* this logic is run (e.g. `tf.function`</span>

<span class="s2">        and `tf.distribute.Strategy` settings), should be left to</span>

<span class="s2">        `Model.make_test_function`, which can also be overridden.</span>

<span class="s2">        Args:</span>

<span class="s2">          data: A nested structure of `Tensor`s.</span>

<span class="s2">        Returns:</span>

<span class="s2">          A `dict` containing values that will be passed to</span>

<span class="s2">          `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the</span>

<span class="s2">          values of the `Model`&#39;s metrics are returned.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

<span class="w">        </span><span class="n">y_pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">training</span><span class="o">=</span><span class="no">False</span><span class="p">)</span>

<span class="w">        </span><span class="c1"># Updates stateful loss metrics.</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">compute_metrics</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="to_json">to_json</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">to_json</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns a JSON string containing the network configuration.</p>
<p>To load a network from a JSON save file, use
<code>keras.models.model_from_json(json_string, custom_objects={})</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Additional keyword arguments to be passed to<br>*<code>json.dumps()</code>.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A JSON string.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">to_json</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a JSON string containing the network configuration.</span>

<span class="sd">        To load a network from a JSON save file, use</span>

<span class="sd">        `keras.models.model_from_json(json_string, custom_objects={})`.</span>

<span class="sd">        Args:</span>

<span class="sd">            **kwargs: Additional keyword arguments to be passed to</span>

<span class="sd">                *`json.dumps()`.</span>

<span class="sd">        Returns:</span>

<span class="sd">            A JSON string.</span>

<span class="sd">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">model_config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_updated_config</span><span class="p">()</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span>

<span class="w">            </span><span class="n">model_config</span><span class="p">,</span><span class="w"> </span><span class="n">default</span><span class="o">=</span><span class="n">json_utils</span><span class="o">.</span><span class="n">get_json_type</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="to_yaml">to_yaml</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">to_yaml</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns a yaml string containing the network configuration.</p>
<p>Note: Since TF 2.6, this method is no longer supported and will raise a
RuntimeError.</p>
<p>To load a network from a yaml save file, use
<code>keras.models.model_from_yaml(yaml_string, custom_objects={})</code>.</p>
<p><code>custom_objects</code> should be a dictionary mapping
the names of custom losses / layers / etc to the corresponding
functions / classes.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Additional keyword arguments<br>to be passed to <code>yaml.dump()</code>.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A YAML string.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>announces that the method poses a security risk</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">to_yaml</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns a yaml string containing the network configuration.</span>

<span class="s2">        Note: Since TF 2.6, this method is no longer supported and will raise a</span>

<span class="s2">        RuntimeError.</span>

<span class="s2">        To load a network from a yaml save file, use</span>

<span class="s2">        `keras.models.model_from_yaml(yaml_string, custom_objects={})`.</span>

<span class="s2">        `custom_objects` should be a dictionary mapping</span>

<span class="s2">        the names of custom losses / layers / etc to the corresponding</span>

<span class="s2">        functions / classes.</span>

<span class="s2">        Args:</span>

<span class="s2">            **kwargs: Additional keyword arguments</span>

<span class="s2">                to be passed to `yaml.dump()`.</span>

<span class="s2">        Returns:</span>

<span class="s2">            A YAML string.</span>

<span class="s2">        Raises:</span>

<span class="s2">            RuntimeError: announces that the method poses a security risk</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">RuntimeError</span><span class="p">(</span>

<span class="w">            </span><span class="s2">&quot;Method `model.to_yaml()` has been removed due to security risk of &quot;</span>

<span class="w">            </span><span class="s2">&quot;arbitrary code execution. Please use `model.to_json()` instead.&quot;</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="train_on_batch">train_on_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">train_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">reset_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Runs a single gradient update on a single batch of data.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input data. It could be:<br>- A Numpy array (or array-like), or a list of arrays<br>    (in case the model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors<br>    (in case the model has multiple inputs).<br>- A dict mapping input names to the corresponding array/tensors,<br>    if the model has named inputs.</td>
<td>None</td>
</tr>
<tr>
<td>y</td>
<td>None</td>
<td>Target data. Like the input data <code>x</code>, it could be either Numpy<br>array(s) or TensorFlow tensor(s).</td>
<td>None</td>
</tr>
<tr>
<td>sample_weight</td>
<td>None</td>
<td>Optional array of the same length as x, containing<br>weights to apply to the model's loss for each sample. In the case<br>of temporal data, you can pass a 2D array with shape (samples,<br>sequence_length), to apply a different weight to every timestep of<br>every sample.</td>
<td>None</td>
</tr>
<tr>
<td>class_weight</td>
<td>None</td>
<td>Optional dictionary mapping class indices (integers)<br>to a weight (float) to apply to the model's loss for the samples<br>from this class during training. This can be useful to tell the<br>model to "pay more attention" to samples from an under-represented<br>class.</td>
<td>None</td>
</tr>
<tr>
<td>reset_metrics</td>
<td>None</td>
<td>If <code>True</code>, the metrics returned will be only for this<br>batch. If <code>False</code>, the metrics will be statefully accumulated<br>across batches.</td>
<td>None</td>
</tr>
<tr>
<td>return_dict</td>
<td>None</td>
<td>If <code>True</code>, loss and metric results are returned as a<br>dict, with each key being the name of the metric. If <code>False</code>, they<br>are returned as a list.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Scalar training loss<br>(if the model has a single output and no metrics)<br>or list of scalars (if the model has multiple outputs<br>and/or metrics). The attribute <code>model.metrics_names</code> will give you<br>the display labels for the scalar outputs.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.train_on_batch</code> is wrapped in a <code>tf.function</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">train_on_batch</span><span class="p">(</span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">x</span><span class="p">,</span>

<span class="w">        </span><span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">class_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">reset_metrics</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

<span class="w">        </span><span class="n">return_dict</span><span class="o">=</span><span class="no">False</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single gradient update on a single batch of data.</span>

<span class="s2">        Args:</span>

<span class="s2">            x: Input data. It could be:</span>

<span class="s2">              - A Numpy array (or array-like), or a list of arrays</span>

<span class="s2">                  (in case the model has multiple inputs).</span>

<span class="s2">              - A TensorFlow tensor, or a list of tensors</span>

<span class="s2">                  (in case the model has multiple inputs).</span>

<span class="s2">              - A dict mapping input names to the corresponding array/tensors,</span>

<span class="s2">                  if the model has named inputs.</span>

<span class="s2">            y: Target data. Like the input data `x`, it could be either Numpy</span>

<span class="s2">              array(s) or TensorFlow tensor(s).</span>

<span class="s2">            sample_weight: Optional array of the same length as x, containing</span>

<span class="s2">              weights to apply to the model&#39;s loss for each sample. In the case</span>

<span class="s2">              of temporal data, you can pass a 2D array with shape (samples,</span>

<span class="s2">              sequence_length), to apply a different weight to every timestep of</span>

<span class="s2">              every sample.</span>

<span class="s2">            class_weight: Optional dictionary mapping class indices (integers)</span>

<span class="s2">              to a weight (float) to apply to the model&#39;s loss for the samples</span>

<span class="s2">              from this class during training. This can be useful to tell the</span>

<span class="s2">              model to &quot;</span><span class="n">pay</span><span class="w"> </span><span class="n">more</span><span class="w"> </span><span class="n">attention</span><span class="s2">&quot; to samples from an under-represented</span>

<span class="s2">              class.</span>

<span class="s2">            reset_metrics: If `True`, the metrics returned will be only for this</span>

<span class="s2">              batch. If `False`, the metrics will be statefully accumulated</span>

<span class="s2">              across batches.</span>

<span class="s2">            return_dict: If `True`, loss and metric results are returned as a</span>

<span class="s2">              dict, with each key being the name of the metric. If `False`, they</span>

<span class="s2">              are returned as a list.</span>

<span class="s2">        Returns:</span>

<span class="s2">            Scalar training loss</span>

<span class="s2">            (if the model has a single output and no metrics)</span>

<span class="s2">            or list of scalars (if the model has multiple outputs</span>

<span class="s2">            and/or metrics). The attribute `model.metrics_names` will give you</span>

<span class="s2">            the display labels for the scalar outputs.</span>

<span class="s2">        Raises:</span>

<span class="s2">          RuntimeError: If `model.train_on_batch` is wrapped in a `tf.function`.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s2">&quot;train_on_batch&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s2">&quot;train_on_batch&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">reset_metrics</span><span class="o">:</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">(),</span><span class="w"> </span><span class="n">training_utils</span><span class="p">.</span><span class="n">RespectCompiledTrainableState</span><span class="p">(</span><span class="w">  </span><span class="c1"># noqa: E501</span>

<span class="w">            </span><span class="n">self</span>

<span class="w">        </span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="n">iterator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">single_batch_iterator</span><span class="p">(</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">,</span><span class="w"> </span><span class="n">class_weight</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">make_train_function</span><span class="p">()</span>

<span class="w">            </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

<span class="w">        </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">return_dict</span><span class="o">:</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="k">logs</span>

<span class="w">        </span><span class="k">else</span><span class="o">:</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">flatten_metrics_in_order</span><span class="p">(</span><span class="k">logs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="train_step">train_step</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span>
<span class="p">)</span>
</code></pre></div>

<p>The logic for one training step.</p>
<p>This method can be overridden to support custom training logic.
For concrete examples of how to override this method see
<a href="https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit">Customizing what happens in fit</a>.
This method is called by <code>Model.make_train_function</code>.</p>
<p>This method should contain the mathematical logic for one step of
training.  This typically includes the forward pass, loss calculation,
backpropagation, and metric updates.</p>
<p>Configuration details for <em>how</em> this logic is run (e.g. <code>tf.function</code>
and <code>tf.distribute.Strategy</code> settings), should be left to
<code>Model.make_train_function</code>, which can also be overridden.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>data</td>
<td>None</td>
<td>A nested structure of <code>Tensor</code>s.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A <code>dict</code> containing values that will be passed to<br><code>tf.keras.callbacks.CallbackList.on_train_batch_end</code>. Typically, the<br>values of the <code>Model</code>'s metrics are returned. Example:<br><code>{'loss': 0.2, 'accuracy': 0.7}</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">train_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">data</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">The logic for one training step.</span>

<span class="s2">        This method can be overridden to support custom training logic.</span>

<span class="s2">        For concrete examples of how to override this method see</span>

<span class="s2">        [Customizing what happens in fit](</span>

<span class="s2">        https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit).</span>

<span class="s2">        This method is called by `Model.make_train_function`.</span>

<span class="s2">        This method should contain the mathematical logic for one step of</span>

<span class="s2">        training.  This typically includes the forward pass, loss calculation,</span>

<span class="s2">        backpropagation, and metric updates.</span>

<span class="s2">        Configuration details for *how* this logic is run (e.g. `tf.function`</span>

<span class="s2">        and `tf.distribute.Strategy` settings), should be left to</span>

<span class="s2">        `Model.make_train_function`, which can also be overridden.</span>

<span class="s2">        Args:</span>

<span class="s2">          data: A nested structure of `Tensor`s.</span>

<span class="s2">        Returns:</span>

<span class="s2">          A `dict` containing values that will be passed to</span>

<span class="s2">          `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the</span>

<span class="s2">          values of the `Model`&#39;s metrics are returned. Example:</span>

<span class="s2">          `{&#39;loss&#39;: 0.2, &#39;accuracy&#39;: 0.7}`.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

<span class="w">        </span><span class="c1"># Run forward pass.</span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">GradientTape</span><span class="p">()</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">tape</span><span class="o">:</span>

<span class="w">            </span><span class="n">y_pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">training</span><span class="o">=</span><span class="no">True</span><span class="p">)</span>

<span class="w">            </span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">)</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_validate_target_and_loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">loss</span><span class="p">)</span>

<span class="w">        </span><span class="c1"># Run backwards pass.</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">,</span><span class="w"> </span><span class="n">tape</span><span class="o">=</span><span class="n">tape</span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">compute_metrics</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">)</span>
</code></pre></div>

</details>
<h3 id="vec">Vec</h3>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">Vec</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">Model</span>
<span class="p">)</span>
</code></pre></div>

<p><code>Model</code> groups layers into an object with training and inference features.</p>
<h4 id="attributes">Attributes</h4>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>inputs</td>
<td>None</td>
<td>The input(s) of the model: a <code>keras.Input</code> object or a<br>combination of <code>keras.Input</code> objects in a dict, list or tuple.</td>
<td>None</td>
</tr>
<tr>
<td>outputs</td>
<td>None</td>
<td>The output(s) of the model: a tensor that originated from<br><code>keras.Input</code> objects or a combination of such tensors in a dict,<br>list or tuple. See Functional API example below.</td>
<td>None</td>
</tr>
<tr>
<td>name</td>
<td>None</td>
<td>String, the name of the model.</td>
<td>None</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="n">Vec</span>(<span class="n">tf</span>.<span class="n">keras</span>.<span class="n">Model</span>):

    <span class="n">def</span> <span class="n">__init__</span>(<span class="nb">self</span>, <span class="n">model:</span> <span class="n">tf</span>.<span class="n">keras</span>.<span class="n">Model</span>):

        <span class="s">&quot;&quot;&quot;</span>

<span class="s">        Class that applies a given model on each element of the input tensor.</span>

<span class="s">        Parameters:</span>

<span class="s">            model (tf.keras.Model): The model to apply on each element of the input tensor.</span>

<span class="s">        &quot;&quot;&quot;</span>

        <span class="n">super</span>().<span class="n">__init__</span>()

        <span class="nb">self</span>.<span class="n">model</span> = <span class="n">model</span>

    <span class="n">def</span> <span class="n">call</span>(<span class="nb">self</span>, <span class="o">x</span>: <span class="n">tf</span>.<span class="n">Tensor</span>) -&gt; <span class="n">tf</span>.<span class="n">Tensor:</span>

        <span class="s">&quot;&quot;&quot;</span>

<span class="s">        Applies the model on each element of the input tensor.</span>

<span class="s">        Parameters:</span>

<span class="s">            x (tf.Tensor): The input tensor</span>

<span class="s">        Returns:</span>

<span class="s">            tf.Tensor: The output tensor with the model applied on each element.</span>

<span class="s">        &quot;&quot;&quot;</span>

        <span class="nb">x</span> = <span class="n">tf</span>.<span class="n">transpose</span>(<span class="nb">x</span>, <span class="n">perm</span>=(<span class="mi">1</span>, <span class="mi">0</span>, <span class="mi">2</span>, <span class="mi">3</span>, <span class="mi">4</span>))

        <span class="nb">x</span> = <span class="n">tf</span>.<span class="n">vectorized_map</span>(<span class="nb">self</span>.<span class="n">model</span>, <span class="nb">x</span>)

        <span class="k">return</span> <span class="n">tf</span>.<span class="n">transpose</span>(<span class="nb">x</span>, <span class="n">perm</span>=(<span class="mi">1</span>, <span class="mi">0</span>, <span class="mi">2</span>, <span class="mi">3</span>, <span class="mi">4</span>))
</code></pre></div>

</details>
<hr />
<h4 id="ancestors-in-mro_1">Ancestors (in MRO)</h4>
<ul>
<li>keras.engine.training.Model</li>
<li>keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.trackable.autotrackable.AutoTrackable</li>
<li>tensorflow.python.trackable.base.Trackable</li>
<li>keras.utils.version_utils.LayerVersionSelector</li>
<li>keras.utils.version_utils.ModelVersionSelector</li>
</ul>
<h4 id="static-methods_1">Static methods</h4>
<h4 id="from_config_1">from_config</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">from_config</span><span class="p">(</span>
    <span class="n">config</span><span class="p">,</span>
    <span class="n">custom_objects</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a layer from its config.</p>
<p>This method is the reverse of <code>get_config</code>,
capable of instantiating the same layer from the config
dictionary. It does not handle layer connectivity
(handled by Network), nor weights (handled by <code>set_weights</code>).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>config</td>
<td>None</td>
<td>A Python dictionary, typically the<br>output of get_config.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A layer instance.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code>    <span class="nd">@classmethod</span>

    <span class="k">def</span> <span class="nf">from_config</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">custom_objects</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

        <span class="n">compile_config</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;compile_config&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="n">build_input_shape</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;build_input_shape&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="c1"># `from_config` assumes `cls` is either `Functional` or a child class of</span>

        <span class="c1"># `Functional`. In the case that `cls` is meant to behave like a child</span>

        <span class="c1"># class of `Functional` but only inherits from the `Model` class, we</span>

        <span class="c1"># have to call `cls(...)` instead of `Functional.from_config`.</span>

        <span class="kn">from</span> <span class="nn">keras.engine</span> <span class="kn">import</span> <span class="n">functional</span>

        <span class="k">with</span> <span class="n">serialization</span><span class="o">.</span><span class="n">SharedObjectLoadingScope</span><span class="p">():</span>

            <span class="n">functional_model_keys</span> <span class="o">=</span> <span class="p">[</span>

                <span class="s2">&quot;name&quot;</span><span class="p">,</span>

                <span class="s2">&quot;layers&quot;</span><span class="p">,</span>

                <span class="s2">&quot;input_layers&quot;</span><span class="p">,</span>

                <span class="s2">&quot;output_layers&quot;</span><span class="p">,</span>

            <span class="p">]</span>

            <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">key</span> <span class="ow">in</span> <span class="n">config</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">functional_model_keys</span><span class="p">):</span>

                <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">layers</span> <span class="o">=</span> <span class="n">functional</span><span class="o">.</span><span class="n">reconstruct_from_config</span><span class="p">(</span>

                    <span class="n">config</span><span class="p">,</span> <span class="n">custom_objects</span>

                <span class="p">)</span>

                <span class="n">model</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span>

                    <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">)</span>

                <span class="p">)</span>

                <span class="n">functional</span><span class="o">.</span><span class="n">connect_ancillary_layers</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">layers</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>

                <span class="c1"># The config does not contain all the information necessary to</span>

                <span class="c1"># revive a Functional model. This happens when the user creates</span>

                <span class="c1"># subclassed models where `get_config()` is returning</span>

                <span class="c1"># insufficient information to be considered a Functional model.</span>

                <span class="c1"># In this case, we fall back to provide all config into the</span>

                <span class="c1"># constructor of the class.</span>

                <span class="k">try</span><span class="p">:</span>

                    <span class="n">model</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="o">**</span><span class="n">config</span><span class="p">)</span>

                <span class="k">except</span> <span class="ne">TypeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>

                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>

                        <span class="s2">&quot;Unable to revive model from config. When overriding &quot;</span>

                        <span class="s2">&quot;the `get_config()`, make sure that the returned &quot;</span>

                        <span class="s2">&quot;config contains all items used as arguments in the &quot;</span>

                        <span class="sa">f</span><span class="s2">&quot;constructor to </span><span class="si">{</span><span class="bp">cls</span><span class="si">}</span><span class="s2">, which is the default behavior. &quot;</span>

                        <span class="s2">&quot;You can override this default behavior by defining a &quot;</span>

                        <span class="s2">&quot;`from_config` method to specify how to create an &quot;</span>

                        <span class="sa">f</span><span class="s2">&quot;instance of </span><span class="si">{</span><span class="bp">cls</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> from the config. </span><span class="se">\n\n</span><span class="s2">&quot;</span>

                        <span class="sa">f</span><span class="s2">&quot;Error encountered during deserialization:</span><span class="se">\n</span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span>

                    <span class="p">)</span>

            <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">saving_lib</span><span class="o">.</span><span class="n">_SAVING_V3_ENABLED</span><span class="p">,</span> <span class="s2">&quot;value&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>

                <span class="k">if</span> <span class="n">build_input_shape</span><span class="p">:</span>

                    <span class="n">model</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">build_input_shape</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">compile_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

                    <span class="n">model</span><span class="o">.</span><span class="n">_compile_from_config</span><span class="p">(</span><span class="n">compile_config</span><span class="p">,</span> <span class="n">base_class</span><span class="o">=</span><span class="n">Model</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">model</span>
</code></pre></div>

</details>
<h4 id="with_name_scope_1">with_name_scope</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">with_name_scope</span><span class="p">(</span>
    <span class="n">method</span>
<span class="p">)</span>
</code></pre></div>

<p>Decorator to automatically enter the module name scope.</p>
<blockquote>
<blockquote>
<blockquote>
<p>class MyModule(tf.Module):
...   @tf.Module.with_name_scope
...   def <strong>call</strong>(self, x):
...     if not hasattr(self, 'w'):
...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))
...     return tf.matmul(x, self.w)</p>
</blockquote>
</blockquote>
</blockquote>
<p>Using the above module would produce <code>tf.Variable</code>s and <code>tf.Tensor</code>s whose
names included the module name:</p>
<blockquote>
<blockquote>
<blockquote>
<p>mod = MyModule()
mod(tf.ones([1, 2]))
<tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>
mod.w
<tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,
numpy=..., dtype=float32)></p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>method</td>
<td>None</td>
<td>The method to wrap.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>The original method wrapped such that it enters the module's name scope.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@classmethod</span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">with_name_scope</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span><span class="w"> </span><span class="k">method</span><span class="p">)</span><span class="err">:</span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Decorator to automatically enter the module name scope.</span>

<span class="ss">    &gt;&gt;&gt; class MyModule(tf.Module):</span>

<span class="ss">    ...   @tf.Module.with_name_scope</span>

<span class="ss">    ...   def __call__(self, x):</span>

<span class="ss">    ...     if not hasattr(self, &#39;w&#39;):</span>

<span class="ss">    ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))</span>

<span class="ss">    ...     return tf.matmul(x, self.w)</span>

<span class="ss">    Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose</span>

<span class="ss">    names included the module name:</span>

<span class="ss">    &gt;&gt;&gt; mod = MyModule()</span>

<span class="ss">    &gt;&gt;&gt; mod(tf.ones([1, 2]))</span>

<span class="ss">    &lt;tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)&gt;</span>

<span class="ss">    &gt;&gt;&gt; mod.w</span>

<span class="ss">    &lt;tf.Variable &#39;my_module/Variable:0&#39; shape=(2, 3) dtype=float32,</span>

<span class="ss">    numpy=..., dtype=float32)&gt;</span>

<span class="ss">    Args:</span>

<span class="ss">      method: The method to wrap.</span>

<span class="ss">    Returns:</span>

<span class="ss">      The original method wrapped such that it enters the module&#39;s name scope.</span>

<span class="ss">    &quot;&quot;&quot;</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">method_with_name_scope</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="err">:</span>

<span class="w">      </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="nl">name_scope</span><span class="p">:</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="k">method</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">tf_decorator</span><span class="p">.</span><span class="n">make_decorator</span><span class="p">(</span><span class="k">method</span><span class="p">,</span><span class="w"> </span><span class="n">method_with_name_scope</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="instance-variables_1">Instance variables</h4>
<div class="codehilite"><pre><span></span><code><span class="n">activity_regularizer</span>
</code></pre></div>

<p>Optional regularizer function for the output of this layer.</p>
<div class="codehilite"><pre><span></span><code><span class="n">compute_dtype</span>
</code></pre></div>

<p>The dtype of the layer's computations.</p>
<p>This is equivalent to <code>Layer.dtype_policy.compute_dtype</code>. Unless
mixed precision is used, this is the same as <code>Layer.dtype</code>, the dtype of
the weights.</p>
<p>Layers automatically cast their inputs to the compute dtype, which
causes computations and the output to be in the compute dtype as well.
This is done by the base Layer class in <code>Layer.__call__</code>, so you do not
have to insert these casts if implementing your own layer.</p>
<p>Layers often perform certain internal computations in higher precision
when <code>compute_dtype</code> is float16 or bfloat16 for numeric stability. The
output will still typically be float16 or bfloat16 in such cases.</p>
<div class="codehilite"><pre><span></span><code><span class="n">distribute_reduction_method</span>
</code></pre></div>

<p>The method employed to reduce per-replica values during training.</p>
<p>Unless specified, the value "auto" will be assumed, indicating that
the reduction strategy should be chosen based on the current
running environment.
See <code>reduce_per_replica</code> function for more details.</p>
<div class="codehilite"><pre><span></span><code><span class="n">distribute_strategy</span>
</code></pre></div>

<p>The <code>tf.distribute.Strategy</code> this model was created under.</p>
<div class="codehilite"><pre><span></span><code><span class="n">dtype</span>
</code></pre></div>

<p>The dtype of the layer weights.</p>
<p>This is equivalent to <code>Layer.dtype_policy.variable_dtype</code>. Unless
mixed precision is used, this is the same as <code>Layer.compute_dtype</code>, the
dtype of the layer's computations.</p>
<div class="codehilite"><pre><span></span><code><span class="n">dtype_policy</span>
</code></pre></div>

<p>The dtype policy associated with this layer.</p>
<p>This is an instance of a <code>tf.keras.mixed_precision.Policy</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">dynamic</span>
</code></pre></div>

<p>Whether the layer is dynamic (eager-only); set in the constructor.</p>
<div class="codehilite"><pre><span></span><code><span class="n">inbound_nodes</span>
</code></pre></div>

<p>Return Functional API nodes upstream of this layer.</p>
<div class="codehilite"><pre><span></span><code><span class="nb">input</span>
</code></pre></div>

<p>Retrieves the input tensor(s) of a layer.</p>
<p>Only applicable if the layer has exactly one input,
i.e. if it is connected to one incoming layer.</p>
<div class="codehilite"><pre><span></span><code><span class="n">input_mask</span>
</code></pre></div>

<p>Retrieves the input mask tensor(s) of a layer.</p>
<p>Only applicable if the layer has exactly one inbound node,
i.e. if it is connected to one incoming layer.</p>
<p>Returns:
    Input mask tensor (potentially None) or list of input
    mask tensors.</p>
<p>Raises:
    AttributeError: if the layer is connected to
    more than one incoming layers.</p>
<div class="codehilite"><pre><span></span><code><span class="n">input_shape</span>
</code></pre></div>

<p>Retrieves the input shape(s) of a layer.</p>
<p>Only applicable if the layer has exactly one input,
i.e. if it is connected to one incoming layer, or if all inputs
have the same shape.</p>
<div class="codehilite"><pre><span></span><code><span class="n">input_spec</span>
</code></pre></div>

<p><code>InputSpec</code> instance(s) describing the input format for this layer.</p>
<p>When you create a layer subclass, you can set <code>self.input_spec</code> to
enable the layer to run input compatibility checks when it is called.
Consider a <code>Conv2D</code> layer: it can only be called on a single input
tensor of rank 4. As such, you can set, in <code>__init__()</code>:</p>
<div class="codehilite"><pre><span></span><code><span class="bp">self</span><span class="o">.</span><span class="n">input_spec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">InputSpec</span><span class="p">(</span><span class="n">ndim</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</code></pre></div>

<p>Now, if you try to call the layer on an input that isn't rank 4
(for instance, an input of shape <code>(2,)</code>, it will raise a
nicely-formatted error:</p>
<div class="codehilite"><pre><span></span><code><span class="n">ValueError</span><span class="o">:</span><span class="w"> </span><span class="n">Input</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="n">conv2d</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">incompatible</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">layer</span><span class="o">:</span>
<span class="n">expected</span><span class="w"> </span><span class="n">ndim</span><span class="o">=</span><span class="mi">4</span><span class="o">,</span><span class="w"> </span><span class="n">found</span><span class="w"> </span><span class="n">ndim</span><span class="o">=</span><span class="mi">1</span><span class="o">.</span><span class="w"> </span><span class="n">Full</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="n">received</span><span class="o">:</span><span class="w"> </span><span class="o">[</span><span class="mi">2</span><span class="o">]</span>
</code></pre></div>

<p>Input checks that can be specified via <code>input_spec</code> include:
- Structure (e.g. a single input, a list of 2 inputs, etc)
- Shape
- Rank (ndim)
- Dtype</p>
<p>For more information, see <code>tf.keras.layers.InputSpec</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">layers</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">losses</span>
</code></pre></div>

<p>List of losses added using the <code>add_loss()</code> API.</p>
<p>Variable regularization tensors are created when this property is
accessed, so it is eager safe: accessing <code>losses</code> under a
<code>tf.GradientTape</code> will propagate gradients back to the corresponding
variables.</p>
<div class="codehilite"><pre><span></span><code><span class="n">metrics</span>
</code></pre></div>

<p>Returns the model's metrics added using <code>compile()</code>, <code>add_metric()</code> APIs.</p>
<p>Note: Metrics passed to <code>compile()</code> are available only after a
<code>keras.Model</code> has been trained/evaluated on actual data.</p>
<div class="codehilite"><pre><span></span><code><span class="n">metrics_names</span>
</code></pre></div>

<p>Returns the model's display labels for all outputs.</p>
<p>Note: <code>metrics_names</code> are available only after a <code>keras.Model</code> has been
trained/evaluated on actual data.</p>
<div class="codehilite"><pre><span></span><code><span class="n">name</span>
</code></pre></div>

<p>Name of the layer (string), set in the constructor.</p>
<div class="codehilite"><pre><span></span><code><span class="n">name_scope</span>
</code></pre></div>

<p>Returns a <code>tf.name_scope</code> instance for this class.</p>
<div class="codehilite"><pre><span></span><code><span class="n">non_trainable_variables</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">non_trainable_weights</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">outbound_nodes</span>
</code></pre></div>

<p>Return Functional API nodes downstream of this layer.</p>
<div class="codehilite"><pre><span></span><code><span class="n">output</span>
</code></pre></div>

<p>Retrieves the output tensor(s) of a layer.</p>
<p>Only applicable if the layer has exactly one output,
i.e. if it is connected to one incoming layer.</p>
<div class="codehilite"><pre><span></span><code><span class="n">output_mask</span>
</code></pre></div>

<p>Retrieves the output mask tensor(s) of a layer.</p>
<p>Only applicable if the layer has exactly one inbound node,
i.e. if it is connected to one incoming layer.</p>
<p>Returns:
    Output mask tensor (potentially None) or list of output
    mask tensors.</p>
<p>Raises:
    AttributeError: if the layer is connected to
    more than one incoming layers.</p>
<div class="codehilite"><pre><span></span><code><span class="n">output_shape</span>
</code></pre></div>

<p>Retrieves the output shape(s) of a layer.</p>
<p>Only applicable if the layer has one output,
or if all outputs have the same shape.</p>
<div class="codehilite"><pre><span></span><code><span class="n">run_eagerly</span>
</code></pre></div>

<p>Settable attribute indicating whether the model should run eagerly.</p>
<p>Running eagerly means that your model will be run step by step,
like Python code. Your model might run slower, but it should become
easier for you to debug it by stepping into individual layer calls.</p>
<p>By default, we will attempt to compile your model to a static graph to
deliver the best execution performance.</p>
<div class="codehilite"><pre><span></span><code><span class="n">state_updates</span>
</code></pre></div>

<p>Deprecated, do NOT use!</p>
<p>Returns the <code>updates</code> from all layers that are stateful.</p>
<p>This is useful for separating training updates and
state updates, e.g. when we need to update a layer's internal state
during prediction.</p>
<div class="codehilite"><pre><span></span><code><span class="n">stateful</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">submodules</span>
</code></pre></div>

<p>Sequence of all sub-modules.</p>
<p>Submodules are modules which are properties of this module, or found as
properties of modules which are properties of this module (and so on).</p>
<blockquote>
<blockquote>
<blockquote>
<p>a = tf.Module()
b = tf.Module()
c = tf.Module()
a.b = b
b.c = c
list(a.submodules) == [b, c]
True
list(b.submodules) == [c]
True
list(c.submodules) == []
True</p>
</blockquote>
</blockquote>
</blockquote>
<div class="codehilite"><pre><span></span><code><span class="n">supports_masking</span>
</code></pre></div>

<p>Whether this layer supports computing a mask using <code>compute_mask</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">trainable</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">trainable_variables</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">trainable_weights</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">updates</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">variable_dtype</span>
</code></pre></div>

<p>Alias of <code>Layer.dtype</code>, the dtype of the weights.</p>
<div class="codehilite"><pre><span></span><code><span class="n">variables</span>
</code></pre></div>

<p>Returns the list of all layer variables/weights.</p>
<p>Alias of <code>self.weights</code>.</p>
<p>Note: This will not track the weights of nested <code>tf.Modules</code> that are
not themselves Keras layers.</p>
<div class="codehilite"><pre><span></span><code><span class="n">weights</span>
</code></pre></div>

<p>Returns the list of all layer variables/weights.</p>
<p>Note: This will not track the weights of nested <code>tf.Modules</code> that are
not themselves Keras layers.</p>
<h4 id="methods_1">Methods</h4>
<h4 id="add_loss_1">add_loss</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_loss</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">losses</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Add loss tensor(s), potentially dependent on layer inputs.</p>
<p>Some losses (for instance, activity regularization losses) may be
dependent on the inputs passed when calling a layer. Hence, when reusing
the same layer on different inputs <code>a</code> and <code>b</code>, some entries in
<code>layer.losses</code> may be dependent on <code>a</code> and some on <code>b</code>. This method
automatically keeps track of dependencies.</p>
<p>This method can be used inside a subclassed layer or model's <code>call</code>
function, in which case <code>losses</code> should be a Tensor or list of Tensors.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>losses</td>
<td>None</td>
<td>Loss tensor, or list/tuple of tensors. Rather than tensors,<br>losses may also be zero-argument callables which create a loss<br>tensor.</td>
<td>None</td>
</tr>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Used for backwards compatibility only.</td>
<td>None</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code>    <span class="n">def</span> <span class="n">add_loss</span>(<span class="nb">self</span>, <span class="n">losses</span>, **<span class="n">kwargs</span>):

        <span class="s">&quot;&quot;&quot;Add loss tensor(s), potentially dependent on layer inputs.</span>

<span class="s">        Some losses (for instance, activity regularization losses) may be</span>

<span class="s">        dependent on the inputs passed when calling a layer. Hence, when reusing</span>

<span class="s">        the same layer on different inputs `a` and `b`, some entries in</span>

<span class="s">        `layer.losses` may be dependent on `a` and some on `b`. This method</span>

<span class="s">        automatically keeps track of dependencies.</span>

<span class="s">        This method can be used inside a subclassed layer or model&#39;s `call`</span>

<span class="s">        function, in which case `losses` should be a Tensor or list of Tensors.</span>

<span class="s">        Example:</span>

<span class="s">        ```python</span>

<span class="s">        class MyLayer(tf.keras.layers.Layer):</span>

<span class="s">          def call(self, inputs):</span>

<span class="s">            self.add_loss(tf.abs(tf.reduce_mean(inputs)))</span>

<span class="s">            return inputs</span>

<span class="s">        ```</span>

<span class="s">        This method can also be called directly on a Functional Model during</span>

<span class="s">        construction. In this case, any loss Tensors passed to this Model must</span>

<span class="s">        be symbolic and be able to be traced back to the model&#39;s `Input`s. These</span>

<span class="s">        losses become part of the model&#39;s topology and are tracked in</span>

<span class="s">        `get_config`.</span>

<span class="s">        Example:</span>

<span class="s">        ```python</span>

<span class="s">        inputs = tf.keras.Input(shape=(10,))</span>

<span class="s">        x = tf.keras.layers.Dense(10)(inputs)</span>

<span class="s">        outputs = tf.keras.layers.Dense(1)(x)</span>

<span class="s">        model = tf.keras.Model(inputs, outputs)</span>

<span class="s">        # Activity regularization.</span>

<span class="s">        model.add_loss(tf.abs(tf.reduce_mean(x)))</span>

<span class="s">        ```</span>

<span class="s">        If this is not the case for your loss (if, for example, your loss</span>

<span class="s">        references a `Variable` of one of the model&#39;s layers), you can wrap your</span>

<span class="s">        loss in a zero-argument lambda. These losses are not tracked as part of</span>

<span class="s">        the model&#39;s topology since they can&#39;t be serialized.</span>

<span class="s">        Example:</span>

<span class="s">        ```python</span>

<span class="s">        inputs = tf.keras.Input(shape=(10,))</span>

<span class="s">        d = tf.keras.layers.Dense(10)</span>

<span class="s">        x = d(inputs)</span>

<span class="s">        outputs = tf.keras.layers.Dense(1)(x)</span>

<span class="s">        model = tf.keras.Model(inputs, outputs)</span>

<span class="s">        # Weight regularization.</span>

<span class="s">        model.add_loss(lambda: tf.reduce_mean(d.kernel))</span>

<span class="s">        ```</span>

<span class="s">        Args:</span>

<span class="s">          losses: Loss tensor, or list/tuple of tensors. Rather than tensors,</span>

<span class="s">            losses may also be zero-argument callables which create a loss</span>

<span class="s">            tensor.</span>

<span class="s">          **kwargs: Used for backwards compatibility only.</span>

<span class="s">        &quot;&quot;&quot;</span>

        <span class="n">kwargs</span>.<span class="nb">pop</span>(<span class="s">&quot;inputs&quot;</span>, <span class="n">None</span>)

        <span class="k">if</span> <span class="n">kwargs:</span>

            <span class="n">raise</span> <span class="n">TypeError</span>(<span class="nb">f</span><span class="s">&quot;Unknown keyword arguments: {kwargs.keys()}&quot;</span>)

        <span class="n">def</span> <span class="n">_tag_callable</span>(<span class="n">loss</span>):

            <span class="s">&quot;&quot;&quot;Tags callable loss tensor as `_unconditional_loss`.&quot;&quot;&quot;</span>

            <span class="k">if</span> <span class="n">callable</span>(<span class="n">loss</span>):

                <span class="c1"># We run the loss without autocasting, as regularizers are often</span>

                <span class="c1"># numerically unstable in float16.</span>

                <span class="k">with</span> <span class="n">autocast_variable</span>.<span class="n">enable_auto_cast_variables</span>(<span class="n">None</span>):

                    <span class="n">loss</span> = <span class="n">loss</span>()

            <span class="k">if</span> <span class="n">loss</span> <span class="k">is</span> <span class="n">None:</span>

                <span class="c1"># Will be filtered out when computing the .losses property</span>

                <span class="k">return</span> <span class="n">None</span>

            <span class="k">if</span> <span class="nb">not</span> <span class="n">tf</span>.<span class="n">is_tensor</span>(<span class="n">loss</span>):

                <span class="n">loss</span> = <span class="n">tf</span>.<span class="n">convert_to_tensor</span>(<span class="n">loss</span>, <span class="n">dtype</span>=<span class="n">backend</span>.<span class="n">floatx</span>())

            <span class="n">loss</span>.<span class="n">_unconditional_loss</span> = <span class="nb">True</span>

            <span class="k">return</span> <span class="n">loss</span>

        <span class="n">losses</span> = <span class="n">tf</span>.<span class="n">nest</span>.<span class="n">flatten</span>(<span class="n">losses</span>)

        <span class="n">callable_losses</span> = []

        <span class="n">eager_losses</span> = []

        <span class="n">symbolic_losses</span> = []

        <span class="k">for</span> <span class="n">loss</span> <span class="nb">in</span> <span class="n">losses:</span>

            <span class="k">if</span> <span class="n">callable</span>(<span class="n">loss</span>):

                <span class="n">callable_losses</span>.<span class="nb">append</span>(<span class="n">functools</span>.<span class="n">partial</span>(<span class="n">_tag_callable</span>, <span class="n">loss</span>))

                <span class="n">continue</span>

            <span class="k">if</span> <span class="n">loss</span> <span class="k">is</span> <span class="n">None:</span>

                <span class="n">continue</span>

            <span class="k">if</span> <span class="nb">not</span> <span class="n">tf</span>.<span class="n">is_tensor</span>(<span class="n">loss</span>) <span class="o">and</span> <span class="nb">not</span> <span class="n">isinstance</span>(

                <span class="n">loss</span>, <span class="n">keras_tensor</span>.<span class="n">KerasTensor</span>

            ):

                <span class="n">loss</span> = <span class="n">tf</span>.<span class="n">convert_to_tensor</span>(<span class="n">loss</span>, <span class="n">dtype</span>=<span class="n">backend</span>.<span class="n">floatx</span>())

            <span class="c1"># TF Functions should take the eager path.</span>

            <span class="k">if</span> (

                <span class="n">tf_utils</span>.<span class="n">is_symbolic_tensor</span>(<span class="n">loss</span>)

                <span class="o">or</span> <span class="n">isinstance</span>(<span class="n">loss</span>, <span class="n">keras_tensor</span>.<span class="n">KerasTensor</span>)

            ) <span class="o">and</span> <span class="nb">not</span> <span class="n">base_layer_utils</span>.<span class="n">is_in_tf_function</span>():

                <span class="n">symbolic_losses</span>.<span class="nb">append</span>(<span class="n">loss</span>)

            <span class="n">elif</span> <span class="n">tf</span>.<span class="n">is_tensor</span>(<span class="n">loss</span>):

                <span class="n">eager_losses</span>.<span class="nb">append</span>(<span class="n">loss</span>)

        <span class="nb">self</span>.<span class="n">_callable_losses</span>.<span class="n">extend</span>(<span class="n">callable_losses</span>)

        <span class="n">in_call_context</span> = <span class="n">base_layer_utils</span>.<span class="n">call_context</span>().<span class="n">in_call</span>

        <span class="k">if</span> <span class="n">eager_losses</span> <span class="o">and</span> <span class="nb">not</span> <span class="n">in_call_context:</span>

            <span class="n">raise</span> <span class="n">ValueError</span>(

                <span class="s">&quot;Expected a symbolic Tensors or a callable for the loss value. &quot;</span>

                <span class="s">&quot;Please wrap your loss computation in a zero argument `lambda`.&quot;</span>

            )

        <span class="nb">self</span>.<span class="n">_eager_losses</span>.<span class="n">extend</span>(<span class="n">eager_losses</span>)

        <span class="k">for</span> <span class="n">symbolic_loss</span> <span class="nb">in</span> <span class="n">symbolic_losses:</span>

            <span class="k">if</span> <span class="n">getattr</span>(<span class="nb">self</span>, <span class="s">&quot;_is_graph_network&quot;</span>, <span class="nb">False</span>):

                <span class="nb">self</span>.<span class="n">_graph_network_add_loss</span>(<span class="n">symbolic_loss</span>)

            <span class="n">else:</span>

                <span class="c1"># Possible a loss was added in a Layer&#39;s `build`.</span>

                <span class="nb">self</span>.<span class="n">_losses</span>.<span class="nb">append</span>(<span class="n">symbolic_loss</span>)
</code></pre></div>

</details>
<h4 id="add_metric_1">add_metric</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_metric</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">value</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Adds metric tensor to the layer.</p>
<p>This method can be used inside the <code>call()</code> method of a subclassed layer
or model.</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">MyMetricLayer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MyMetricLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;my_metric_layer&#39;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;metric_1&#39;</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;metric_2&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">inputs</span>
</code></pre></div>

<p>This method can also be called directly on a Functional Model during
construction. In this case, any tensor passed to this Model must
be symbolic and be able to be traced back to the model's <code>Input</code>s. These
metrics become part of the model's topology and are tracked when you
save the model via <code>save()</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="n">math_ops</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;metric_1&#39;</span><span class="p">)</span>
</code></pre></div>

<p>Note: Calling <code>add_metric()</code> with the result of a metric object on a
Functional Model, as shown in the example below, is not supported. This
is because we cannot trace the metric result tensor back to the model's
inputs.</p>
<div class="codehilite"><pre><span></span><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">()(</span><span class="n">x</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;metric_1&#39;</span><span class="p">)</span>
</code></pre></div>

<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>value</td>
<td>None</td>
<td>Metric tensor.</td>
<td>None</td>
</tr>
<tr>
<td>name</td>
<td>None</td>
<td>String metric name.</td>
<td>None</td>
</tr>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Additional keyword arguments for backward compatibility.<br>Accepted values:<br><code>aggregation</code> - When the <code>value</code> tensor provided is not the result<br>of calling a <code>keras.Metric</code> instance, it will be aggregated by<br>default using a <code>keras.Metric.Mean</code>.</td>
<td>None</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">add_metric</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">value</span><span class="p">,</span><span class="w"> </span><span class="k">name</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Adds metric tensor to the layer.</span>

<span class="s2">        This method can be used inside the `call()` method of a subclassed layer</span>

<span class="s2">        or model.</span>

<span class="s2">        ```python</span>

<span class="s2">        class MyMetricLayer(tf.keras.layers.Layer):</span>

<span class="s2">          def __init__(self):</span>

<span class="s2">            super(MyMetricLayer, self).__init__(name=&#39;my_metric_layer&#39;)</span>

<span class="s2">            self.mean = tf.keras.metrics.Mean(name=&#39;metric_1&#39;)</span>

<span class="s2">          def call(self, inputs):</span>

<span class="s2">            self.add_metric(self.mean(inputs))</span>

<span class="s2">            self.add_metric(tf.reduce_sum(inputs), name=&#39;metric_2&#39;)</span>

<span class="s2">            return inputs</span>

<span class="s2">        ```</span>

<span class="s2">        This method can also be called directly on a Functional Model during</span>

<span class="s2">        construction. In this case, any tensor passed to this Model must</span>

<span class="s2">        be symbolic and be able to be traced back to the model&#39;s `Input`s. These</span>

<span class="s2">        metrics become part of the model&#39;s topology and are tracked when you</span>

<span class="s2">        save the model via `save()`.</span>

<span class="s2">        ```python</span>

<span class="s2">        inputs = tf.keras.Input(shape=(10,))</span>

<span class="s2">        x = tf.keras.layers.Dense(10)(inputs)</span>

<span class="s2">        outputs = tf.keras.layers.Dense(1)(x)</span>

<span class="s2">        model = tf.keras.Model(inputs, outputs)</span>

<span class="s2">        model.add_metric(math_ops.reduce_sum(x), name=&#39;metric_1&#39;)</span>

<span class="s2">        ```</span>

<span class="s2">        Note: Calling `add_metric()` with the result of a metric object on a</span>

<span class="s2">        Functional Model, as shown in the example below, is not supported. This</span>

<span class="s2">        is because we cannot trace the metric result tensor back to the model&#39;s</span>

<span class="s2">        inputs.</span>

<span class="s2">        ```python</span>

<span class="s2">        inputs = tf.keras.Input(shape=(10,))</span>

<span class="s2">        x = tf.keras.layers.Dense(10)(inputs)</span>

<span class="s2">        outputs = tf.keras.layers.Dense(1)(x)</span>

<span class="s2">        model = tf.keras.Model(inputs, outputs)</span>

<span class="s2">        model.add_metric(tf.keras.metrics.Mean()(x), name=&#39;metric_1&#39;)</span>

<span class="s2">        ```</span>

<span class="s2">        Args:</span>

<span class="s2">          value: Metric tensor.</span>

<span class="s2">          name: String metric name.</span>

<span class="s2">          **kwargs: Additional keyword arguments for backward compatibility.</span>

<span class="s2">            Accepted values:</span>

<span class="s2">            `aggregation` - When the `value` tensor provided is not the result</span>

<span class="s2">            of calling a `keras.Metric` instance, it will be aggregated by</span>

<span class="s2">            default using a `keras.Metric.Mean`.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">kwargs_keys</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">list</span><span class="p">(</span><span class="n">kwargs</span><span class="p">.</span><span class="k">keys</span><span class="p">())</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">len</span><span class="p">(</span><span class="n">kwargs_keys</span><span class="p">)</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="k">or</span><span class="w"> </span><span class="p">(</span>

<span class="w">            </span><span class="n">len</span><span class="p">(</span><span class="n">kwargs_keys</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">kwargs_keys</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="s2">&quot;aggregation&quot;</span>

<span class="w">        </span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="n">raise</span><span class="w"> </span><span class="n">TypeError</span><span class="p">(</span>

<span class="w">                </span><span class="n">f</span><span class="s2">&quot;Unknown keyword arguments: {kwargs.keys()}. &quot;</span>

<span class="w">                </span><span class="s2">&quot;Expected `aggregation`.&quot;</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="n">from_metric_obj</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hasattr</span><span class="p">(</span><span class="k">value</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;_metric_obj&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="n">is_symbolic</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="k">value</span><span class="p">,</span><span class="w"> </span><span class="n">keras_tensor</span><span class="p">.</span><span class="n">KerasTensor</span><span class="p">)</span>

<span class="w">        </span><span class="n">in_call_context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">base_layer_utils</span><span class="p">.</span><span class="n">call_context</span><span class="p">().</span><span class="n">in_call</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="k">name</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">from_metric_obj</span><span class="o">:</span>

<span class="w">            </span><span class="c1"># Eg. `self.add_metric(math_ops.reduce_sum(x))` In eager mode, we</span>

<span class="w">            </span><span class="c1"># use metric name to lookup a metric. Without a name, a new Mean</span>

<span class="w">            </span><span class="c1"># metric wrapper will be created on every model/layer call. So, we</span>

<span class="w">            </span><span class="c1"># raise an error when no name is provided. We will do the same for</span>

<span class="w">            </span><span class="c1"># symbolic mode for consistency although a name will be generated if</span>

<span class="w">            </span><span class="c1"># no name is provided.</span>

<span class="w">            </span><span class="c1"># We will not raise this error in the foll use case for the sake of</span>

<span class="w">            </span><span class="c1"># consistency as name in provided in the metric constructor.</span>

<span class="w">            </span><span class="c1"># mean = metrics.Mean(name=&#39;my_metric&#39;)</span>

<span class="w">            </span><span class="c1"># model.add_metric(mean(outputs))</span>

<span class="w">            </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                </span><span class="s2">&quot;Please provide a name for your metric like &quot;</span>

<span class="w">                </span><span class="s2">&quot;`self.add_metric(tf.reduce_sum(inputs), &quot;</span>

<span class="w">                </span><span class="s2">&quot;name=&#39;mean_activation&#39;)`&quot;</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="n">elif</span><span class="w"> </span><span class="n">from_metric_obj</span><span class="o">:</span>

<span class="w">            </span><span class="k">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">value</span><span class="p">.</span><span class="n">_metric_obj</span><span class="p">.</span><span class="k">name</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">in_call_context</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">is_symbolic</span><span class="o">:</span>

<span class="w">            </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                </span><span class="s2">&quot;Expected a symbolic Tensor for the metric value, received: &quot;</span>

<span class="w">                </span><span class="o">+</span><span class="w"> </span><span class="n">str</span><span class="p">(</span><span class="k">value</span><span class="p">)</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="c1"># If a metric was added in a Layer&#39;s `call` or `build`.</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">in_call_context</span><span class="w"> </span><span class="k">or</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;_is_graph_network&quot;</span><span class="p">,</span><span class="w"> </span><span class="no">False</span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="c1"># TF Function path should take the eager path.</span>

<span class="w">            </span><span class="c1"># If the given metric is available in `metrics` list we just update</span>

<span class="w">            </span><span class="c1"># state on it, otherwise we create a new metric instance and</span>

<span class="w">            </span><span class="c1"># add it to the `metrics` list.</span>

<span class="w">            </span><span class="n">metric_obj</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="k">value</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;_metric_obj&quot;</span><span class="p">,</span><span class="w"> </span><span class="k">None</span><span class="p">)</span>

<span class="w">            </span><span class="c1"># Tensors that come from a Metric object already updated the Metric</span>

<span class="w">            </span><span class="c1"># state.</span>

<span class="w">            </span><span class="n">should_update_state</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">metric_obj</span>

<span class="w">            </span><span class="k">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">metric_obj</span><span class="p">.</span><span class="k">name</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">metric_obj</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="k">name</span>

<span class="w">            </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_metrics_lock</span><span class="o">:</span>

<span class="w">                </span><span class="k">match</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_existing_metric</span><span class="p">(</span><span class="k">name</span><span class="p">)</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="k">match</span><span class="o">:</span>

<span class="w">                    </span><span class="n">metric_obj</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">match</span>

<span class="w">                </span><span class="n">elif</span><span class="w"> </span><span class="n">metric_obj</span><span class="o">:</span>

<span class="w">                    </span><span class="n">self</span><span class="p">.</span><span class="n">_metrics</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">metric_obj</span><span class="p">)</span>

<span class="w">                </span><span class="k">else</span><span class="o">:</span>

<span class="w">                    </span><span class="c1"># Build the metric object with the value&#39;s dtype if it</span>

<span class="w">                    </span><span class="c1"># defines one</span>

<span class="w">                    </span><span class="n">metric_obj</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">metrics_mod</span><span class="p">.</span><span class="n">Mean</span><span class="p">(</span>

<span class="w">                        </span><span class="k">name</span><span class="o">=</span><span class="k">name</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="o">=</span><span class="n">getattr</span><span class="p">(</span><span class="k">value</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;dtype&quot;</span><span class="p">,</span><span class="w"> </span><span class="k">None</span><span class="p">)</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">                    </span><span class="n">self</span><span class="p">.</span><span class="n">_metrics</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">metric_obj</span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">should_update_state</span><span class="o">:</span>

<span class="w">                </span><span class="n">metric_obj</span><span class="p">(</span><span class="k">value</span><span class="p">)</span>

<span class="w">        </span><span class="k">else</span><span class="o">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">from_metric_obj</span><span class="o">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                    </span><span class="s2">&quot;Using the result of calling a `Metric` object &quot;</span>

<span class="w">                    </span><span class="s2">&quot;when calling `add_metric` on a Functional &quot;</span>

<span class="w">                    </span><span class="s2">&quot;Model is not supported. Please pass the &quot;</span>

<span class="w">                    </span><span class="s2">&quot;Tensor to monitor directly.&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="c1"># Insert layers into the Keras Graph Network.</span>

<span class="w">            </span><span class="n">aggregation</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">from_metric_obj</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s2">&quot;mean&quot;</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">_graph_network_add_metric</span><span class="p">(</span><span class="k">value</span><span class="p">,</span><span class="w"> </span><span class="n">aggregation</span><span class="p">,</span><span class="w"> </span><span class="k">name</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="add_update_1">add_update</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_update</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">updates</span>
<span class="p">)</span>
</code></pre></div>

<p>Add update op(s), potentially dependent on layer inputs.</p>
<p>Weight updates (for instance, the updates of the moving mean and
variance in a BatchNormalization layer) may be dependent on the inputs
passed when calling a layer. Hence, when reusing the same layer on
different inputs <code>a</code> and <code>b</code>, some entries in <code>layer.updates</code> may be
dependent on <code>a</code> and some on <code>b</code>. This method automatically keeps track
of dependencies.</p>
<p>This call is ignored when eager execution is enabled (in that case,
variable updates are run on the fly and thus do not need to be tracked
for later execution).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>updates</td>
<td>None</td>
<td>Update op, or list/tuple of update ops, or zero-arg callable<br>that returns an update op. A zero-arg callable should be passed in<br>order to disable running the updates by setting <code>trainable=False</code><br>on this Layer, when executing in Eager mode.</td>
<td>None</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@doc_controls.do_not_doc_inheritable</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">add_update</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">updates</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Add update op(s), potentially dependent on layer inputs.</span>

<span class="s2">        Weight updates (for instance, the updates of the moving mean and</span>

<span class="s2">        variance in a BatchNormalization layer) may be dependent on the inputs</span>

<span class="s2">        passed when calling a layer. Hence, when reusing the same layer on</span>

<span class="s2">        different inputs `a` and `b`, some entries in `layer.updates` may be</span>

<span class="s2">        dependent on `a` and some on `b`. This method automatically keeps track</span>

<span class="s2">        of dependencies.</span>

<span class="s2">        This call is ignored when eager execution is enabled (in that case,</span>

<span class="s2">        variable updates are run on the fly and thus do not need to be tracked</span>

<span class="s2">        for later execution).</span>

<span class="s2">        Args:</span>

<span class="s2">          updates: Update op, or list/tuple of update ops, or zero-arg callable</span>

<span class="s2">            that returns an update op. A zero-arg callable should be passed in</span>

<span class="s2">            order to disable running the updates by setting `trainable=False`</span>

<span class="s2">            on this Layer, when executing in Eager mode.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">call_context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">base_layer_utils</span><span class="p">.</span><span class="n">call_context</span><span class="p">()</span>

<span class="w">        </span><span class="c1"># No need to run updates during Functional API construction.</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">call_context</span><span class="p">.</span><span class="n">in_keras_graph</span><span class="o">:</span>

<span class="w">            </span><span class="k">return</span>

<span class="w">        </span><span class="c1"># Callable updates are disabled by setting `trainable=False`.</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">call_context</span><span class="p">.</span><span class="n">frozen</span><span class="o">:</span>

<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="k">update</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">updates</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">callable</span><span class="p">(</span><span class="k">update</span><span class="p">)</span><span class="o">:</span>

<span class="w">                    </span><span class="k">update</span><span class="p">()</span>
</code></pre></div>

</details>
<h4 id="add_variable_1">add_variable</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_variable</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Deprecated, do NOT use! Alias for <code>add_weight</code>.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@doc_controls.do_not_doc_inheritable</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">add_variable</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Deprecated, do NOT use! Alias for `add_weight`.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="k">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span>

<span class="w">            </span><span class="s2">&quot;`layer.add_variable` is deprecated and &quot;</span>

<span class="w">            </span><span class="s2">&quot;will be removed in a future version. &quot;</span>

<span class="w">            </span><span class="s2">&quot;Please use the `layer.add_weight()` method instead.&quot;</span><span class="p">,</span>

<span class="w">            </span><span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>

<span class="w">        </span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">add_weight</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="add_weight_1">add_weight</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_weight</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">initializer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">trainable</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">constraint</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">use_resource</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">synchronization</span><span class="o">=&lt;</span><span class="n">VariableSynchronization</span><span class="o">.</span><span class="n">AUTO</span><span class="p">:</span> <span class="mi">0</span><span class="o">&gt;</span><span class="p">,</span>
    <span class="n">aggregation</span><span class="o">=&lt;</span><span class="n">VariableAggregationV2</span><span class="o">.</span><span class="n">NONE</span><span class="p">:</span> <span class="mi">0</span><span class="o">&gt;</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Adds a new variable to the layer.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>name</td>
<td>None</td>
<td>Variable name.</td>
<td>None</td>
</tr>
<tr>
<td>shape</td>
<td>None</td>
<td>Variable shape. Defaults to scalar if unspecified.</td>
<td>scalar if unspecified</td>
</tr>
<tr>
<td>dtype</td>
<td>None</td>
<td>The type of the variable. Defaults to <code>self.dtype</code>.</td>
<td><code>self.dtype</code></td>
</tr>
<tr>
<td>initializer</td>
<td>None</td>
<td>Initializer instance (callable).</td>
<td>None</td>
</tr>
<tr>
<td>regularizer</td>
<td>None</td>
<td>Regularizer instance (callable).</td>
<td>None</td>
</tr>
<tr>
<td>trainable</td>
<td>None</td>
<td>Boolean, whether the variable should be part of the layer's<br>"trainable_variables" (e.g. variables, biases)<br>or "non_trainable_variables" (e.g. BatchNorm mean and variance).<br>Note that <code>trainable</code> cannot be <code>True</code> if <code>synchronization</code><br>is set to <code>ON_READ</code>.</td>
<td>None</td>
</tr>
<tr>
<td>constraint</td>
<td>None</td>
<td>Constraint instance (callable).</td>
<td>None</td>
</tr>
<tr>
<td>use_resource</td>
<td>None</td>
<td>Whether to use a <code>ResourceVariable</code> or not.<br>See <a href="&lt;br&gt;https://www.tensorflow.org/guide/migrate/tf1_vs_tf2#resourcevariables_instead_of_referencevariables">this guide</a><br> for more information.</td>
<td>None</td>
</tr>
<tr>
<td>synchronization</td>
<td>None</td>
<td>Indicates when a distributed a variable will be<br>aggregated. Accepted values are constants defined in the class<br><code>tf.VariableSynchronization</code>. By default the synchronization is set<br>to <code>AUTO</code> and the current <code>DistributionStrategy</code> chooses when to<br>synchronize. If <code>synchronization</code> is set to <code>ON_READ</code>, <code>trainable</code><br>must not be set to <code>True</code>.</td>
<td>None</td>
</tr>
<tr>
<td>aggregation</td>
<td>None</td>
<td>Indicates how a distributed variable will be aggregated.<br>Accepted values are constants defined in the class<br><code>tf.VariableAggregation</code>.</td>
<td>None</td>
</tr>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Additional keyword arguments. Accepted values are <code>getter</code>,<br><code>collections</code>, <code>experimental_autocast</code> and <code>caching_device</code>.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>The variable created.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>When giving unsupported dtype and no initializer or when<br>trainable has been set to True with synchronization set as<br><code>ON_READ</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="p">@</span><span class="n">doc_controls</span><span class="p">.</span><span class="n">for_subclass_implementers</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">add_weight</span><span class="p">(</span>

<span class="w">        </span><span class="nb">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">name</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">shape</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">dtype</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">initializer</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">regularizer</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">trainable</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">constraint</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">use_resource</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">synchronization</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">VariableSynchronization</span><span class="p">.</span><span class="n">AUTO</span><span class="p">,</span>

<span class="w">        </span><span class="n">aggregation</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">VariableAggregation</span><span class="p">.</span><span class="n">NONE</span><span class="p">,</span>

<span class="w">        </span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s">&quot;&quot;&quot;Adds a new variable to the layer.</span>

<span class="w">        </span><span class="nl">Args</span><span class="p">:</span>

<span class="w">          </span><span class="nl">name</span><span class="p">:</span><span class="w"> </span><span class="n">Variable</span><span class="w"> </span><span class="n">name</span><span class="p">.</span>

<span class="w">          </span><span class="nl">shape</span><span class="p">:</span><span class="w"> </span><span class="n">Variable</span><span class="w"> </span><span class="n">shape</span><span class="p">.</span><span class="w"> </span><span class="n">Defaults</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">scalar</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">unspecified</span><span class="p">.</span>

<span class="w">          </span><span class="nl">dtype</span><span class="p">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">type</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">variable</span><span class="p">.</span><span class="w"> </span><span class="n">Defaults</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="err">`</span><span class="nb">self</span><span class="p">.</span><span class="n">dtype</span><span class="err">`</span><span class="p">.</span>

<span class="w">          </span><span class="nl">initializer</span><span class="p">:</span><span class="w"> </span><span class="n">Initializer</span><span class="w"> </span><span class="n">instance</span><span class="w"> </span><span class="p">(</span><span class="n">callable</span><span class="p">).</span>

<span class="w">          </span><span class="nl">regularizer</span><span class="p">:</span><span class="w"> </span><span class="n">Regularizer</span><span class="w"> </span><span class="n">instance</span><span class="w"> </span><span class="p">(</span><span class="n">callable</span><span class="p">).</span>

<span class="w">          </span><span class="nl">trainable</span><span class="p">:</span><span class="w"> </span><span class="kt">Boolean</span><span class="p">,</span><span class="w"> </span><span class="n">whether</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">variable</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">part</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">layer</span><span class="err">&#39;</span><span class="n">s</span>

<span class="w">            </span><span class="s">&quot;trainable_variables&quot;</span><span class="w"> </span><span class="p">(</span><span class="n">e</span><span class="p">.</span><span class="n">g</span><span class="p">.</span><span class="w"> </span><span class="n">variables</span><span class="p">,</span><span class="w"> </span><span class="n">biases</span><span class="p">)</span>

<span class="w">            </span><span class="n">or</span><span class="w"> </span><span class="s">&quot;non_trainable_variables&quot;</span><span class="w"> </span><span class="p">(</span><span class="n">e</span><span class="p">.</span><span class="n">g</span><span class="p">.</span><span class="w"> </span><span class="n">BatchNorm</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">variance</span><span class="p">).</span>

<span class="w">            </span><span class="n">Note</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="err">`</span><span class="n">trainable</span><span class="err">`</span><span class="w"> </span><span class="n">cannot</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="err">`</span><span class="n">True</span><span class="err">`</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="err">`</span><span class="n">synchronization</span><span class="err">`</span>

<span class="w">            </span><span class="n">is</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="err">`</span><span class="n">ON_READ</span><span class="err">`</span><span class="p">.</span>

<span class="w">          </span><span class="nl">constraint</span><span class="p">:</span><span class="w"> </span><span class="n">Constraint</span><span class="w"> </span><span class="n">instance</span><span class="w"> </span><span class="p">(</span><span class="n">callable</span><span class="p">).</span>

<span class="w">          </span><span class="nl">use_resource</span><span class="p">:</span><span class="w"> </span><span class="n">Whether</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">use</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="err">`</span><span class="n">ResourceVariable</span><span class="err">`</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">not</span><span class="p">.</span>

<span class="w">            </span><span class="n">See</span><span class="w"> </span><span class="p">[</span><span class="n">this</span><span class="w"> </span><span class="n">guide</span><span class="p">](</span>

<span class="w">            </span><span class="nl">https</span><span class="p">:</span><span class="c1">//www.tensorflow.org/guide/migrate/tf1_vs_tf2#resourcevariables_instead_of_referencevariables)</span>

<span class="w">             </span><span class="k">for</span><span class="w"> </span><span class="n">more</span><span class="w"> </span><span class="n">information</span><span class="p">.</span>

<span class="w">          </span><span class="nl">synchronization</span><span class="p">:</span><span class="w"> </span><span class="n">Indicates</span><span class="w"> </span><span class="n">when</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">distributed</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">variable</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">be</span>

<span class="w">            </span><span class="n">aggregated</span><span class="p">.</span><span class="w"> </span><span class="n">Accepted</span><span class="w"> </span><span class="n">values</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">constants</span><span class="w"> </span><span class="n">defined</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">class</span>

<span class="w">            </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">VariableSynchronization</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">By</span><span class="w"> </span><span class="k">default</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">synchronization</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">set</span>

<span class="w">            </span><span class="n">to</span><span class="w"> </span><span class="err">`</span><span class="n">AUTO</span><span class="err">`</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">current</span><span class="w"> </span><span class="err">`</span><span class="n">DistributionStrategy</span><span class="err">`</span><span class="w"> </span><span class="n">chooses</span><span class="w"> </span><span class="n">when</span><span class="w"> </span><span class="n">to</span>

<span class="w">            </span><span class="n">synchronize</span><span class="p">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="err">`</span><span class="n">synchronization</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="err">`</span><span class="n">ON_READ</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="err">`</span><span class="n">trainable</span><span class="err">`</span>

<span class="w">            </span><span class="n">must</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="err">`</span><span class="n">True</span><span class="err">`</span><span class="p">.</span>

<span class="w">          </span><span class="nl">aggregation</span><span class="p">:</span><span class="w"> </span><span class="n">Indicates</span><span class="w"> </span><span class="n">how</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">distributed</span><span class="w"> </span><span class="n">variable</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">aggregated</span><span class="p">.</span>

<span class="w">            </span><span class="n">Accepted</span><span class="w"> </span><span class="n">values</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">constants</span><span class="w"> </span><span class="n">defined</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">class</span>

<span class="w">            </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">VariableAggregation</span><span class="err">`</span><span class="p">.</span>

<span class="w">          </span><span class="o">**</span><span class="n">kwargs</span><span class="o">:</span><span class="w"> </span><span class="n">Additional</span><span class="w"> </span><span class="n">keyword</span><span class="w"> </span><span class="n">arguments</span><span class="p">.</span><span class="w"> </span><span class="n">Accepted</span><span class="w"> </span><span class="n">values</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="err">`</span><span class="k">getter</span><span class="err">`</span><span class="p">,</span>

<span class="w">            </span><span class="err">`</span><span class="n">collections</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="err">`</span><span class="n">experimental_autocast</span><span class="err">`</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="err">`</span><span class="n">caching_device</span><span class="err">`</span><span class="p">.</span>

<span class="w">        </span><span class="nl">Returns</span><span class="p">:</span>

<span class="w">          </span><span class="n">The</span><span class="w"> </span><span class="n">variable</span><span class="w"> </span><span class="n">created</span><span class="p">.</span>

<span class="w">        </span><span class="nl">Raises</span><span class="p">:</span>

<span class="w">          </span><span class="nl">ValueError</span><span class="p">:</span><span class="w"> </span><span class="n">When</span><span class="w"> </span><span class="n">giving</span><span class="w"> </span><span class="n">unsupported</span><span class="w"> </span><span class="n">dtype</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">no</span><span class="w"> </span><span class="n">initializer</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">when</span>

<span class="w">            </span><span class="n">trainable</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">been</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">True</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">synchronization</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">as</span>

<span class="w">            </span><span class="err">`</span><span class="n">ON_READ</span><span class="err">`</span><span class="p">.</span>

<span class="w">        </span><span class="s">&quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">None</span><span class="o">:</span>

<span class="w">            </span><span class="n">shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">()</span>

<span class="w">        </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">&quot;partitioner&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">)</span><span class="w">  </span><span class="err">#</span><span class="w"> </span><span class="n">Ignored</span><span class="p">.</span>

<span class="w">        </span><span class="cp"># Validate optional keyword arguments.</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">kwarg</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">kwargs</span><span class="o">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">kwarg</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="p">[</span>

<span class="w">                </span><span class="s">&quot;collections&quot;</span><span class="p">,</span>

<span class="w">                </span><span class="s">&quot;experimental_autocast&quot;</span><span class="p">,</span>

<span class="w">                </span><span class="s">&quot;caching_device&quot;</span><span class="p">,</span>

<span class="w">                </span><span class="s">&quot;getter&quot;</span><span class="p">,</span>

<span class="w">                </span><span class="s">&quot;layout&quot;</span><span class="p">,</span>

<span class="w">            </span><span class="p">]</span><span class="o">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">TypeError</span><span class="p">(</span><span class="s">&quot;Unknown keyword argument:&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">kwarg</span><span class="p">)</span>

<span class="w">        </span><span class="n">collections_arg</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">&quot;collections&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">)</span>

<span class="w">        </span><span class="cp"># &#39;experimental_autocast&#39; can be set to False by the caller to indicate</span>

<span class="w">        </span><span class="cp"># an AutoCastVariable should never be created.</span>

<span class="w">        </span><span class="n">autocast</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">&quot;experimental_autocast&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">True</span><span class="p">)</span>

<span class="w">        </span><span class="cp"># See the docstring for tf.Variable about the details for</span>

<span class="w">        </span><span class="cp"># caching_device.</span>

<span class="w">        </span><span class="n">caching_device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">&quot;caching_device&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">)</span>

<span class="w">        </span><span class="n">layout</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">&quot;layout&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">)</span>

<span class="w">        </span><span class="cp"># Specially handling of auto layout fetch, based on the variable name</span>

<span class="w">        </span><span class="cp"># and attribute name. For built-in keras layers, usually the variable</span>

<span class="w">        </span><span class="cp"># name, eg &#39;kernel&#39;, will match with a &#39;kernel_layout&#39; attribute name on</span>

<span class="w">        </span><span class="cp"># the instance. We will try to do this auto fetch if layout is not</span>

<span class="w">        </span><span class="cp"># explicitly specified. This is mainly a quick workaround for not</span>

<span class="w">        </span><span class="cp"># applying too many interface change to built-in layers, until DTensor</span>

<span class="w">        </span><span class="cp"># is a public API.  Also see dtensor.utils.allow_initializer_layout for</span>

<span class="w">        </span><span class="cp"># more details.</span>

<span class="w">        </span><span class="cp"># TODO(scottzhu): Remove this once dtensor is public to end user.</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">layout</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">name</span><span class="o">:</span>

<span class="w">            </span><span class="n">layout</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span><span class="w"> </span><span class="n">name</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s">&quot;_layout&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">dtype</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">None</span><span class="o">:</span>

<span class="w">            </span><span class="n">dtype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">dtype</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">backend</span><span class="p">.</span><span class="n">floatx</span><span class="p">()</span>

<span class="w">        </span><span class="n">dtype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">as_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">_dtype_policy</span><span class="p">.</span><span class="n">variable_dtype</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">None</span><span class="o">:</span>

<span class="w">            </span><span class="cp"># The policy is &quot;_infer&quot;, so we infer the policy from the variable</span>

<span class="w">            </span><span class="cp"># dtype.</span>

<span class="w">            </span><span class="nb">self</span><span class="p">.</span><span class="n">_set_dtype_policy</span><span class="p">(</span><span class="n">policy</span><span class="p">.</span><span class="n">Policy</span><span class="p">(</span><span class="n">dtype</span><span class="p">.</span><span class="n">base_dtype</span><span class="p">.</span><span class="n">name</span><span class="p">))</span>

<span class="w">        </span><span class="n">initializer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">initializers</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">initializer</span><span class="p">)</span>

<span class="w">        </span><span class="n">regularizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">regularizers</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">regularizer</span><span class="p">)</span>

<span class="w">        </span><span class="n">constraint</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">constraints</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">constraint</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">synchronization</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">VariableSynchronization</span><span class="p">.</span><span class="n">ON_READ</span><span class="o">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">trainable</span><span class="o">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                    </span><span class="s">&quot;Synchronization value can be set to &quot;</span>

<span class="w">                    </span><span class="s">&quot;VariableSynchronization.ON_READ only for non-trainable &quot;</span>

<span class="w">                    </span><span class="s">&quot;variables. You have specified trainable=True and &quot;</span>

<span class="w">                    </span><span class="s">&quot;synchronization=VariableSynchronization.ON_READ.&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="nl">else</span><span class="p">:</span>

<span class="w">                </span><span class="cp"># Set trainable to be false when variable is to be synced on</span>

<span class="w">                </span><span class="cp"># read.</span>

<span class="w">                </span><span class="n">trainable</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">False</span>

<span class="w">        </span><span class="n">elif</span><span class="w"> </span><span class="n">trainable</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">None</span><span class="o">:</span>

<span class="w">            </span><span class="n">trainable</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">True</span>

<span class="w">        </span><span class="cp"># Initialize variable when no initializer provided</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">initializer</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">None</span><span class="o">:</span>

<span class="w">            </span><span class="cp"># If dtype is DT_FLOAT, provide a uniform unit scaling initializer</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">dtype</span><span class="p">.</span><span class="n">is_floating</span><span class="o">:</span>

<span class="w">                </span><span class="n">initializer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">initializers</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">&quot;glorot_uniform&quot;</span><span class="p">)</span>

<span class="w">            </span><span class="cp"># If dtype is DT_INT/DT_UINT, provide a default value `zero`</span>

<span class="w">            </span><span class="cp"># If dtype is DT_BOOL, provide a default value `FALSE`</span>

<span class="w">            </span><span class="n">elif</span><span class="w"> </span><span class="n">dtype</span><span class="p">.</span><span class="n">is_integer</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">dtype</span><span class="p">.</span><span class="n">is_unsigned</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">dtype</span><span class="p">.</span><span class="n">is_bool</span><span class="o">:</span>

<span class="w">                </span><span class="n">initializer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">initializers</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">&quot;zeros&quot;</span><span class="p">)</span>

<span class="w">            </span><span class="cp"># NOTES:Do we need to support for handling DT_STRING and DT_COMPLEX</span>

<span class="w">            </span><span class="cp"># here?</span>

<span class="w">            </span><span class="n">elif</span><span class="w"> </span><span class="s">&quot;getter&quot;</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">kwargs</span><span class="o">:</span>

<span class="w">                </span><span class="cp"># When `getter` is specified, it&#39;s possibly fine for</span>

<span class="w">                </span><span class="cp"># `initializer` to be None since it&#39;s up to the custom `getter`</span>

<span class="w">                </span><span class="cp"># to raise error in case it indeed needs `initializer`.</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                    </span><span class="n">f</span><span class="s">&quot;An initializer for variable {name} of type &quot;</span>

<span class="w">                    </span><span class="n">f</span><span class="s">&quot;{dtype.base_dtype} is required for layer &quot;</span>

<span class="w">                    </span><span class="n">f</span><span class="s">&quot;{self.name}. Received: {initializer}.&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">        </span><span class="k">getter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">&quot;getter&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">base_layer_utils</span><span class="p">.</span><span class="n">make_variable</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span>

<span class="w">            </span><span class="n">autocast</span>

<span class="w">            </span><span class="n">and</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">_dtype_policy</span><span class="p">.</span><span class="n">compute_dtype</span>

<span class="w">            </span><span class="o">!=</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">_dtype_policy</span><span class="p">.</span><span class="n">variable_dtype</span>

<span class="w">            </span><span class="n">and</span><span class="w"> </span><span class="n">dtype</span><span class="p">.</span><span class="n">is_floating</span>

<span class="w">        </span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="n">old_getter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">getter</span>

<span class="w">            </span><span class="cp"># Wrap variable constructor to return an AutoCastVariable.</span>

<span class="w">            </span><span class="n">def</span><span class="w"> </span><span class="k">getter</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">variable</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">old_getter</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">autocast_variable</span><span class="p">.</span><span class="n">create_autocast_variable</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>

<span class="w">            </span><span class="cp"># Also the caching_device does not work with the mixed precision</span>

<span class="w">            </span><span class="cp"># API, disable it if it is specified.</span>

<span class="w">            </span><span class="cp"># TODO(b/142020079): Re-enable it once the bug is fixed.</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">caching_device</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">None</span><span class="o">:</span>

<span class="w">                </span><span class="n">tf_logging</span><span class="p">.</span><span class="n">warning</span><span class="p">(</span>

<span class="w">                    </span><span class="s">&quot;`caching_device` does not work with mixed precision API. &quot;</span>

<span class="w">                    </span><span class="s">&quot;Ignoring user specified `caching_device`.&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">                </span><span class="n">caching_device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">layout</span><span class="o">:</span>

<span class="w">            </span><span class="k">getter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">functools</span><span class="p">.</span><span class="n">partial</span><span class="p">(</span><span class="k">getter</span><span class="p">,</span><span class="w"> </span><span class="n">layout</span><span class="o">=</span><span class="n">layout</span><span class="p">)</span>

<span class="w">        </span><span class="n">variable</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">_add_variable_with_custom_getter</span><span class="p">(</span>

<span class="w">            </span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>

<span class="w">            </span><span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>

<span class="w">            </span><span class="cp"># TODO(allenl): a `make_variable` equivalent should be added as a</span>

<span class="w">            </span><span class="cp"># `Trackable` method.</span>

<span class="w">            </span><span class="k">getter</span><span class="o">=</span><span class="k">getter</span><span class="p">,</span>

<span class="w">            </span><span class="cp"># Manage errors in Layer rather than Trackable.</span>

<span class="w">            </span><span class="n">overwrite</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

<span class="w">            </span><span class="n">initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span>

<span class="w">            </span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>

<span class="w">            </span><span class="n">constraint</span><span class="o">=</span><span class="n">constraint</span><span class="p">,</span>

<span class="w">            </span><span class="n">trainable</span><span class="o">=</span><span class="n">trainable</span><span class="p">,</span>

<span class="w">            </span><span class="n">use_resource</span><span class="o">=</span><span class="n">use_resource</span><span class="p">,</span>

<span class="w">            </span><span class="n">collections</span><span class="o">=</span><span class="n">collections_arg</span><span class="p">,</span>

<span class="w">            </span><span class="n">synchronization</span><span class="o">=</span><span class="n">synchronization</span><span class="p">,</span>

<span class="w">            </span><span class="n">aggregation</span><span class="o">=</span><span class="n">aggregation</span><span class="p">,</span>

<span class="w">            </span><span class="n">caching_device</span><span class="o">=</span><span class="n">caching_device</span><span class="p">,</span>

<span class="w">        </span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">regularizer</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">None</span><span class="o">:</span>

<span class="w">            </span><span class="cp"># TODO(fchollet): in the future, this should be handled at the</span>

<span class="w">            </span><span class="cp"># level of variable creation, and weight regularization losses</span>

<span class="w">            </span><span class="cp"># should be variable attributes.</span>

<span class="w">            </span><span class="n">name_in_scope</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">variable</span><span class="p">.</span><span class="n">name</span><span class="p">[</span><span class="o">:</span><span class="w"> </span><span class="n">variable</span><span class="p">.</span><span class="n">name</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="s">&quot;:&quot;</span><span class="p">)]</span>

<span class="w">            </span><span class="nb">self</span><span class="p">.</span><span class="n">_handle_weight_regularization</span><span class="p">(</span>

<span class="w">                </span><span class="n">name_in_scope</span><span class="p">,</span><span class="w"> </span><span class="n">variable</span><span class="p">,</span><span class="w"> </span><span class="n">regularizer</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">base_layer_utils</span><span class="p">.</span><span class="n">is_split_variable</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">v</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">variable</span><span class="o">:</span>

<span class="w">                </span><span class="n">backend</span><span class="p">.</span><span class="n">track_variable</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">trainable</span><span class="o">:</span>

<span class="w">                    </span><span class="nb">self</span><span class="p">.</span><span class="n">_trainable_weights</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

<span class="w">                </span><span class="nl">else</span><span class="p">:</span>

<span class="w">                    </span><span class="nb">self</span><span class="p">.</span><span class="n">_non_trainable_weights</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

<span class="w">        </span><span class="nl">else</span><span class="p">:</span>

<span class="w">            </span><span class="n">backend</span><span class="p">.</span><span class="n">track_variable</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">trainable</span><span class="o">:</span>

<span class="w">                </span><span class="nb">self</span><span class="p">.</span><span class="n">_trainable_weights</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>

<span class="w">            </span><span class="nl">else</span><span class="p">:</span>

<span class="w">                </span><span class="nb">self</span><span class="p">.</span><span class="n">_non_trainable_weights</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">variable</span>
</code></pre></div>

</details>
<h4 id="build_1">build</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">build</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_shape</span>
<span class="p">)</span>
</code></pre></div>

<p>Builds the model based on input shapes received.</p>
<p>This is to be used for subclassed models, which do not know at
instantiation time what their inputs look like.</p>
<p>This method only exists for users who want to call <code>model.build()</code> in a
standalone way (as a substitute for calling the model on real data to
build it). It will never be called by the framework (and thus it will
never throw unexpected errors in an unrelated workflow).</p>
<p>Args:
 input_shape: Single tuple, <code>TensorShape</code> instance, or list/dict of
   shapes, where shapes are tuples, integers, or <code>TensorShape</code>
   instances.</p>
<p>Raises:
  ValueError:
    1. In case of invalid user-provided data (not of type tuple,
       list, <code>TensorShape</code>, or dict).
    2. If the model requires call arguments that are agnostic
       to the input shapes (positional or keyword arg in call
       signature).
    3. If not all layers were properly built.
    4. If float type inputs are not supported within the layers.</p>
<p>In each of these cases, the user should build their model by calling
  it on real tensor data.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@generic_utils.default</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">build</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">input_shape</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Builds the model based on input shapes received.</span>

<span class="s2">        This is to be used for subclassed models, which do not know at</span>

<span class="s2">        instantiation time what their inputs look like.</span>

<span class="s2">        This method only exists for users who want to call `model.build()` in a</span>

<span class="s2">        standalone way (as a substitute for calling the model on real data to</span>

<span class="s2">        build it). It will never be called by the framework (and thus it will</span>

<span class="s2">        never throw unexpected errors in an unrelated workflow).</span>

<span class="s2">        Args:</span>

<span class="s2">         input_shape: Single tuple, `TensorShape` instance, or list/dict of</span>

<span class="s2">           shapes, where shapes are tuples, integers, or `TensorShape`</span>

<span class="s2">           instances.</span>

<span class="s2">        Raises:</span>

<span class="s2">          ValueError:</span>

<span class="s2">            1. In case of invalid user-provided data (not of type tuple,</span>

<span class="s2">               list, `TensorShape`, or dict).</span>

<span class="s2">            2. If the model requires call arguments that are agnostic</span>

<span class="s2">               to the input shapes (positional or keyword arg in call</span>

<span class="s2">               signature).</span>

<span class="s2">            3. If not all layers were properly built.</span>

<span class="s2">            4. If float type inputs are not supported within the layers.</span>

<span class="s2">          In each of these cases, the user should build their model by calling</span>

<span class="s2">          it on real tensor data.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_is_graph_network</span><span class="o">:</span>

<span class="w">            </span><span class="k">super</span><span class="p">().</span><span class="n">build</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>

<span class="w">            </span><span class="k">return</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">input_shape</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="o">:</span>

<span class="w">            </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                </span><span class="s2">&quot;Input shape must be defined when calling `build()` on &quot;</span>

<span class="w">                </span><span class="s2">&quot;a `Model` subclass.&quot;</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="n">valid_types</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">tuple</span><span class="p">,</span><span class="w"> </span><span class="k">list</span><span class="p">,</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">TensorShape</span><span class="p">,</span><span class="w"> </span><span class="n">dict</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span><span class="w"> </span><span class="n">valid_types</span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                </span><span class="s2">&quot;Specified input shape is not one of the valid types. &quot;</span>

<span class="w">                </span><span class="s2">&quot;Please specify a batch input shape of type tuple or &quot;</span>

<span class="w">                </span><span class="s2">&quot;list of input shapes. User provided &quot;</span>

<span class="w">                </span><span class="s2">&quot;input type: {}.&quot;</span><span class="p">.</span><span class="k">format</span><span class="p">(</span><span class="k">type</span><span class="p">(</span><span class="n">input_shape</span><span class="p">))</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">input_shape</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">inputs</span><span class="o">:</span>

<span class="w">            </span><span class="c1"># We create placeholders for the `None`s in the shape and build the</span>

<span class="w">            </span><span class="c1"># model in a Graph. Since tf.Variable is compatible with both eager</span>

<span class="w">            </span><span class="c1"># execution and graph building, the variables created after building</span>

<span class="w">            </span><span class="c1"># the model in a Graph are still valid when executing eagerly.</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">executing_eagerly</span><span class="p">()</span><span class="o">:</span>

<span class="w">                </span><span class="n">graph</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">__internal__</span><span class="p">.</span><span class="n">FuncGraph</span><span class="p">(</span><span class="s2">&quot;build_graph&quot;</span><span class="p">)</span>

<span class="w">            </span><span class="k">else</span><span class="o">:</span>

<span class="w">                </span><span class="n">graph</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">backend</span><span class="p">.</span><span class="n">get_graph</span><span class="p">()</span>

<span class="w">            </span><span class="k">with</span><span class="w"> </span><span class="n">graph</span><span class="p">.</span><span class="n">as_default</span><span class="p">()</span><span class="o">:</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span><span class="w"> </span><span class="k">list</span><span class="p">)</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">all</span><span class="p">(</span>

<span class="w">                    </span><span class="n">d</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">or</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">d</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">d</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">input_shape</span>

<span class="w">                </span><span class="p">)</span><span class="o">:</span>

<span class="w">                    </span><span class="n">input_shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tuple</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span><span class="w"> </span><span class="k">list</span><span class="p">)</span><span class="o">:</span>

<span class="w">                    </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">[</span>

<span class="w">                        </span><span class="n">base_layer_utils</span><span class="p">.</span><span class="n">generate_placeholders_from_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>

<span class="w">                        </span><span class="k">for</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">input_shape</span>

<span class="w">                    </span><span class="err">]</span>

<span class="w">                </span><span class="n">elif</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span><span class="w"> </span><span class="n">dict</span><span class="p">)</span><span class="o">:</span>

<span class="w">                    </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">{</span>

<span class="w">                        </span><span class="n">k</span><span class="o">:</span><span class="w"> </span><span class="n">base_layer_utils</span><span class="p">.</span><span class="n">generate_placeholders_from_shape</span><span class="p">(</span>

<span class="w">                            </span><span class="n">shape</span>

<span class="w">                        </span><span class="p">)</span>

<span class="w">                        </span><span class="k">for</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">input_shape</span><span class="p">.</span><span class="n">items</span><span class="p">()</span>

<span class="w">                    </span><span class="err">}</span>

<span class="w">                </span><span class="k">else</span><span class="o">:</span>

<span class="w">                    </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">base_layer_utils</span><span class="p">.</span><span class="n">generate_placeholders_from_shape</span><span class="p">(</span>

<span class="w">                        </span><span class="n">input_shape</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">                </span><span class="n">kwargs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">{}</span>

<span class="w">                </span><span class="n">call_signature</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_call_spec</span><span class="p">.</span><span class="n">full_argspec</span>

<span class="w">                </span><span class="n">call_args</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">call_signature</span><span class="p">.</span><span class="n">args</span>

<span class="w">                </span><span class="c1"># Exclude `self`, `inputs`, and any argument with a default</span>

<span class="w">                </span><span class="c1"># value.</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">len</span><span class="p">(</span><span class="n">call_args</span><span class="p">)</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">2</span><span class="o">:</span>

<span class="w">                    </span><span class="k">if</span><span class="w"> </span><span class="n">call_signature</span><span class="p">.</span><span class="n">defaults</span><span class="o">:</span>

<span class="w">                        </span><span class="n">call_args</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">call_args</span><span class="err">[</span><span class="mi">2</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="o">-</span><span class="n">len</span><span class="p">(</span><span class="n">call_signature</span><span class="p">.</span><span class="n">defaults</span><span class="p">)</span><span class="err">]</span>

<span class="w">                    </span><span class="k">else</span><span class="o">:</span>

<span class="w">                        </span><span class="n">call_args</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">call_args</span><span class="err">[</span><span class="mi">2</span><span class="o">:</span><span class="err">]</span>

<span class="w">                    </span><span class="k">for</span><span class="w"> </span><span class="n">arg</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">call_args</span><span class="o">:</span>

<span class="w">                        </span><span class="k">if</span><span class="w"> </span><span class="n">arg</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">&quot;training&quot;</span><span class="o">:</span>

<span class="w">                            </span><span class="c1"># Case where `training` is a positional arg with no</span>

<span class="w">                            </span><span class="c1"># default.</span>

<span class="w">                            </span><span class="n">kwargs</span><span class="err">[</span><span class="s2">&quot;training&quot;</span><span class="err">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="no">False</span>

<span class="w">                        </span><span class="k">else</span><span class="o">:</span>

<span class="w">                            </span><span class="c1"># Has invalid call signature with unknown positional</span>

<span class="w">                            </span><span class="c1"># arguments.</span>

<span class="w">                            </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                                </span><span class="s2">&quot;Currently, you cannot build your model if it &quot;</span>

<span class="w">                                </span><span class="s2">&quot;has positional or keyword arguments that are &quot;</span>

<span class="w">                                </span><span class="s2">&quot;not inputs to the model, but are required for &quot;</span>

<span class="w">                                </span><span class="s2">&quot;its `call()` method. Instead, in order to &quot;</span>

<span class="w">                                </span><span class="s2">&quot;instantiate and build your model, `call()` &quot;</span>

<span class="w">                                </span><span class="s2">&quot;your model on real tensor data with all &quot;</span>

<span class="w">                                </span><span class="s2">&quot;expected call arguments. The argument &quot;</span>

<span class="w">                                </span><span class="s2">&quot;for `call()` can be a single list/tuple that &quot;</span>

<span class="w">                                </span><span class="s2">&quot;contains multiple inputs.&quot;</span>

<span class="w">                            </span><span class="p">)</span>

<span class="w">                </span><span class="n">elif</span><span class="w"> </span><span class="n">len</span><span class="p">(</span><span class="n">call_args</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">2</span><span class="o">:</span>

<span class="w">                    </span><span class="c1"># Signature without `inputs`.</span>

<span class="w">                    </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                        </span><span class="s2">&quot;You can only call `build()` on a model if its &quot;</span>

<span class="w">                        </span><span class="s2">&quot;`call()` method accepts an `inputs` argument.&quot;</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">                </span><span class="n">try</span><span class="o">:</span>

<span class="w">                    </span><span class="n">self</span><span class="p">.</span><span class="k">call</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="w">                </span><span class="k">except</span><span class="w"> </span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="k">errors</span><span class="p">.</span><span class="n">InvalidArgumentError</span><span class="p">,</span><span class="w"> </span><span class="n">TypeError</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">e</span><span class="o">:</span>

<span class="w">                    </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                        </span><span class="s2">&quot;You cannot build your model by calling `build` &quot;</span>

<span class="w">                        </span><span class="s2">&quot;if your layers do not support float type inputs. &quot;</span>

<span class="w">                        </span><span class="s2">&quot;Instead, in order to instantiate and build your &quot;</span>

<span class="w">                        </span><span class="s2">&quot;model, call your model on real tensor data (of &quot;</span>

<span class="w">                        </span><span class="s2">&quot;the correct dtype).</span><span class="se">\n\n</span><span class="s2">The actual error from &quot;</span>

<span class="w">                        </span><span class="n">f</span><span class="s2">&quot;`call` is: {e}.&quot;</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">        </span><span class="k">super</span><span class="p">().</span><span class="n">build</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="call_1">call</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span>
</code></pre></div>

<p>Applies the model on each element of the input tensor.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>tf.Tensor</td>
<td>The input tensor</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>tf.Tensor</td>
<td>The output tensor with the model applied on each element.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">call</span><span class="p">(</span><span class="kr">self</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="o">:</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="o">:</span>

<span class="w">        </span><span class="s">&quot;&quot;&quot;</span>

<span class="s">        Applies the model on each element of the input tensor.</span>

<span class="s">        Parameters:</span>

<span class="s">            x (tf.Tensor): The input tensor</span>

<span class="s">        Returns:</span>

<span class="s">            tf.Tensor: The output tensor with the model applied on each element.</span>

<span class="s">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">perm</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">))</span>

<span class="w">        </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">vectorized_map</span><span class="p">(</span><span class="kr">self</span><span class="p">.</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">)</span>

<span class="w">        </span><span class="kr">return</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">perm</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">))</span>
</code></pre></div>

</details>
<h4 id="compile_1">compile</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compile</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">loss_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">weighted_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">run_eagerly</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">steps_per_execution</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">jit_compile</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Configures the model for training.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>optimizer</td>
<td>None</td>
<td>String (name of optimizer) or optimizer instance. See<br><code>tf.keras.optimizers</code>.</td>
<td>None</td>
</tr>
<tr>
<td>loss</td>
<td>None</td>
<td>Loss function. May be a string (name of loss function), or<br>a <code>tf.keras.losses.Loss</code> instance. See <code>tf.keras.losses</code>. A loss<br>function is any callable with the signature <code>loss = fn(y_true,&lt;br&gt;y_pred)</code>, where <code>y_true</code> are the ground truth values, and<br><code>y_pred</code> are the model's predictions.<br><code>y_true</code> should have shape<br><code>(batch_size, d0, .. dN)</code> (except in the case of<br>sparse loss functions such as<br>sparse categorical crossentropy which expects integer arrays of<br>shape <code>(batch_size, d0, .. dN-1)</code>).<br><code>y_pred</code> should have shape <code>(batch_size, d0, .. dN)</code>.<br>The loss function should return a float tensor.<br>If a custom <code>Loss</code> instance is<br>used and reduction is set to <code>None</code>, return value has shape<br><code>(batch_size, d0, .. dN-1)</code> i.e. per-sample or per-timestep loss<br>values; otherwise, it is a scalar. If the model has multiple<br>outputs, you can use a different loss on each output by passing a<br>dictionary or a list of losses. The loss value that will be<br>minimized by the model will then be the sum of all individual<br>losses, unless <code>loss_weights</code> is specified.</td>
<td>None</td>
</tr>
<tr>
<td>metrics</td>
<td>None</td>
<td>List of metrics to be evaluated by the model during<br>training and testing. Each of this can be a string (name of a<br>built-in function), function or a <code>tf.keras.metrics.Metric</code><br>instance. See <code>tf.keras.metrics</code>. Typically you will use<br><code>metrics=['accuracy']</code>.<br>A function is any callable with the signature <code>result = fn(y_true,&lt;br&gt;y_pred)</code>. To specify different metrics for different outputs of a<br>multi-output model, you could also pass a dictionary, such as<br><code>metrics={'output_a':'accuracy', 'output_b':['accuracy', 'mse']}</code>.<br>You can also pass a list to specify a metric or a list of metrics<br>for each output, such as<br><code>metrics=[['accuracy'], ['accuracy', 'mse']]</code><br>or <code>metrics=['accuracy', ['accuracy', 'mse']]</code>. When you pass the<br>strings 'accuracy' or 'acc', we convert this to one of<br><code>tf.keras.metrics.BinaryAccuracy</code>,<br><code>tf.keras.metrics.CategoricalAccuracy</code>,<br><code>tf.keras.metrics.SparseCategoricalAccuracy</code> based on the shapes<br>of the targets and of the model output. We do a similar<br>conversion for the strings 'crossentropy' and 'ce' as well.<br>The metrics passed here are evaluated without sample weighting; if<br>you would like sample weighting to apply, you can specify your<br>metrics via the <code>weighted_metrics</code> argument instead.</td>
<td>None</td>
</tr>
<tr>
<td>loss_weights</td>
<td>None</td>
<td>Optional list or dictionary specifying scalar<br>coefficients (Python floats) to weight the loss contributions of<br>different model outputs. The loss value that will be minimized by<br>the model will then be the <em>weighted sum</em> of all individual<br>losses, weighted by the <code>loss_weights</code> coefficients.  If a list,<br>it is expected to have a 1:1 mapping to the model's outputs. If a<br>dict, it is expected to map output names (strings) to scalar<br>coefficients.</td>
<td>None</td>
</tr>
<tr>
<td>weighted_metrics</td>
<td>None</td>
<td>List of metrics to be evaluated and weighted by<br><code>sample_weight</code> or <code>class_weight</code> during training and testing.</td>
<td>None</td>
</tr>
<tr>
<td>run_eagerly</td>
<td>None</td>
<td>Bool. Defaults to <code>False</code>. If <code>True</code>, this <code>Model</code>'s<br>logic will not be wrapped in a <code>tf.function</code>. Recommended to leave<br>this as <code>None</code> unless your <code>Model</code> cannot be run inside a<br><code>tf.function</code>. <code>run_eagerly=True</code> is not supported when using<br><code>tf.distribute.experimental.ParameterServerStrategy</code>.</td>
<td><code>False</code></td>
</tr>
<tr>
<td>steps_per_execution</td>
<td>None</td>
<td>Int. Defaults to 1. The number of batches to<br>run during each <code>tf.function</code> call. Running multiple batches<br>inside a single <code>tf.function</code> call can greatly improve performance<br>on TPUs or small models with a large Python overhead. At most, one<br>full epoch will be run each execution. If a number larger than the<br>size of the epoch is passed, the execution will be truncated to<br>the size of the epoch. Note that if <code>steps_per_execution</code> is set<br>to <code>N</code>, <code>Callback.on_batch_begin</code> and <code>Callback.on_batch_end</code><br>methods will only be called every <code>N</code> batches (i.e. before/after<br>each <code>tf.function</code> execution).</td>
<td>1</td>
</tr>
<tr>
<td>jit_compile</td>
<td>None</td>
<td>If <code>True</code>, compile the model training step with XLA.<br><a href="https://www.tensorflow.org/xla">XLA</a> is an optimizing compiler<br>for machine learning.<br><code>jit_compile</code> is not enabled for by default.<br>This option cannot be enabled with <code>run_eagerly=True</code>.<br>Note that <code>jit_compile=True</code><br>may not necessarily work for all models.<br>For more information on supported operations please refer to the<br><a href="https://www.tensorflow.org/xla">XLA documentation</a>.<br>Also refer to<br><a href="https://www.tensorflow.org/xla/known_issues">known XLA issues</a><br>for more details.</td>
<td>None</td>
</tr>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Arguments supported for backwards compatibility only.</td>
<td>None</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="p">@</span><span class="n">traceback_utils</span><span class="p">.</span><span class="n">filter_traceback</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">compile</span><span class="p">(</span>

<span class="w">        </span><span class="nb">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">optimizer</span><span class="o">=</span><span class="s">&quot;rmsprop&quot;</span><span class="p">,</span>

<span class="w">        </span><span class="n">loss</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">metrics</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">loss_weights</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">weighted_metrics</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">run_eagerly</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">jit_compile</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s">&quot;&quot;&quot;Configures the model for training.</span>

<span class="w">        </span><span class="nl">Example</span><span class="p">:</span>

<span class="w">        </span><span class="err">```</span><span class="n">python</span>

<span class="w">        </span><span class="n">model</span><span class="p">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">),</span>

<span class="w">                      </span><span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">BinaryCrossentropy</span><span class="p">(),</span>

<span class="w">                      </span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">BinaryAccuracy</span><span class="p">(),</span>

<span class="w">                               </span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">FalseNegatives</span><span class="p">()])</span>

<span class="w">        </span><span class="err">```</span>

<span class="w">        </span><span class="nl">Args</span><span class="p">:</span>

<span class="w">            </span><span class="nl">optimizer</span><span class="p">:</span><span class="w"> </span><span class="n">String</span><span class="w"> </span><span class="p">(</span><span class="n">name</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">optimizer</span><span class="p">)</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">optimizer</span><span class="w"> </span><span class="n">instance</span><span class="p">.</span><span class="w"> </span><span class="n">See</span>

<span class="w">              </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="err">`</span><span class="p">.</span>

<span class="w">            </span><span class="nl">loss</span><span class="p">:</span><span class="w"> </span><span class="n">Loss</span><span class="w"> </span><span class="n">function</span><span class="p">.</span><span class="w"> </span><span class="n">May</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">string</span><span class="w"> </span><span class="p">(</span><span class="n">name</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">function</span><span class="p">),</span><span class="w"> </span><span class="n">or</span>

<span class="w">              </span><span class="n">a</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">Loss</span><span class="err">`</span><span class="w"> </span><span class="n">instance</span><span class="p">.</span><span class="w"> </span><span class="n">See</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">A</span><span class="w"> </span><span class="n">loss</span>

<span class="w">              </span><span class="n">function</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">any</span><span class="w"> </span><span class="n">callable</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">signature</span><span class="w"> </span><span class="err">`</span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fn</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span>

<span class="w">              </span><span class="n">y_pred</span><span class="p">)</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="err">`</span><span class="n">y_true</span><span class="err">`</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">ground</span><span class="w"> </span><span class="n">truth</span><span class="w"> </span><span class="n">values</span><span class="p">,</span><span class="w"> </span><span class="n">and</span>

<span class="w">              </span><span class="err">`</span><span class="n">y_pred</span><span class="err">`</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="err">&#39;</span><span class="n">s</span><span class="w"> </span><span class="n">predictions</span><span class="p">.</span>

<span class="w">              </span><span class="err">`</span><span class="n">y_true</span><span class="err">`</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">shape</span>

<span class="w">              </span><span class="err">`</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="n">d0</span><span class="p">,</span><span class="w"> </span><span class="p">..</span><span class="w"> </span><span class="n">dN</span><span class="p">)</span><span class="err">`</span><span class="w"> </span><span class="p">(</span><span class="n">except</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">case</span><span class="w"> </span><span class="no">of</span>

<span class="w">              </span><span class="no">sparse</span><span class="w"> </span><span class="no">loss</span><span class="w"> </span><span class="no">functions</span><span class="w"> </span><span class="no">such</span><span class="w"> </span><span class="no">as</span>

<span class="w">              </span><span class="no">sparse</span><span class="w"> </span><span class="no">categorical</span><span class="w"> </span><span class="no">crossentropy</span><span class="w"> </span><span class="no">which</span><span class="w"> </span><span class="no">expects</span><span class="w"> </span><span class="no">integer</span><span class="w"> </span><span class="no">arrays</span><span class="w"> </span><span class="no">of</span>

<span class="w">              </span><span class="no">shape</span><span class="w"> </span><span class="err">`</span><span class="p">(</span><span class="no">batch_size</span><span class="p">,</span><span class="w"> </span><span class="no">d0</span><span class="p">,</span><span class="w"> </span><span class="p">..</span><span class="w"> </span><span class="no">dN</span><span class="mi">-1</span><span class="p">)</span><span class="err">`</span><span class="p">).</span>

<span class="w">              </span><span class="err">`</span><span class="no">y_pred</span><span class="err">`</span><span class="w"> </span><span class="no">should</span><span class="w"> </span><span class="no">have</span><span class="w"> </span><span class="no">shape</span><span class="w"> </span><span class="err">`</span><span class="p">(</span><span class="no">batch_size</span><span class="p">,</span><span class="w"> </span><span class="no">d0</span><span class="p">,</span><span class="w"> </span><span class="p">..</span><span class="w"> </span><span class="no">dN</span><span class="p">)</span><span class="err">`</span><span class="p">.</span>

<span class="w">              </span><span class="no">The</span><span class="w"> </span><span class="no">loss</span><span class="w"> </span><span class="no">function</span><span class="w"> </span><span class="no">should</span><span class="w"> </span><span class="no">return</span><span class="w"> </span><span class="no">a</span><span class="w"> </span><span class="no">float</span><span class="w"> </span><span class="no">tensor</span><span class="p">.</span>

<span class="w">              </span><span class="no">If</span><span class="w"> </span><span class="no">a</span><span class="w"> </span><span class="no">custom</span><span class="w"> </span><span class="err">`</span><span class="no">Loss</span><span class="err">`</span><span class="w"> </span><span class="no">instance</span><span class="w"> </span><span class="no">is</span>

<span class="w">              </span><span class="no">used</span><span class="w"> </span><span class="no">and</span><span class="w"> </span><span class="no">reduction</span><span class="w"> </span><span class="no">is</span><span class="w"> </span><span class="no">set</span><span class="w"> </span><span class="no">to</span><span class="w"> </span><span class="err">`</span><span class="no">None</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="no">return</span><span class="w"> </span><span class="no">value</span><span class="w"> </span><span class="no">has</span><span class="w"> </span><span class="no">shape</span>

<span class="w">              </span><span class="err">`</span><span class="p">(</span><span class="no">batch_size</span><span class="p">,</span><span class="w"> </span><span class="no">d0</span><span class="p">,</span><span class="w"> </span><span class="p">..</span><span class="w"> </span><span class="no">dN</span><span class="mi">-1</span><span class="p">)</span><span class="err">`</span><span class="w"> </span><span class="no">i</span><span class="p">.</span><span class="no">e</span><span class="p">.</span><span class="w"> </span><span class="no">per</span><span class="o">-</span><span class="no">sample</span><span class="w"> </span><span class="no">or</span><span class="w"> </span><span class="no">per</span><span class="o">-</span><span class="no">timestep</span><span class="w"> </span><span class="no">loss</span>

<span class="w">              </span><span class="no">values</span><span class="err">;</span><span class="w"> </span><span class="no">otherwise</span><span class="p">,</span><span class="w"> </span><span class="no">it</span><span class="w"> </span><span class="no">is</span><span class="w"> </span><span class="no">a</span><span class="w"> </span><span class="no">scalar</span><span class="p">.</span><span class="w"> </span><span class="no">If</span><span class="w"> </span><span class="no">the</span><span class="w"> </span><span class="no">model</span><span class="w"> </span><span class="no">has</span><span class="w"> </span><span class="no">multiple</span>

<span class="w">              </span><span class="no">outputs</span><span class="p">,</span><span class="w"> </span><span class="no">you</span><span class="w"> </span><span class="no">can</span><span class="w"> </span><span class="no">use</span><span class="w"> </span><span class="no">a</span><span class="w"> </span><span class="no">different</span><span class="w"> </span><span class="no">loss</span><span class="w"> </span><span class="no">on</span><span class="w"> </span><span class="no">each</span><span class="w"> </span><span class="no">output</span><span class="w"> </span><span class="no">by</span><span class="w"> </span><span class="no">passing</span><span class="w"> </span><span class="no">a</span>

<span class="w">              </span><span class="no">dictionary</span><span class="w"> </span><span class="no">or</span><span class="w"> </span><span class="no">a</span><span class="w"> </span><span class="no">list</span><span class="w"> </span><span class="no">of</span><span class="w"> </span><span class="no">losses</span><span class="p">.</span><span class="w"> </span><span class="no">The</span><span class="w"> </span><span class="no">loss</span><span class="w"> </span><span class="no">value</span><span class="w"> </span><span class="no">that</span><span class="w"> </span><span class="no">will</span><span class="w"> </span><span class="no">be</span>

<span class="w">              </span><span class="no">minimized</span><span class="w"> </span><span class="no">by</span><span class="w"> </span><span class="no">the</span><span class="w"> </span><span class="no">model</span><span class="w"> </span><span class="no">will</span><span class="w"> </span><span class="no">then</span><span class="w"> </span><span class="no">be</span><span class="w"> </span><span class="no">the</span><span class="w"> </span><span class="no">sum</span><span class="w"> </span><span class="no">of</span><span class="w"> </span><span class="no">all</span><span class="w"> </span><span class="no">individual</span>

<span class="w">              </span><span class="no">losses</span><span class="p">,</span><span class="w"> </span><span class="no">unless</span><span class="w"> </span><span class="err">`</span><span class="no">loss_weights</span><span class="err">`</span><span class="w"> </span><span class="no">is</span><span class="w"> </span><span class="no">specified</span><span class="p">.</span>

<span class="w">            </span><span class="nl">metrics</span><span class="p">:</span><span class="w"> </span><span class="no">List</span><span class="w"> </span><span class="no">of</span><span class="w"> </span><span class="no">metrics</span><span class="w"> </span><span class="no">to</span><span class="w"> </span><span class="no">be</span><span class="w"> </span><span class="no">evaluated</span><span class="w"> </span><span class="no">by</span><span class="w"> </span><span class="no">the</span><span class="w"> </span><span class="no">model</span><span class="w"> </span><span class="no">during</span>

<span class="w">              </span><span class="no">training</span><span class="w"> </span><span class="no">and</span><span class="w"> </span><span class="no">testing</span><span class="p">.</span><span class="w"> </span><span class="no">Each</span><span class="w"> </span><span class="no">of</span><span class="w"> </span><span class="no">this</span><span class="w"> </span><span class="no">can</span><span class="w"> </span><span class="no">be</span><span class="w"> </span><span class="no">a</span><span class="w"> </span><span class="no">string</span><span class="w"> </span><span class="p">(</span><span class="no">name</span><span class="w"> </span><span class="no">of</span><span class="w"> </span><span class="no">a</span>

<span class="w">              </span><span class="no">built</span><span class="o">-</span><span class="no">in</span><span class="w"> </span><span class="no">function</span><span class="p">),</span><span class="w"> </span><span class="no">function</span><span class="w"> </span><span class="no">or</span><span class="w"> </span><span class="no">a</span><span class="w"> </span><span class="err">`</span><span class="no">tf</span><span class="p">.</span><span class="no">keras</span><span class="p">.</span><span class="no">metrics</span><span class="p">.</span><span class="no">Metric</span><span class="err">`</span>

<span class="w">              </span><span class="no">instance</span><span class="p">.</span><span class="w"> </span><span class="no">See</span><span class="w"> </span><span class="err">`</span><span class="no">tf</span><span class="p">.</span><span class="no">keras</span><span class="p">.</span><span class="no">metrics</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="no">Typically</span><span class="w"> </span><span class="no">you</span><span class="w"> </span><span class="no">will</span><span class="w"> </span><span class="no">use</span>

<span class="w">              </span><span class="err">`</span><span class="no">metrics</span><span class="o">=</span><span class="p">[</span><span class="err">&#39;</span><span class="no">accuracy</span><span class="err">&#39;</span><span class="p">]</span><span class="err">`</span><span class="p">.</span>

<span class="w">              </span><span class="no">A</span><span class="w"> </span><span class="no">function</span><span class="w"> </span><span class="no">is</span><span class="w"> </span><span class="no">any</span><span class="w"> </span><span class="no">callable</span><span class="w"> </span><span class="no">with</span><span class="w"> </span><span class="no">the</span><span class="w"> </span><span class="no">signature</span><span class="w"> </span><span class="err">`</span><span class="no">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="no">fn</span><span class="p">(</span><span class="no">y_true</span><span class="p">,</span>

<span class="w">              </span><span class="no">y_pred</span><span class="p">)</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="no">To</span><span class="w"> </span><span class="no">specify</span><span class="w"> </span><span class="no">different</span><span class="w"> </span><span class="no">metrics</span><span class="w"> </span><span class="no">for</span><span class="w"> </span><span class="no">different</span><span class="w"> </span><span class="no">outputs</span><span class="w"> </span><span class="no">of</span><span class="w"> </span><span class="no">a</span>

<span class="w">              </span><span class="no">multi</span><span class="o">-</span><span class="no">output</span><span class="w"> </span><span class="no">model</span><span class="p">,</span><span class="w"> </span><span class="no">you</span><span class="w"> </span><span class="no">could</span><span class="w"> </span><span class="no">also</span><span class="w"> </span><span class="no">pass</span><span class="w"> </span><span class="no">a</span><span class="w"> </span><span class="no">dictionary</span><span class="p">,</span><span class="w"> </span><span class="no">such</span><span class="w"> </span><span class="no">as</span>

<span class="w">              </span><span class="err">`</span><span class="no">metrics</span><span class="o">=</span><span class="err">{&#39;</span><span class="no">output_a</span><span class="sc">&#39;:&#39;</span><span class="no">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="no">output_b</span><span class="err">&#39;</span><span class="p">:[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="n">mse</span><span class="err">&#39;</span><span class="p">]}</span><span class="err">`</span><span class="p">.</span>

<span class="w">              </span><span class="n">You</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">also</span><span class="w"> </span><span class="n">pass</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">specify</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">metric</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">metrics</span>

<span class="w">              </span><span class="k">for</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="n">output</span><span class="p">,</span><span class="w"> </span><span class="n">such</span><span class="w"> </span><span class="n">as</span>

<span class="w">              </span><span class="err">`</span><span class="n">metrics</span><span class="o">=</span><span class="p">[[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="n">mse</span><span class="err">&#39;</span><span class="p">]]</span><span class="err">`</span>

<span class="w">              </span><span class="n">or</span><span class="w"> </span><span class="err">`</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="n">mse</span><span class="err">&#39;</span><span class="p">]]</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">When</span><span class="w"> </span><span class="n">you</span><span class="w"> </span><span class="n">pass</span><span class="w"> </span><span class="n">the</span>

<span class="w">              </span><span class="n">strings</span><span class="w"> </span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="err">&#39;</span><span class="n">acc</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">convert</span><span class="w"> </span><span class="n">this</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">one</span><span class="w"> </span><span class="n">of</span>

<span class="w">              </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">BinaryAccuracy</span><span class="err">`</span><span class="p">,</span>

<span class="w">              </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">CategoricalAccuracy</span><span class="err">`</span><span class="p">,</span>

<span class="w">              </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">SparseCategoricalAccuracy</span><span class="err">`</span><span class="w"> </span><span class="n">based</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">shapes</span>

<span class="w">              </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">targets</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">output</span><span class="p">.</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="k">do</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">similar</span>

<span class="w">              </span><span class="n">conversion</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">strings</span><span class="w"> </span><span class="err">&#39;</span><span class="n">crossentropy</span><span class="err">&#39;</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="err">&#39;</span><span class="n">ce</span><span class="err">&#39;</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="n">well</span><span class="p">.</span>

<span class="w">              </span><span class="n">The</span><span class="w"> </span><span class="n">metrics</span><span class="w"> </span><span class="n">passed</span><span class="w"> </span><span class="n">here</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">evaluated</span><span class="w"> </span><span class="n">without</span><span class="w"> </span><span class="n">sample</span><span class="w"> </span><span class="n">weighting</span><span class="p">;</span><span class="w"> </span><span class="k">if</span>

<span class="w">              </span><span class="n">you</span><span class="w"> </span><span class="n">would</span><span class="w"> </span><span class="n">like</span><span class="w"> </span><span class="n">sample</span><span class="w"> </span><span class="n">weighting</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">apply</span><span class="p">,</span><span class="w"> </span><span class="n">you</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">specify</span><span class="w"> </span><span class="n">your</span>

<span class="w">              </span><span class="n">metrics</span><span class="w"> </span><span class="n">via</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="err">`</span><span class="n">weighted_metrics</span><span class="err">`</span><span class="w"> </span><span class="n">argument</span><span class="w"> </span><span class="n">instead</span><span class="p">.</span>

<span class="w">            </span><span class="nl">loss_weights</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">dictionary</span><span class="w"> </span><span class="n">specifying</span><span class="w"> </span><span class="n">scalar</span>

<span class="w">              </span><span class="n">coefficients</span><span class="w"> </span><span class="p">(</span><span class="n">Python</span><span class="w"> </span><span class="n">floats</span><span class="p">)</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">weight</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">contributions</span><span class="w"> </span><span class="n">of</span>

<span class="w">              </span><span class="n">different</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">outputs</span><span class="p">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">minimized</span><span class="w"> </span><span class="n">by</span>

<span class="w">              </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">then</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="o">*</span><span class="n">weighted</span><span class="w"> </span><span class="n">sum</span><span class="o">*</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">individual</span>

<span class="w">              </span><span class="n">losses</span><span class="p">,</span><span class="w"> </span><span class="n">weighted</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="err">`</span><span class="n">loss_weights</span><span class="err">`</span><span class="w"> </span><span class="n">coefficients</span><span class="p">.</span><span class="w">  </span><span class="n">If</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="p">,</span>

<span class="w">              </span><span class="n">it</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">expected</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="mi">1</span><span class="w"> </span><span class="n">mapping</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="err">&#39;</span><span class="n">s</span><span class="w"> </span><span class="n">outputs</span><span class="p">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">a</span>

<span class="w">              </span><span class="n">dict</span><span class="p">,</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">expected</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">map</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="n">names</span><span class="w"> </span><span class="p">(</span><span class="n">strings</span><span class="p">)</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">scalar</span>

<span class="w">              </span><span class="n">coefficients</span><span class="p">.</span>

<span class="w">            </span><span class="nl">weighted_metrics</span><span class="p">:</span><span class="w"> </span><span class="n">List</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">metrics</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">evaluated</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">weighted</span><span class="w"> </span><span class="n">by</span>

<span class="w">              </span><span class="err">`</span><span class="n">sample_weight</span><span class="err">`</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="err">`</span><span class="n">class_weight</span><span class="err">`</span><span class="w"> </span><span class="n">during</span><span class="w"> </span><span class="n">training</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">testing</span><span class="p">.</span>

<span class="w">            </span><span class="nl">run_eagerly</span><span class="p">:</span><span class="w"> </span><span class="n">Bool</span><span class="p">.</span><span class="w"> </span><span class="n">Defaults</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="err">`</span><span class="n">False</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="err">`</span><span class="n">True</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="n">this</span><span class="w"> </span><span class="err">`</span><span class="n">Model</span><span class="err">`&#39;</span><span class="n">s</span>

<span class="w">              </span><span class="n">logic</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">wrapped</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">Recommended</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">leave</span>

<span class="w">              </span><span class="n">this</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="err">`</span><span class="n">None</span><span class="err">`</span><span class="w"> </span><span class="n">unless</span><span class="w"> </span><span class="n">your</span><span class="w"> </span><span class="err">`</span><span class="n">Model</span><span class="err">`</span><span class="w"> </span><span class="n">cannot</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">run</span><span class="w"> </span><span class="n">inside</span><span class="w"> </span><span class="n">a</span>

<span class="w">              </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="err">`</span><span class="n">run_eagerly</span><span class="o">=</span><span class="n">True</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">supported</span><span class="w"> </span><span class="n">when</span><span class="w"> </span><span class="n">using</span>

<span class="w">              </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">distribute</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">ParameterServerStrategy</span><span class="err">`</span><span class="p">.</span>

<span class="w">            </span><span class="nl">steps_per_execution</span><span class="p">:</span><span class="w"> </span><span class="n">Int</span><span class="p">.</span><span class="w"> </span><span class="n">Defaults</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="mf">1.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">batches</span><span class="w"> </span><span class="n">to</span>

<span class="w">              </span><span class="n">run</span><span class="w"> </span><span class="n">during</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="w"> </span><span class="n">call</span><span class="p">.</span><span class="w"> </span><span class="n">Running</span><span class="w"> </span><span class="n">multiple</span><span class="w"> </span><span class="n">batches</span>

<span class="w">              </span><span class="n">inside</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">single</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="w"> </span><span class="n">call</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">greatly</span><span class="w"> </span><span class="n">improve</span><span class="w"> </span><span class="n">performance</span>

<span class="w">              </span><span class="n">on</span><span class="w"> </span><span class="n">TPUs</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">small</span><span class="w"> </span><span class="n">models</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">large</span><span class="w"> </span><span class="n">Python</span><span class="w"> </span><span class="n">overhead</span><span class="p">.</span><span class="w"> </span><span class="n">At</span><span class="w"> </span><span class="n">most</span><span class="p">,</span><span class="w"> </span><span class="n">one</span>

<span class="w">              </span><span class="n">full</span><span class="w"> </span><span class="n">epoch</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">run</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="n">execution</span><span class="p">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="n">larger</span><span class="w"> </span><span class="n">than</span><span class="w"> </span><span class="n">the</span>

<span class="w">              </span><span class="n">size</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">epoch</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">passed</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">execution</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">truncated</span><span class="w"> </span><span class="n">to</span>

<span class="w">              </span><span class="n">the</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">epoch</span><span class="p">.</span><span class="w"> </span><span class="n">Note</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="err">`</span><span class="n">steps_per_execution</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">set</span>

<span class="w">              </span><span class="n">to</span><span class="w"> </span><span class="err">`</span><span class="n">N</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="err">`</span><span class="n">Callback</span><span class="p">.</span><span class="n">on_batch_begin</span><span class="err">`</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="err">`</span><span class="n">Callback</span><span class="p">.</span><span class="n">on_batch_end</span><span class="err">`</span>

<span class="w">              </span><span class="n">methods</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">only</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">called</span><span class="w"> </span><span class="n">every</span><span class="w"> </span><span class="err">`</span><span class="n">N</span><span class="err">`</span><span class="w"> </span><span class="n">batches</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="p">.</span><span class="n">e</span><span class="p">.</span><span class="w"> </span><span class="n">before</span><span class="o">/</span><span class="n">after</span>

<span class="w">              </span><span class="n">each</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="w"> </span><span class="n">execution</span><span class="p">).</span>

<span class="w">            </span><span class="nl">jit_compile</span><span class="p">:</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="err">`</span><span class="n">True</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="n">compile</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">training</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">XLA</span><span class="p">.</span>

<span class="w">              </span><span class="p">[</span><span class="n">XLA</span><span class="p">](</span><span class="n">https</span><span class="o">:</span><span class="c1">//www.tensorflow.org/xla) is an optimizing compiler</span>

<span class="w">              </span><span class="k">for</span><span class="w"> </span><span class="n">machine</span><span class="w"> </span><span class="n">learning</span><span class="p">.</span>

<span class="w">              </span><span class="err">`</span><span class="n">jit_compile</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">enabled</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="k">default</span><span class="p">.</span>

<span class="w">              </span><span class="n">This</span><span class="w"> </span><span class="n">option</span><span class="w"> </span><span class="n">cannot</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">enabled</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="err">`</span><span class="n">run_eagerly</span><span class="o">=</span><span class="n">True</span><span class="err">`</span><span class="p">.</span>

<span class="w">              </span><span class="n">Note</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="err">`</span><span class="n">jit_compile</span><span class="o">=</span><span class="n">True</span><span class="err">`</span>

<span class="w">              </span><span class="n">may</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">necessarily</span><span class="w"> </span><span class="n">work</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">models</span><span class="p">.</span>

<span class="w">              </span><span class="n">For</span><span class="w"> </span><span class="n">more</span><span class="w"> </span><span class="n">information</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">supported</span><span class="w"> </span><span class="n">operations</span><span class="w"> </span><span class="n">please</span><span class="w"> </span><span class="n">refer</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span>

<span class="w">              </span><span class="p">[</span><span class="n">XLA</span><span class="w"> </span><span class="n">documentation</span><span class="p">](</span><span class="n">https</span><span class="o">:</span><span class="c1">//www.tensorflow.org/xla).</span>

<span class="w">              </span><span class="n">Also</span><span class="w"> </span><span class="n">refer</span><span class="w"> </span><span class="n">to</span>

<span class="w">              </span><span class="p">[</span><span class="n">known</span><span class="w"> </span><span class="n">XLA</span><span class="w"> </span><span class="n">issues</span><span class="p">](</span><span class="n">https</span><span class="o">:</span><span class="c1">//www.tensorflow.org/xla/known_issues)</span>

<span class="w">              </span><span class="k">for</span><span class="w"> </span><span class="n">more</span><span class="w"> </span><span class="n">details</span><span class="p">.</span>

<span class="w">            </span><span class="o">**</span><span class="n">kwargs</span><span class="o">:</span><span class="w"> </span><span class="n">Arguments</span><span class="w"> </span><span class="n">supported</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">backwards</span><span class="w"> </span><span class="n">compatibility</span><span class="w"> </span><span class="n">only</span><span class="p">.</span>

<span class="w">        </span><span class="s">&quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">base_layer</span><span class="p">.</span><span class="n">keras_api_gauge</span><span class="p">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s">&quot;compile&quot;</span><span class="p">).</span><span class="n">set</span><span class="p">(</span><span class="n">True</span><span class="p">)</span>

<span class="w">        </span><span class="nb">self</span><span class="p">.</span><span class="n">_compile_config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">generic_utils</span><span class="p">.</span><span class="n">Config</span><span class="p">(</span>

<span class="w">            </span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>

<span class="w">            </span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>

<span class="w">            </span><span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span>

<span class="w">            </span><span class="n">loss_weights</span><span class="o">=</span><span class="n">loss_weights</span><span class="p">,</span>

<span class="w">            </span><span class="n">weighted_metrics</span><span class="o">=</span><span class="n">weighted_metrics</span><span class="p">,</span>

<span class="w">            </span><span class="n">run_eagerly</span><span class="o">=</span><span class="n">run_eagerly</span><span class="p">,</span>

<span class="w">            </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="n">steps_per_execution</span><span class="p">,</span>

<span class="w">            </span><span class="n">jit_compile</span><span class="o">=</span><span class="n">jit_compile</span><span class="p">,</span>

<span class="w">        </span><span class="p">)</span>

<span class="w">        </span><span class="n">with</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="s">&quot;experimental_steps_per_execution&quot;</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">kwargs</span><span class="o">:</span>

<span class="w">                </span><span class="n">logging</span><span class="p">.</span><span class="n">warning</span><span class="p">(</span>

<span class="w">                    </span><span class="s">&quot;The argument `steps_per_execution` is no longer &quot;</span>

<span class="w">                    </span><span class="s">&quot;experimental. Pass `steps_per_execution` instead of &quot;</span>

<span class="w">                    </span><span class="s">&quot;`experimental_steps_per_execution`.&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">steps_per_execution</span><span class="o">:</span>

<span class="w">                    </span><span class="n">steps_per_execution</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span>

<span class="w">                        </span><span class="s">&quot;experimental_steps_per_execution&quot;</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">            </span><span class="cp"># When compiling from an already-serialized model, we do not want to</span>

<span class="w">            </span><span class="cp"># reapply some processing steps (e.g. metric renaming for</span>

<span class="w">            </span><span class="cp"># multi-output models, which have prefixes added for each</span>

<span class="w">            </span><span class="cp"># corresponding output name).</span>

<span class="w">            </span><span class="n">from_serialized</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">&quot;from_serialized&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">False</span><span class="p">)</span>

<span class="w">            </span><span class="nb">self</span><span class="p">.</span><span class="n">_validate_compile</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span><span class="w"> </span><span class="n">metrics</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="w">            </span><span class="nb">self</span><span class="p">.</span><span class="n">_run_eagerly</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">run_eagerly</span>

<span class="w">            </span><span class="nb">self</span><span class="p">.</span><span class="n">optimizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">_get_optimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="n">compile_utils</span><span class="p">.</span><span class="n">LossesContainer</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="nb">self</span><span class="p">.</span><span class="n">compiled_loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">loss</span>

<span class="w">            </span><span class="nl">else</span><span class="p">:</span>

<span class="w">                </span><span class="nb">self</span><span class="p">.</span><span class="n">compiled_loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">compile_utils</span><span class="p">.</span><span class="n">LossesContainer</span><span class="p">(</span>

<span class="w">                    </span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="n">loss_weights</span><span class="p">,</span><span class="w"> </span><span class="n">output_names</span><span class="o">=</span><span class="nb">self</span><span class="p">.</span><span class="n">output_names</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="nb">self</span><span class="p">.</span><span class="n">compiled_metrics</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">compile_utils</span><span class="p">.</span><span class="n">MetricsContainer</span><span class="p">(</span>

<span class="w">                </span><span class="n">metrics</span><span class="p">,</span>

<span class="w">                </span><span class="n">weighted_metrics</span><span class="p">,</span>

<span class="w">                </span><span class="n">output_names</span><span class="o">=</span><span class="nb">self</span><span class="p">.</span><span class="n">output_names</span><span class="p">,</span>

<span class="w">                </span><span class="n">from_serialized</span><span class="o">=</span><span class="n">from_serialized</span><span class="p">,</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">            </span><span class="nb">self</span><span class="p">.</span><span class="n">_configure_steps_per_execution</span><span class="p">(</span><span class="n">steps_per_execution</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>

<span class="w">            </span><span class="cp"># Initializes attrs that are reset each time `compile` is called.</span>

<span class="w">            </span><span class="nb">self</span><span class="p">.</span><span class="n">_reset_compile_cache</span><span class="p">()</span>

<span class="w">            </span><span class="nb">self</span><span class="p">.</span><span class="n">_is_compiled</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">True</span>

<span class="w">            </span><span class="nb">self</span><span class="p">.</span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="p">{}</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nb">self</span><span class="p">.</span><span class="n">_run_eagerly</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">dynamic</span><span class="p">)</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">jit_compile</span><span class="o">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                    </span><span class="s">&quot;You cannot enable `run_eagerly` and `jit_compile` &quot;</span>

<span class="w">                    </span><span class="s">&quot;at the same time.&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="nl">else</span><span class="p">:</span>

<span class="w">                </span><span class="nb">self</span><span class="p">.</span><span class="n">_jit_compile</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">jit_compile</span>
</code></pre></div>

</details>
<h4 id="compute_loss_1">compute_loss</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Compute the total loss, validate it, and return it.</p>
<p>Subclasses can optionally override this method to provide custom loss
computation logic.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input data.</td>
<td>None</td>
</tr>
<tr>
<td>y</td>
<td>None</td>
<td>Target data.</td>
<td>None</td>
</tr>
<tr>
<td>y_pred</td>
<td>None</td>
<td>Predictions returned by the model (output of <code>model(x)</code>)</td>
<td>None</td>
</tr>
<tr>
<td>sample_weight</td>
<td>None</td>
<td>Sample weights for weighting the loss function.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>The total loss as a <code>tf.Tensor</code>, or <code>None</code> if no loss results (which<br>is the case when called by <code>Model.test_step</code>).</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">compute_loss</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Compute the total loss, validate it, and return it.</span>

<span class="s2">        Subclasses can optionally override this method to provide custom loss</span>

<span class="s2">        computation logic.</span>

<span class="s2">        Example:</span>

<span class="s2">        ```python</span>

<span class="s2">        class MyModel(tf.keras.Model):</span>

<span class="s2">          def __init__(self, *args, **kwargs):</span>

<span class="s2">            super(MyModel, self).__init__(*args, **kwargs)</span>

<span class="s2">            self.loss_tracker = tf.keras.metrics.Mean(name=&#39;loss&#39;)</span>

<span class="s2">          def compute_loss(self, x, y, y_pred, sample_weight):</span>

<span class="s2">            loss = tf.reduce_mean(tf.math.squared_difference(y_pred, y))</span>

<span class="s2">            loss += tf.add_n(self.losses)</span>

<span class="s2">            self.loss_tracker.update_state(loss)</span>

<span class="s2">            return loss</span>

<span class="s2">          def reset_metrics(self):</span>

<span class="s2">            self.loss_tracker.reset_states()</span>

<span class="s2">          @property</span>

<span class="s2">          def metrics(self):</span>

<span class="s2">            return [self.loss_tracker]</span>

<span class="s2">        tensors = tf.random.uniform((10, 10)), tf.random.uniform((10,))</span>

<span class="s2">        dataset = tf.data.Dataset.from_tensor_slices(tensors).repeat().batch(1)</span>

<span class="s2">        inputs = tf.keras.layers.Input(shape=(10,), name=&#39;my_input&#39;)</span>

<span class="s2">        outputs = tf.keras.layers.Dense(10)(inputs)</span>

<span class="s2">        model = MyModel(inputs, outputs)</span>

<span class="s2">        model.add_loss(tf.reduce_sum(outputs))</span>

<span class="s2">        optimizer = tf.keras.optimizers.SGD()</span>

<span class="s2">        model.compile(optimizer, loss=&#39;mse&#39;, steps_per_execution=10)</span>

<span class="s2">        model.fit(dataset, epochs=2, steps_per_epoch=10)</span>

<span class="s2">        print(&#39;My custom loss: &#39;, model.loss_tracker.result().numpy())</span>

<span class="s2">        ```</span>

<span class="s2">        Args:</span>

<span class="s2">          x: Input data.</span>

<span class="s2">          y: Target data.</span>

<span class="s2">          y_pred: Predictions returned by the model (output of `model(x)`)</span>

<span class="s2">          sample_weight: Sample weights for weighting the loss function.</span>

<span class="s2">        Returns:</span>

<span class="s2">          The total loss as a `tf.Tensor`, or `None` if no loss results (which</span>

<span class="s2">          is the case when called by `Model.test_step`).</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">del</span><span class="w"> </span><span class="n">x</span><span class="w">  </span><span class="c1"># The default implementation does not use `x`.</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">compiled_loss</span><span class="p">(</span>

<span class="w">            </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">,</span><span class="w"> </span><span class="n">regularization_losses</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">losses</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="compute_mask_1">compute_mask</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_mask</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">,</span>
    <span class="n">mask</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Computes an output mask tensor.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>inputs</td>
<td>None</td>
<td>Tensor or list of tensors.</td>
<td>None</td>
</tr>
<tr>
<td>mask</td>
<td>None</td>
<td>Tensor or list of tensors.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>None or a tensor (or list of tensors,<br>one per output tensor of the layer).</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@generic_utils</span><span class="p">.</span><span class="k">default</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">compute_mask</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">mask</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Computes an output mask tensor.</span>

<span class="ss">        Args:</span>

<span class="ss">            inputs: Tensor or list of tensors.</span>

<span class="ss">            mask: Tensor or list of tensors.</span>

<span class="ss">        Returns:</span>

<span class="ss">            None or a tensor (or list of tensors,</span>

<span class="ss">                one per output tensor of the layer).</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="nl">_supports_masking</span><span class="p">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="ow">any</span><span class="p">(</span><span class="n">m</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">mask</span><span class="p">))</span><span class="err">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">TypeError</span><span class="p">(</span>

<span class="w">                    </span><span class="ss">&quot;Layer &quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">name</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="ss">&quot; does not support masking, &quot;</span>

<span class="w">                    </span><span class="ss">&quot;but was passed an input_mask: &quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">str</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="err">#</span><span class="w"> </span><span class="n">masking</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">explicitly</span><span class="w"> </span><span class="nl">supported</span><span class="p">:</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">mask</span><span class="p">.</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="k">None</span>

<span class="w">        </span><span class="err">#</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">masking</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">explicitly</span><span class="w"> </span><span class="n">supported</span><span class="p">,</span><span class="w"> </span><span class="k">by</span><span class="w"> </span><span class="k">default</span>

<span class="w">        </span><span class="err">#</span><span class="w"> </span><span class="n">carry</span><span class="w"> </span><span class="k">over</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">input</span><span class="w"> </span><span class="n">mask</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">mask</span>
</code></pre></div>

</details>
<h4 id="compute_metrics_1">compute_metrics</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">,</span>
    <span class="n">sample_weight</span>
<span class="p">)</span>
</code></pre></div>

<p>Update metric states and collect all metrics to be returned.</p>
<p>Subclasses can optionally override this method to provide custom metric
updating and collection logic.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input data.</td>
<td>None</td>
</tr>
<tr>
<td>y</td>
<td>None</td>
<td>Target data.</td>
<td>None</td>
</tr>
<tr>
<td>y_pred</td>
<td>None</td>
<td>Predictions returned by the model (output of <code>model.call(x)</code>)</td>
<td>None</td>
</tr>
<tr>
<td>sample_weight</td>
<td>None</td>
<td>Sample weights for weighting the loss function.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A <code>dict</code> containing values that will be passed to<br><code>tf.keras.callbacks.CallbackList.on_train_batch_end()</code>. Typically, the<br>values of the metrics listed in <code>self.metrics</code> are returned. Example:<br><code>{'loss': 0.2, 'accuracy': 0.7}</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">compute_metrics</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Update metric states and collect all metrics to be returned.</span>

<span class="s2">        Subclasses can optionally override this method to provide custom metric</span>

<span class="s2">        updating and collection logic.</span>

<span class="s2">        Example:</span>

<span class="s2">        ```python</span>

<span class="s2">        class MyModel(tf.keras.Sequential):</span>

<span class="s2">          def compute_metrics(self, x, y, y_pred, sample_weight):</span>

<span class="s2">            # This super call updates `self.compiled_metrics` and returns</span>

<span class="s2">            # results for all metrics listed in `self.metrics`.</span>

<span class="s2">            metric_results = super(MyModel, self).compute_metrics(</span>

<span class="s2">                x, y, y_pred, sample_weight)</span>

<span class="s2">            # Note that `self.custom_metric` is not listed in `self.metrics`.</span>

<span class="s2">            self.custom_metric.update_state(x, y, y_pred, sample_weight)</span>

<span class="s2">            metric_results[&#39;custom_metric_name&#39;] = self.custom_metric.result()</span>

<span class="s2">            return metric_results</span>

<span class="s2">        ```</span>

<span class="s2">        Args:</span>

<span class="s2">          x: Input data.</span>

<span class="s2">          y: Target data.</span>

<span class="s2">          y_pred: Predictions returned by the model (output of `model.call(x)`)</span>

<span class="s2">          sample_weight: Sample weights for weighting the loss function.</span>

<span class="s2">        Returns:</span>

<span class="s2">          A `dict` containing values that will be passed to</span>

<span class="s2">          `tf.keras.callbacks.CallbackList.on_train_batch_end()`. Typically, the</span>

<span class="s2">          values of the metrics listed in `self.metrics` are returned. Example:</span>

<span class="s2">          `{&#39;loss&#39;: 0.2, &#39;accuracy&#39;: 0.7}`.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">del</span><span class="w"> </span><span class="n">x</span><span class="w">  </span><span class="c1"># The default implementation does not use `x`.</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">compiled_metrics</span><span class="p">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">get_metrics_result</span><span class="p">()</span>
</code></pre></div>

</details>
<h4 id="compute_output_shape_1">compute_output_shape</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_shape</span>
<span class="p">)</span>
</code></pre></div>

<p>Computes the output shape of the layer.</p>
<p>This method will cause the layer's state to be built, if that has not
happened before. This requires that the layer will later be used with
inputs that match the input shape provided here.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>input_shape</td>
<td>None</td>
<td>Shape tuple (tuple of integers) or <code>tf.TensorShape</code>,<br>or structure of shape tuples / <code>tf.TensorShape</code> instances<br>(one per output tensor of the layer).<br>Shape tuples can include None for free dimensions,<br>instead of an integer.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A <code>tf.TensorShape</code> instance<br>or structure of <code>tf.TensorShape</code> instances.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code>    <span class="n">def</span> <span class="n">compute_output_shape</span>(<span class="nb">self</span>, <span class="n">input_shape</span>):

        <span class="s">&quot;&quot;&quot;Computes the output shape of the layer.</span>

<span class="s">        This method will cause the layer&#39;s state to be built, if that has not</span>

<span class="s">        happened before. This requires that the layer will later be used with</span>

<span class="s">        inputs that match the input shape provided here.</span>

<span class="s">        Args:</span>

<span class="s">            input_shape: Shape tuple (tuple of integers) or `tf.TensorShape`,</span>

<span class="s">                or structure of shape tuples / `tf.TensorShape` instances</span>

<span class="s">                (one per output tensor of the layer).</span>

<span class="s">                Shape tuples can include None for free dimensions,</span>

<span class="s">                instead of an integer.</span>

<span class="s">        Returns:</span>

<span class="s">            A `tf.TensorShape` instance</span>

<span class="s">            or structure of `tf.TensorShape` instances.</span>

<span class="s">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">tf</span>.<span class="n">executing_eagerly</span>():

            <span class="c1"># In this case we build the model first in order to do shape</span>

            <span class="c1"># inference.  This is acceptable because the framework only calls</span>

            <span class="c1"># `compute_output_shape` on shape values that the layer would later</span>

            <span class="c1"># be built for. It would however cause issues in case a user</span>

            <span class="c1"># attempts to use `compute_output_shape` manually with shapes that</span>

            <span class="c1"># are incompatible with the shape the Layer will be called on (these</span>

            <span class="c1"># users will have to implement `compute_output_shape` themselves).</span>

            <span class="nb">self</span>.<span class="n">_maybe_build</span>(<span class="n">input_shape</span>)

            <span class="n">graph_name</span> = <span class="n">str</span>(<span class="nb">self</span>.<span class="nb">name</span>) + <span class="s">&quot;_scratch_graph&quot;</span>

            <span class="k">with</span> <span class="n">tf</span>.<span class="n">__internal__</span>.<span class="n">FuncGraph</span>(<span class="n">graph_name</span>).<span class="n">as_default</span>():

                <span class="n">input_shape</span> = <span class="n">tf_utils</span>.<span class="n">convert_shapes</span>(

                    <span class="n">input_shape</span>, <span class="n">to_tuples</span>=<span class="nb">False</span>

                )

                <span class="n">def</span> <span class="n">_make_placeholder_like</span>(<span class="nb">shape</span>):

                    <span class="n">ph</span> = <span class="n">backend</span>.<span class="nb">placeholder</span>(<span class="nb">shape</span>=<span class="nb">shape</span>, <span class="n">dtype</span>=<span class="nb">self</span>.<span class="n">dtype</span>)

                    <span class="n">ph</span>.<span class="n">_keras_mask</span> = <span class="n">None</span>

                    <span class="k">return</span> <span class="n">ph</span>

                <span class="n">inputs</span> = <span class="n">tf</span>.<span class="n">nest</span>.<span class="n">map_structure</span>(

                    <span class="n">_make_placeholder_like</span>, <span class="n">input_shape</span>

                )

                <span class="n">try:</span>

                    <span class="n">outputs</span> = <span class="nb">self</span>(<span class="n">inputs</span>, <span class="n">training</span>=<span class="nb">False</span>)

                <span class="n">except</span> <span class="n">TypeError</span> <span class="n">as</span> <span class="n">e:</span>

                    <span class="n">raise</span> <span class="n">NotImplementedError</span>(

                        <span class="s">&quot;We could not automatically infer the static shape of &quot;</span>

                        <span class="s">&quot;the layer&#39;s output. Please implement the &quot;</span>

                        <span class="s">&quot;`compute_output_shape` method on your layer (%s).&quot;</span>

                        % <span class="nb">self</span>.<span class="n">__class__</span>.<span class="n">__name__</span>

                    ) <span class="nb">from</span> <span class="nb">e</span>

            <span class="k">return</span> <span class="n">tf</span>.<span class="n">nest</span>.<span class="n">map_structure</span>(<span class="n">lambda</span> <span class="n">t:</span> <span class="nb">t</span>.<span class="nb">shape</span>, <span class="n">outputs</span>)

        <span class="n">raise</span> <span class="n">NotImplementedError</span>(

            <span class="s">&quot;Please run in eager mode or implement the `compute_output_shape` &quot;</span>

            <span class="s">&quot;method on your layer (%s).&quot;</span> % <span class="nb">self</span>.<span class="n">__class__</span>.<span class="n">__name__</span>

        )
</code></pre></div>

</details>
<h4 id="compute_output_signature_1">compute_output_signature</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_output_signature</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_signature</span>
<span class="p">)</span>
</code></pre></div>

<p>Compute the output tensor signature of the layer based on the inputs.</p>
<p>Unlike a TensorShape object, a TensorSpec object contains both shape
and dtype information for a tensor. This method allows layers to provide
output dtype information if it is different from the input dtype.
For any layer that doesn't implement this function,
the framework will fall back to use <code>compute_output_shape</code>, and will
assume that the output dtype matches the input dtype.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>input_signature</td>
<td>None</td>
<td>Single TensorSpec or nested structure of TensorSpec<br>objects, describing a candidate input for the layer.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Single TensorSpec or nested structure of TensorSpec objects,<br>describing how the layer would transform the provided input.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>TypeError</td>
<td>If input_signature contains a non-TensorSpec object.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@doc_controls.for_subclass_implementers</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">compute_output_signature</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">input_signature</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Compute the output tensor signature of the layer based on the inputs.</span>

<span class="s2">        Unlike a TensorShape object, a TensorSpec object contains both shape</span>

<span class="s2">        and dtype information for a tensor. This method allows layers to provide</span>

<span class="s2">        output dtype information if it is different from the input dtype.</span>

<span class="s2">        For any layer that doesn&#39;t implement this function,</span>

<span class="s2">        the framework will fall back to use `compute_output_shape`, and will</span>

<span class="s2">        assume that the output dtype matches the input dtype.</span>

<span class="s2">        Args:</span>

<span class="s2">          input_signature: Single TensorSpec or nested structure of TensorSpec</span>

<span class="s2">            objects, describing a candidate input for the layer.</span>

<span class="s2">        Returns:</span>

<span class="s2">          Single TensorSpec or nested structure of TensorSpec objects,</span>

<span class="s2">            describing how the layer would transform the provided input.</span>

<span class="s2">        Raises:</span>

<span class="s2">          TypeError: If input_signature contains a non-TensorSpec object.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">def</span><span class="w"> </span><span class="n">check_type_return_shape</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">TensorSpec</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">TypeError</span><span class="p">(</span>

<span class="w">                    </span><span class="s2">&quot;Only TensorSpec signature types are supported. &quot;</span>

<span class="w">                    </span><span class="n">f</span><span class="s2">&quot;Received: {s}.&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">s</span><span class="p">.</span><span class="n">shape</span>

<span class="w">        </span><span class="n">input_shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span>

<span class="w">            </span><span class="n">check_type_return_shape</span><span class="p">,</span><span class="w"> </span><span class="n">input_signature</span>

<span class="w">        </span><span class="p">)</span>

<span class="w">        </span><span class="n">output_shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">compute_output_shape</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>

<span class="w">        </span><span class="n">dtype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_compute_dtype</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">dtype</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="o">:</span>

<span class="w">            </span><span class="n">input_dtypes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">[</span><span class="n">s</span><span class="p">.</span><span class="n">dtype</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">input_signature</span><span class="p">)</span><span class="err">]</span>

<span class="w">            </span><span class="c1"># Default behavior when self.dtype is None, is to use the first</span>

<span class="w">            </span><span class="c1"># input&#39;s dtype.</span>

<span class="w">            </span><span class="n">dtype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input_dtypes</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span>

<span class="w">            </span><span class="n">lambda</span><span class="w"> </span><span class="n">s</span><span class="o">:</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">TensorSpec</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="n">shape</span><span class="o">=</span><span class="n">s</span><span class="p">),</span><span class="w"> </span><span class="n">output_shape</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="count_params_1">count_params</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">count_params</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Count the total number of scalars composing the weights.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>An integer count.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>if the layer isn't yet built<br>(in which case its weights aren't yet defined).</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">count_params</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Count the total number of scalars composing the weights.</span>

<span class="s2">        Returns:</span>

<span class="s2">            An integer count.</span>

<span class="s2">        Raises:</span>

<span class="s2">            ValueError: if the layer isn&#39;t yet built</span>

<span class="s2">              (in which case its weights aren&#39;t yet defined).</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">built</span><span class="o">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;_is_graph_network&quot;</span><span class="p">,</span><span class="w"> </span><span class="no">False</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="k">with</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">maybe_init_scope</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

<span class="w">                    </span><span class="n">self</span><span class="p">.</span><span class="n">_maybe_build</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">inputs</span><span class="p">)</span>

<span class="w">            </span><span class="k">else</span><span class="o">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                    </span><span class="s2">&quot;You tried to call `count_params` &quot;</span>

<span class="w">                    </span><span class="n">f</span><span class="s2">&quot;on layer {self.name}&quot;</span>

<span class="w">                    </span><span class="s2">&quot;, but the layer isn&#39;t built. &quot;</span>

<span class="w">                    </span><span class="s2">&quot;You can build it manually via: &quot;</span>

<span class="w">                    </span><span class="n">f</span><span class="s2">&quot;`{self.name}.build(batch_input_shape)`.&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">layer_utils</span><span class="p">.</span><span class="n">count_params</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">weights</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="evaluate_1">evaluate</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns the loss value &amp; metrics values for the model in test mode.</p>
<p>Computation is done in batches (see the <code>batch_size</code> arg.)</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input data. It could be:<br>- A Numpy array (or array-like), or a list of arrays<br>  (in case the model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors<br>  (in case the model has multiple inputs).<br>- A dict mapping input names to the corresponding array/tensors,<br>  if the model has named inputs.<br>- A <code>tf.data</code> dataset. Should return a tuple<br>  of either <code>(inputs, targets)</code> or<br>  <code>(inputs, targets, sample_weights)</code>.<br>- A generator or <code>keras.utils.Sequence</code> returning <code>(inputs,&lt;br&gt;  targets)</code> or <code>(inputs, targets, sample_weights)</code>.<br>A more detailed description of unpacking behavior for iterator<br>types (Dataset, generator, Sequence) is given in the <code>Unpacking&lt;br&gt;behavior for iterator-like inputs</code> section of <code>Model.fit</code>.</td>
<td>None</td>
</tr>
<tr>
<td>y</td>
<td>None</td>
<td>Target data. Like the input data <code>x</code>, it could be either Numpy<br>array(s) or TensorFlow tensor(s). It should be consistent with <code>x</code><br>(you cannot have Numpy inputs and tensor targets, or inversely).<br>If <code>x</code> is a dataset, generator or <code>keras.utils.Sequence</code> instance,<br><code>y</code> should not be specified (since targets will be obtained from<br>the iterator/dataset).</td>
<td>None</td>
</tr>
<tr>
<td>batch_size</td>
<td>None</td>
<td>Integer or <code>None</code>. Number of samples per batch of<br>computation. If unspecified, <code>batch_size</code> will default to 32. Do<br>not specify the <code>batch_size</code> if your data is in the form of a<br>dataset, generators, or <code>keras.utils.Sequence</code> instances (since<br>they generate batches).</td>
<td>None</td>
</tr>
<tr>
<td>verbose</td>
<td>None</td>
<td><code>"auto"</code>, 0, 1, or 2. Verbosity mode.<br>0 = silent, 1 = progress bar, 2 = single line.<br><code>"auto"</code> defaults to 1 for most cases, and to 2 when used with<br><code>ParameterServerStrategy</code>. Note that the progress bar is not<br>particularly useful when logged to a file, so <code>verbose=2</code> is<br>recommended when not running interactively (e.g. in a production<br>environment).</td>
<td>None</td>
</tr>
<tr>
<td>sample_weight</td>
<td>None</td>
<td>Optional Numpy array of weights for the test samples,<br>used for weighting the loss function. You can either pass a flat<br>(1D) Numpy array with the same length as the input samples<br>  (1:1 mapping between weights and samples), or in the case of<br>    temporal data, you can pass a 2D array with shape <code>(samples,&lt;br&gt;    sequence_length)</code>, to apply a different weight to every<br>    timestep of every sample. This argument is not supported when<br>    <code>x</code> is a dataset, instead pass sample weights as the third<br>    element of <code>x</code>.</td>
<td>None</td>
</tr>
<tr>
<td>steps</td>
<td>None</td>
<td>Integer or <code>None</code>. Total number of steps (batches of samples)<br>before declaring the evaluation round finished. Ignored with the<br>default value of <code>None</code>. If x is a <code>tf.data</code> dataset and <code>steps</code><br>is None, 'evaluate' will run until the dataset is exhausted. This<br>argument is not supported with array inputs.</td>
<td>None</td>
</tr>
<tr>
<td>callbacks</td>
<td>None</td>
<td>List of <code>keras.callbacks.Callback</code> instances. List of<br>callbacks to apply during evaluation. See<br><a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks">callbacks</a>.</td>
<td>None</td>
</tr>
<tr>
<td>max_queue_size</td>
<td>None</td>
<td>Integer. Used for generator or<br><code>keras.utils.Sequence</code> input only. Maximum size for the generator<br>queue. If unspecified, <code>max_queue_size</code> will default to 10.</td>
<td>None</td>
</tr>
<tr>
<td>workers</td>
<td>None</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code> input<br>only. Maximum number of processes to spin up when using<br>process-based threading. If unspecified, <code>workers</code> will default to<br>1.</td>
<td>None</td>
</tr>
<tr>
<td>use_multiprocessing</td>
<td>None</td>
<td>Boolean. Used for generator or<br><code>keras.utils.Sequence</code> input only. If <code>True</code>, use process-based<br>threading. If unspecified, <code>use_multiprocessing</code> will default to<br><code>False</code>. Note that because this implementation relies on<br>multiprocessing, you should not pass non-picklable arguments to<br>the generator as they can't be passed easily to children<br>processes.</td>
<td>None</td>
</tr>
<tr>
<td>return_dict</td>
<td>None</td>
<td>If <code>True</code>, loss and metric results are returned as a<br>dict, with each key being the name of the metric. If <code>False</code>, they<br>are returned as a list.</td>
<td>None</td>
</tr>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Unused at this time.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Scalar test loss (if the model has a single output and no metrics)<br>or list of scalars (if the model has multiple outputs<br>and/or metrics). The attribute <code>model.metrics_names</code> will give you<br>the display labels for the scalar outputs.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.evaluate</code> is wrapped in a <code>tf.function</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@traceback_utils.filter_traceback</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">evaluate</span><span class="p">(</span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">x</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">batch_size</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">verbose</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>

<span class="w">        </span><span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

<span class="w">        </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="no">False</span><span class="p">,</span>

<span class="w">        </span><span class="n">return_dict</span><span class="o">=</span><span class="no">False</span><span class="p">,</span>

<span class="w">        </span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns the loss value &amp; metrics values for the model in test mode.</span>

<span class="s2">        Computation is done in batches (see the `batch_size` arg.)</span>

<span class="s2">        Args:</span>

<span class="s2">            x: Input data. It could be:</span>

<span class="s2">              - A Numpy array (or array-like), or a list of arrays</span>

<span class="s2">                (in case the model has multiple inputs).</span>

<span class="s2">              - A TensorFlow tensor, or a list of tensors</span>

<span class="s2">                (in case the model has multiple inputs).</span>

<span class="s2">              - A dict mapping input names to the corresponding array/tensors,</span>

<span class="s2">                if the model has named inputs.</span>

<span class="s2">              - A `tf.data` dataset. Should return a tuple</span>

<span class="s2">                of either `(inputs, targets)` or</span>

<span class="s2">                `(inputs, targets, sample_weights)`.</span>

<span class="s2">              - A generator or `keras.utils.Sequence` returning `(inputs,</span>

<span class="s2">                targets)` or `(inputs, targets, sample_weights)`.</span>

<span class="s2">              A more detailed description of unpacking behavior for iterator</span>

<span class="s2">              types (Dataset, generator, Sequence) is given in the `Unpacking</span>

<span class="s2">              behavior for iterator-like inputs` section of `Model.fit`.</span>

<span class="s2">            y: Target data. Like the input data `x`, it could be either Numpy</span>

<span class="s2">              array(s) or TensorFlow tensor(s). It should be consistent with `x`</span>

<span class="s2">              (you cannot have Numpy inputs and tensor targets, or inversely).</span>

<span class="s2">              If `x` is a dataset, generator or `keras.utils.Sequence` instance,</span>

<span class="s2">              `y` should not be specified (since targets will be obtained from</span>

<span class="s2">              the iterator/dataset).</span>

<span class="s2">            batch_size: Integer or `None`. Number of samples per batch of</span>

<span class="s2">              computation. If unspecified, `batch_size` will default to 32. Do</span>

<span class="s2">              not specify the `batch_size` if your data is in the form of a</span>

<span class="s2">              dataset, generators, or `keras.utils.Sequence` instances (since</span>

<span class="s2">              they generate batches).</span>

<span class="s2">            verbose: `&quot;</span><span class="n">auto</span><span class="s2">&quot;`, 0, 1, or 2. Verbosity mode.</span>

<span class="s2">                0 = silent, 1 = progress bar, 2 = single line.</span>

<span class="s2">                `&quot;</span><span class="n">auto</span><span class="s2">&quot;` defaults to 1 for most cases, and to 2 when used with</span>

<span class="s2">                `ParameterServerStrategy`. Note that the progress bar is not</span>

<span class="s2">                particularly useful when logged to a file, so `verbose=2` is</span>

<span class="s2">                recommended when not running interactively (e.g. in a production</span>

<span class="s2">                environment).</span>

<span class="s2">            sample_weight: Optional Numpy array of weights for the test samples,</span>

<span class="s2">              used for weighting the loss function. You can either pass a flat</span>

<span class="s2">              (1D) Numpy array with the same length as the input samples</span>

<span class="s2">                (1:1 mapping between weights and samples), or in the case of</span>

<span class="s2">                  temporal data, you can pass a 2D array with shape `(samples,</span>

<span class="s2">                  sequence_length)`, to apply a different weight to every</span>

<span class="s2">                  timestep of every sample. This argument is not supported when</span>

<span class="s2">                  `x` is a dataset, instead pass sample weights as the third</span>

<span class="s2">                  element of `x`.</span>

<span class="s2">            steps: Integer or `None`. Total number of steps (batches of samples)</span>

<span class="s2">              before declaring the evaluation round finished. Ignored with the</span>

<span class="s2">              default value of `None`. If x is a `tf.data` dataset and `steps`</span>

<span class="s2">              is None, &#39;evaluate&#39; will run until the dataset is exhausted. This</span>

<span class="s2">              argument is not supported with array inputs.</span>

<span class="s2">            callbacks: List of `keras.callbacks.Callback` instances. List of</span>

<span class="s2">              callbacks to apply during evaluation. See</span>

<span class="s2">              [callbacks](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks).</span>

<span class="s2">            max_queue_size: Integer. Used for generator or</span>

<span class="s2">              `keras.utils.Sequence` input only. Maximum size for the generator</span>

<span class="s2">              queue. If unspecified, `max_queue_size` will default to 10.</span>

<span class="s2">            workers: Integer. Used for generator or `keras.utils.Sequence` input</span>

<span class="s2">              only. Maximum number of processes to spin up when using</span>

<span class="s2">              process-based threading. If unspecified, `workers` will default to</span>

<span class="s2">              1.</span>

<span class="s2">            use_multiprocessing: Boolean. Used for generator or</span>

<span class="s2">              `keras.utils.Sequence` input only. If `True`, use process-based</span>

<span class="s2">              threading. If unspecified, `use_multiprocessing` will default to</span>

<span class="s2">              `False`. Note that because this implementation relies on</span>

<span class="s2">              multiprocessing, you should not pass non-picklable arguments to</span>

<span class="s2">              the generator as they can&#39;t be passed easily to children</span>

<span class="s2">              processes.</span>

<span class="s2">            return_dict: If `True`, loss and metric results are returned as a</span>

<span class="s2">              dict, with each key being the name of the metric. If `False`, they</span>

<span class="s2">              are returned as a list.</span>

<span class="s2">            **kwargs: Unused at this time.</span>

<span class="s2">        See the discussion of `Unpacking behavior for iterator-like inputs` for</span>

<span class="s2">        `Model.fit`.</span>

<span class="s2">        Returns:</span>

<span class="s2">            Scalar test loss (if the model has a single output and no metrics)</span>

<span class="s2">            or list of scalars (if the model has multiple outputs</span>

<span class="s2">            and/or metrics). The attribute `model.metrics_names` will give you</span>

<span class="s2">            the display labels for the scalar outputs.</span>

<span class="s2">        Raises:</span>

<span class="s2">            RuntimeError: If `model.evaluate` is wrapped in a `tf.function`.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">base_layer</span><span class="p">.</span><span class="n">keras_api_gauge</span><span class="p">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s2">&quot;evaluate&quot;</span><span class="p">).</span><span class="kt">set</span><span class="p">(</span><span class="no">True</span><span class="p">)</span>

<span class="w">        </span><span class="n">version_utils</span><span class="p">.</span><span class="n">disallow_legacy_graph</span><span class="p">(</span><span class="s2">&quot;Model&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;evaluate&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s2">&quot;evaluate&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_check_sample_weight_warning</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">)</span>

<span class="w">        </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s2">&quot;evaluate&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="n">use_cached_eval_dataset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;_use_cached_eval_dataset&quot;</span><span class="p">,</span><span class="w"> </span><span class="no">False</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">kwargs</span><span class="o">:</span>

<span class="w">            </span><span class="n">raise</span><span class="w"> </span><span class="n">TypeError</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Invalid keyword arguments: {list(kwargs.keys())}&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">_should_use_with_coordinator</span><span class="o">:</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span>

<span class="w">                </span><span class="n">tf</span><span class="p">.</span><span class="n">distribute</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">coordinator</span><span class="p">.</span><span class="n">ClusterCoordinator</span><span class="p">(</span>

<span class="w">                    </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="n">verbose</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">_get_verbosity</span><span class="p">(</span><span class="n">verbose</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">)</span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span>

<span class="w">            </span><span class="c1"># Use cached evaluation data only when it&#39;s called in `Model.fit`</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span>

<span class="w">                </span><span class="n">use_cached_eval_dataset</span>

<span class="w">                </span><span class="k">and</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;_eval_data_handler&quot;</span><span class="p">,</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span>

<span class="w">            </span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_eval_data_handler</span>

<span class="w">            </span><span class="k">else</span><span class="o">:</span>

<span class="w">                </span><span class="c1"># Creates a `tf.data.Dataset` and handles batch and epoch</span>

<span class="w">                </span><span class="c1"># iteration.</span>

<span class="w">                </span><span class="n">data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">get_data_handler</span><span class="p">(</span>

<span class="w">                    </span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>

<span class="w">                    </span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>

<span class="w">                    </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>

<span class="w">                    </span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>

<span class="w">                    </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>

<span class="w">                    </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

<span class="w">                    </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">                    </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

<span class="w">                    </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

<span class="w">                    </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

<span class="w">                    </span><span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span>

<span class="w">                    </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">,</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span><span class="w"> </span><span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">callbacks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">(</span>

<span class="w">                    </span><span class="n">callbacks</span><span class="p">,</span>

<span class="w">                    </span><span class="n">add_history</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

<span class="w">                    </span><span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>

<span class="w">                    </span><span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span>

<span class="w">                    </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>

<span class="w">                    </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">                    </span><span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="p">.</span><span class="n">inferred_steps</span><span class="p">,</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">{}</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">make_test_function</span><span class="p">()</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">_test_counter</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="w">            </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_begin</span><span class="p">()</span>

<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">enumerate_epochs</span><span class="p">()</span><span class="o">:</span><span class="w">  </span><span class="c1"># Single epoch.</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span>

<span class="w">                </span><span class="k">with</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">catch_stop_iteration</span><span class="p">()</span><span class="o">:</span>

<span class="w">                    </span><span class="k">for</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">steps</span><span class="p">()</span><span class="o">:</span>

<span class="w">                        </span><span class="k">with</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">profiler</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">Trace</span><span class="p">(</span>

<span class="w">                            </span><span class="s2">&quot;test&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">step_num</span><span class="o">=</span><span class="n">step</span><span class="p">,</span><span class="w"> </span><span class="n">_r</span><span class="o">=</span><span class="mi">1</span>

<span class="w">                        </span><span class="p">)</span><span class="o">:</span>

<span class="w">                            </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>

<span class="w">                            </span><span class="n">tmp_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

<span class="w">                            </span><span class="k">if</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">should_sync</span><span class="o">:</span>

<span class="w">                                </span><span class="k">context</span><span class="p">.</span><span class="n">async_wait</span><span class="p">()</span>

<span class="w">                            </span><span class="c1"># No error, now safe to assign to logs.</span>

<span class="w">                            </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tmp_logs</span>

<span class="w">                            </span><span class="n">end_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">step_increment</span>

<span class="w">                            </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_batch_end</span><span class="p">(</span><span class="n">end_step</span><span class="p">,</span><span class="w"> </span><span class="k">logs</span><span class="p">)</span>

<span class="w">            </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span>

<span class="w">            </span><span class="c1"># Override with model metrics instead of last step logs</span>

<span class="w">            </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_validate_and_get_metrics_result</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span>

<span class="w">            </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_end</span><span class="p">(</span><span class="k">logs</span><span class="o">=</span><span class="k">logs</span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">return_dict</span><span class="o">:</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="k">logs</span>

<span class="w">            </span><span class="k">else</span><span class="o">:</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">flatten_metrics_in_order</span><span class="p">(</span><span class="k">logs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="evaluate_generator_1">evaluate_generator</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate_generator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>

<p>Evaluates the model on a data generator.</p>
<p>DEPRECATED:
  <code>Model.evaluate</code> now supports generators, so there is no longer any
  need to use this endpoint.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_generate_docs</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">evaluate_generator</span><span class="p">(</span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">generator</span><span class="p">,</span>

<span class="w">        </span><span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

<span class="w">        </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="k">False</span><span class="p">,</span>

<span class="w">        </span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Evaluates the model on a data generator.</span>

<span class="ss">        DEPRECATED:</span>

<span class="ss">          `Model.evaluate` now supports generators, so there is no longer any</span>

<span class="ss">          need to use this endpoint.</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span>

<span class="w">            </span><span class="ss">&quot;`Model.evaluate_generator` is deprecated and &quot;</span>

<span class="w">            </span><span class="ss">&quot;will be removed in a future version. &quot;</span>

<span class="w">            </span><span class="ss">&quot;Please use `Model.evaluate`, which supports generators.&quot;</span><span class="p">,</span>

<span class="w">            </span><span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>

<span class="w">        </span><span class="p">)</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="ss">&quot;evaluate_generator&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span>

<span class="w">            </span><span class="n">generator</span><span class="p">,</span>

<span class="w">            </span><span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>

<span class="w">            </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

<span class="w">            </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

<span class="w">            </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

<span class="w">            </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>

<span class="w">            </span><span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="finalize_state_1">finalize_state</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">finalize_state</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Finalizes the layers state after updating layer weights.</p>
<p>This function can be subclassed in a layer and will be called after
updating a layer weights. It can be overridden to finalize any
additional layer state after a weight update.</p>
<p>This function will be called after weights of a layer have been restored
from a loaded model.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="err">@</span><span class="n">doc_controls</span><span class="o">.</span><span class="n">do_not_generate_docs</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">finalize_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;Finalizes the layers state after updating layer weights.</span>

<span class="sd">        This function can be subclassed in a layer and will be called after</span>

<span class="sd">        updating a layer weights. It can be overridden to finalize any</span>

<span class="sd">        additional layer state after a weight update.</span>

<span class="sd">        This function will be called after weights of a layer have been restored</span>

<span class="sd">        from a loaded model.</span>

<span class="sd">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">pass</span>
</code></pre></div>

</details>
<h4 id="fit_1">fit</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Trains the model for a fixed number of epochs (iterations on a dataset).</p>
<p>Args:
    x: Input data. It could be:
      - A Numpy array (or array-like), or a list of arrays
        (in case the model has multiple inputs).
      - A TensorFlow tensor, or a list of tensors
        (in case the model has multiple inputs).
      - A dict mapping input names to the corresponding array/tensors,
        if the model has named inputs.
      - A <code>tf.data</code> dataset. Should return a tuple
        of either <code>(inputs, targets)</code> or
        <code>(inputs, targets, sample_weights)</code>.
      - A generator or <code>keras.utils.Sequence</code> returning <code>(inputs,
        targets)</code> or <code>(inputs, targets, sample_weights)</code>.
      - A <code>tf.keras.utils.experimental.DatasetCreator</code>, which wraps a
        callable that takes a single argument of type
        <code>tf.distribute.InputContext</code>, and returns a <code>tf.data.Dataset</code>.
        <code>DatasetCreator</code> should be used when users prefer to specify the
        per-replica batching and sharding logic for the <code>Dataset</code>.
        See <code>tf.keras.utils.experimental.DatasetCreator</code> doc for more
        information.
      A more detailed description of unpacking behavior for iterator
      types (Dataset, generator, Sequence) is given below. If these
      include <code>sample_weights</code> as a third component, note that sample
      weighting applies to the <code>weighted_metrics</code> argument but not the
      <code>metrics</code> argument in <code>compile()</code>. If using
      <code>tf.distribute.experimental.ParameterServerStrategy</code>, only
      <code>DatasetCreator</code> type is supported for <code>x</code>.
    y: Target data. Like the input data <code>x</code>,
      it could be either Numpy array(s) or TensorFlow tensor(s).
      It should be consistent with <code>x</code> (you cannot have Numpy inputs and
      tensor targets, or inversely). If <code>x</code> is a dataset, generator,
      or <code>keras.utils.Sequence</code> instance, <code>y</code> should
      not be specified (since targets will be obtained from <code>x</code>).
    batch_size: Integer or <code>None</code>.
        Number of samples per gradient update.
        If unspecified, <code>batch_size</code> will default to 32.
        Do not specify the <code>batch_size</code> if your data is in the
        form of datasets, generators, or <code>keras.utils.Sequence</code>
        instances (since they generate batches).
    epochs: Integer. Number of epochs to train the model.
        An epoch is an iteration over the entire <code>x</code> and <code>y</code>
        data provided
        (unless the <code>steps_per_epoch</code> flag is set to
        something other than None).
        Note that in conjunction with <code>initial_epoch</code>,
        <code>epochs</code> is to be understood as "final epoch".
        The model is not trained for a number of iterations
        given by <code>epochs</code>, but merely until the epoch
        of index <code>epochs</code> is reached.
    verbose: 'auto', 0, 1, or 2. Verbosity mode.
        0 = silent, 1 = progress bar, 2 = one line per epoch.
        'auto' defaults to 1 for most cases, but 2 when used with
        <code>ParameterServerStrategy</code>. Note that the progress bar is not
        particularly useful when logged to a file, so verbose=2 is
        recommended when not running interactively (eg, in a production
        environment).
    callbacks: List of <code>keras.callbacks.Callback</code> instances.
        List of callbacks to apply during training.
        See <code>tf.keras.callbacks</code>. Note
        <code>tf.keras.callbacks.ProgbarLogger</code> and
        <code>tf.keras.callbacks.History</code> callbacks are created automatically
        and need not be passed into <code>model.fit</code>.
        <code>tf.keras.callbacks.ProgbarLogger</code> is created or not based on
        <code>verbose</code> argument to <code>model.fit</code>.
        Callbacks with batch-level calls are currently unsupported with
        <code>tf.distribute.experimental.ParameterServerStrategy</code>, and users
        are advised to implement epoch-level calls instead with an
        appropriate <code>steps_per_epoch</code> value.
    validation_split: Float between 0 and 1.
        Fraction of the training data to be used as validation data.
        The model will set apart this fraction of the training data,
        will not train on it, and will evaluate
        the loss and any model metrics
        on this data at the end of each epoch.
        The validation data is selected from the last samples
        in the <code>x</code> and <code>y</code> data provided, before shuffling. This
        argument is not supported when <code>x</code> is a dataset, generator or
        <code>keras.utils.Sequence</code> instance.
        If both <code>validation_data</code> and <code>validation_split</code> are provided,
        <code>validation_data</code> will override <code>validation_split</code>.
        <code>validation_split</code> is not yet supported with
        <code>tf.distribute.experimental.ParameterServerStrategy</code>.
    validation_data: Data on which to evaluate
        the loss and any model metrics at the end of each epoch.
        The model will not be trained on this data. Thus, note the fact
        that the validation loss of data provided using
        <code>validation_split</code> or <code>validation_data</code> is not affected by
        regularization layers like noise and dropout.
        <code>validation_data</code> will override <code>validation_split</code>.
        <code>validation_data</code> could be:
          - A tuple <code>(x_val, y_val)</code> of Numpy arrays or tensors.
          - A tuple <code>(x_val, y_val, val_sample_weights)</code> of NumPy
            arrays.
          - A <code>tf.data.Dataset</code>.
          - A Python generator or <code>keras.utils.Sequence</code> returning
          <code>(inputs, targets)</code> or <code>(inputs, targets, sample_weights)</code>.
        <code>validation_data</code> is not yet supported with
        <code>tf.distribute.experimental.ParameterServerStrategy</code>.
    shuffle: Boolean (whether to shuffle the training data
        before each epoch) or str (for 'batch'). This argument is
        ignored when <code>x</code> is a generator or an object of tf.data.Dataset.
        'batch' is a special option for dealing
        with the limitations of HDF5 data; it shuffles in batch-sized
        chunks. Has no effect when <code>steps_per_epoch</code> is not <code>None</code>.
    class_weight: Optional dictionary mapping class indices (integers)
        to a weight (float) value, used for weighting the loss function
        (during training only).
        This can be useful to tell the model to
        "pay more attention" to samples from
        an under-represented class.
    sample_weight: Optional Numpy array of weights for
        the training samples, used for weighting the loss function
        (during training only). You can either pass a flat (1D)
        Numpy array with the same length as the input samples
        (1:1 mapping between weights and samples),
        or in the case of temporal data,
        you can pass a 2D array with shape
        <code>(samples, sequence_length)</code>,
        to apply a different weight to every timestep of every sample.
        This argument is not supported when <code>x</code> is a dataset, generator,
        or <code>keras.utils.Sequence</code> instance, instead provide the
        sample_weights as the third element of <code>x</code>.
        Note that sample weighting does not apply to metrics specified
        via the <code>metrics</code> argument in <code>compile()</code>. To apply sample
        weighting to your metrics, you can specify them via the
        <code>weighted_metrics</code> in <code>compile()</code> instead.
    initial_epoch: Integer.
        Epoch at which to start training
        (useful for resuming a previous training run).
    steps_per_epoch: Integer or <code>None</code>.
        Total number of steps (batches of samples)
        before declaring one epoch finished and starting the
        next epoch. When training with input tensors such as
        TensorFlow data tensors, the default <code>None</code> is equal to
        the number of samples in your dataset divided by
        the batch size, or 1 if that cannot be determined. If x is a
        <code>tf.data</code> dataset, and 'steps_per_epoch'
        is None, the epoch will run until the input dataset is
        exhausted.  When passing an infinitely repeating dataset, you
        must specify the <code>steps_per_epoch</code> argument. If
        <code>steps_per_epoch=-1</code> the training will run indefinitely with an
        infinitely repeating dataset.  This argument is not supported
        with array inputs.
        When using <code>tf.distribute.experimental.ParameterServerStrategy</code>:
          * <code>steps_per_epoch=None</code> is not supported.
    validation_steps: Only relevant if <code>validation_data</code> is provided and
        is a <code>tf.data</code> dataset. Total number of steps (batches of
        samples) to draw before stopping when performing validation
        at the end of every epoch. If 'validation_steps' is None,
        validation will run until the <code>validation_data</code> dataset is
        exhausted. In the case of an infinitely repeated dataset, it
        will run into an infinite loop. If 'validation_steps' is
        specified and only part of the dataset will be consumed, the
        evaluation will start from the beginning of the dataset at each
        epoch. This ensures that the same validation samples are used
        every time.
    validation_batch_size: Integer or <code>None</code>.
        Number of samples per validation batch.
        If unspecified, will default to <code>batch_size</code>.
        Do not specify the <code>validation_batch_size</code> if your data is in
        the form of datasets, generators, or <code>keras.utils.Sequence</code>
        instances (since they generate batches).
    validation_freq: Only relevant if validation data is provided.
      Integer or <code>collections.abc.Container</code> instance (e.g. list, tuple,
      etc.).  If an integer, specifies how many training epochs to run
      before a new validation run is performed, e.g. <code>validation_freq=2</code>
      runs validation every 2 epochs. If a Container, specifies the
      epochs on which to run validation, e.g.
      <code>validation_freq=[1, 2, 10]</code> runs validation at the end of the
      1st, 2nd, and 10th epochs.
    max_queue_size: Integer. Used for generator or
      <code>keras.utils.Sequence</code> input only. Maximum size for the generator
      queue.  If unspecified, <code>max_queue_size</code> will default to 10.
    workers: Integer. Used for generator or <code>keras.utils.Sequence</code> input
        only. Maximum number of processes to spin up
        when using process-based threading. If unspecified, <code>workers</code>
        will default to 1.
    use_multiprocessing: Boolean. Used for generator or
        <code>keras.utils.Sequence</code> input only. If <code>True</code>, use process-based
        threading. If unspecified, <code>use_multiprocessing</code> will default to
        <code>False</code>. Note that because this implementation relies on
        multiprocessing, you should not pass non-picklable arguments to
        the generator as they can't be passed easily to children
        processes.</p>
<p>Unpacking behavior for iterator-like inputs:
    A common pattern is to pass a tf.data.Dataset, generator, or
  tf.keras.utils.Sequence to the <code>x</code> argument of fit, which will in fact
  yield not only features (x) but optionally targets (y) and sample
  weights.  Keras requires that the output of such iterator-likes be
  unambiguous. The iterator should return a tuple of length 1, 2, or 3,
  where the optional second and third elements will be used for y and
  sample_weight respectively. Any other type provided will be wrapped in
  a length one tuple, effectively treating everything as 'x'. When
  yielding dicts, they should still adhere to the top-level tuple
  structure.
  e.g. <code>({"x0": x0, "x1": x1}, y)</code>. Keras will not attempt to separate
  features, targets, and weights from the keys of a single dict.
    A notable unsupported data type is the namedtuple. The reason is
  that it behaves like both an ordered datatype (tuple) and a mapping
  datatype (dict). So given a namedtuple of the form:
      <code>namedtuple("example_tuple", ["y", "x"])</code>
  it is ambiguous whether to reverse the order of the elements when
  interpreting the value. Even worse is a tuple of the form:
      <code>namedtuple("other_tuple", ["x", "y", "z"])</code>
  where it is unclear if the tuple was intended to be unpacked into x,
  y, and sample_weight or passed through as a single element to <code>x</code>. As
  a result the data processing code will simply raise a ValueError if it
  encounters a namedtuple. (Along with instructions to remedy the
  issue.)</p>
<p>Returns:
    A <code>History</code> object. Its <code>History.history</code> attribute is
    a record of training loss values and metrics values
    at successive epochs, as well as validation loss values
    and validation metrics values (if applicable).</p>
<p>Raises:
    RuntimeError: 1. If the model was never compiled or,
    2. If <code>model.fit</code> is  wrapped in <code>tf.function</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">ValueError</span><span class="o">:</span><span class="w"> </span><span class="n">In</span><span class="w"> </span><span class="k">case</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">mismatch</span><span class="w"> </span><span class="n">between</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">provided</span><span class="w"> </span><span class="n">input</span><span class="w"> </span><span class="n">data</span>
<span class="w">    </span><span class="n">and</span><span class="w"> </span><span class="n">what</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">expects</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">when</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">input</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">empty</span><span class="o">.</span>
</code></pre></div>

<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="err">@</span><span class="n">traceback_utils</span><span class="o">.</span><span class="n">filter_traceback</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">fit</span><span class="p">(</span>

<span class="w">        </span><span class="bp">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">x</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">y</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">batch_size</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="n">verbose</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">validation_split</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>

<span class="w">        </span><span class="n">validation_data</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">shuffle</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

<span class="w">        </span><span class="n">class_weight</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

<span class="w">        </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">validation_steps</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">validation_batch_size</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

<span class="w">        </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">False</span><span class="p">,</span>

<span class="w">    </span><span class="p">):</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;Trains the model for a fixed number of epochs (iterations on a dataset).</span>

<span class="sd">        Args:</span>

<span class="sd">            x: Input data. It could be:</span>

<span class="sd">              - A Numpy array (or array-like), or a list of arrays</span>

<span class="sd">                (in case the model has multiple inputs).</span>

<span class="sd">              - A TensorFlow tensor, or a list of tensors</span>

<span class="sd">                (in case the model has multiple inputs).</span>

<span class="sd">              - A dict mapping input names to the corresponding array/tensors,</span>

<span class="sd">                if the model has named inputs.</span>

<span class="sd">              - A `tf.data` dataset. Should return a tuple</span>

<span class="sd">                of either `(inputs, targets)` or</span>

<span class="sd">                `(inputs, targets, sample_weights)`.</span>

<span class="sd">              - A generator or `keras.utils.Sequence` returning `(inputs,</span>

<span class="sd">                targets)` or `(inputs, targets, sample_weights)`.</span>

<span class="sd">              - A `tf.keras.utils.experimental.DatasetCreator`, which wraps a</span>

<span class="sd">                callable that takes a single argument of type</span>

<span class="sd">                `tf.distribute.InputContext`, and returns a `tf.data.Dataset`.</span>

<span class="sd">                `DatasetCreator` should be used when users prefer to specify the</span>

<span class="sd">                per-replica batching and sharding logic for the `Dataset`.</span>

<span class="sd">                See `tf.keras.utils.experimental.DatasetCreator` doc for more</span>

<span class="sd">                information.</span>

<span class="sd">              A more detailed description of unpacking behavior for iterator</span>

<span class="sd">              types (Dataset, generator, Sequence) is given below. If these</span>

<span class="sd">              include `sample_weights` as a third component, note that sample</span>

<span class="sd">              weighting applies to the `weighted_metrics` argument but not the</span>

<span class="sd">              `metrics` argument in `compile()`. If using</span>

<span class="sd">              `tf.distribute.experimental.ParameterServerStrategy`, only</span>

<span class="sd">              `DatasetCreator` type is supported for `x`.</span>

<span class="sd">            y: Target data. Like the input data `x`,</span>

<span class="sd">              it could be either Numpy array(s) or TensorFlow tensor(s).</span>

<span class="sd">              It should be consistent with `x` (you cannot have Numpy inputs and</span>

<span class="sd">              tensor targets, or inversely). If `x` is a dataset, generator,</span>

<span class="sd">              or `keras.utils.Sequence` instance, `y` should</span>

<span class="sd">              not be specified (since targets will be obtained from `x`).</span>

<span class="sd">            batch_size: Integer or `None`.</span>

<span class="sd">                Number of samples per gradient update.</span>

<span class="sd">                If unspecified, `batch_size` will default to 32.</span>

<span class="sd">                Do not specify the `batch_size` if your data is in the</span>

<span class="sd">                form of datasets, generators, or `keras.utils.Sequence`</span>

<span class="sd">                instances (since they generate batches).</span>

<span class="sd">            epochs: Integer. Number of epochs to train the model.</span>

<span class="sd">                An epoch is an iteration over the entire `x` and `y`</span>

<span class="sd">                data provided</span>

<span class="sd">                (unless the `steps_per_epoch` flag is set to</span>

<span class="sd">                something other than None).</span>

<span class="sd">                Note that in conjunction with `initial_epoch`,</span>

<span class="sd">                `epochs` is to be understood as &quot;final epoch&quot;.</span>

<span class="sd">                The model is not trained for a number of iterations</span>

<span class="sd">                given by `epochs`, but merely until the epoch</span>

<span class="sd">                of index `epochs` is reached.</span>

<span class="sd">            verbose: &#39;auto&#39;, 0, 1, or 2. Verbosity mode.</span>

<span class="sd">                0 = silent, 1 = progress bar, 2 = one line per epoch.</span>

<span class="sd">                &#39;auto&#39; defaults to 1 for most cases, but 2 when used with</span>

<span class="sd">                `ParameterServerStrategy`. Note that the progress bar is not</span>

<span class="sd">                particularly useful when logged to a file, so verbose=2 is</span>

<span class="sd">                recommended when not running interactively (eg, in a production</span>

<span class="sd">                environment).</span>

<span class="sd">            callbacks: List of `keras.callbacks.Callback` instances.</span>

<span class="sd">                List of callbacks to apply during training.</span>

<span class="sd">                See `tf.keras.callbacks`. Note</span>

<span class="sd">                `tf.keras.callbacks.ProgbarLogger` and</span>

<span class="sd">                `tf.keras.callbacks.History` callbacks are created automatically</span>

<span class="sd">                and need not be passed into `model.fit`.</span>

<span class="sd">                `tf.keras.callbacks.ProgbarLogger` is created or not based on</span>

<span class="sd">                `verbose` argument to `model.fit`.</span>

<span class="sd">                Callbacks with batch-level calls are currently unsupported with</span>

<span class="sd">                `tf.distribute.experimental.ParameterServerStrategy`, and users</span>

<span class="sd">                are advised to implement epoch-level calls instead with an</span>

<span class="sd">                appropriate `steps_per_epoch` value.</span>

<span class="sd">            validation_split: Float between 0 and 1.</span>

<span class="sd">                Fraction of the training data to be used as validation data.</span>

<span class="sd">                The model will set apart this fraction of the training data,</span>

<span class="sd">                will not train on it, and will evaluate</span>

<span class="sd">                the loss and any model metrics</span>

<span class="sd">                on this data at the end of each epoch.</span>

<span class="sd">                The validation data is selected from the last samples</span>

<span class="sd">                in the `x` and `y` data provided, before shuffling. This</span>

<span class="sd">                argument is not supported when `x` is a dataset, generator or</span>

<span class="sd">                `keras.utils.Sequence` instance.</span>

<span class="sd">                If both `validation_data` and `validation_split` are provided,</span>

<span class="sd">                `validation_data` will override `validation_split`.</span>

<span class="sd">                `validation_split` is not yet supported with</span>

<span class="sd">                `tf.distribute.experimental.ParameterServerStrategy`.</span>

<span class="sd">            validation_data: Data on which to evaluate</span>

<span class="sd">                the loss and any model metrics at the end of each epoch.</span>

<span class="sd">                The model will not be trained on this data. Thus, note the fact</span>

<span class="sd">                that the validation loss of data provided using</span>

<span class="sd">                `validation_split` or `validation_data` is not affected by</span>

<span class="sd">                regularization layers like noise and dropout.</span>

<span class="sd">                `validation_data` will override `validation_split`.</span>

<span class="sd">                `validation_data` could be:</span>

<span class="sd">                  - A tuple `(x_val, y_val)` of Numpy arrays or tensors.</span>

<span class="sd">                  - A tuple `(x_val, y_val, val_sample_weights)` of NumPy</span>

<span class="sd">                    arrays.</span>

<span class="sd">                  - A `tf.data.Dataset`.</span>

<span class="sd">                  - A Python generator or `keras.utils.Sequence` returning</span>

<span class="sd">                  `(inputs, targets)` or `(inputs, targets, sample_weights)`.</span>

<span class="sd">                `validation_data` is not yet supported with</span>

<span class="sd">                `tf.distribute.experimental.ParameterServerStrategy`.</span>

<span class="sd">            shuffle: Boolean (whether to shuffle the training data</span>

<span class="sd">                before each epoch) or str (for &#39;batch&#39;). This argument is</span>

<span class="sd">                ignored when `x` is a generator or an object of tf.data.Dataset.</span>

<span class="sd">                &#39;batch&#39; is a special option for dealing</span>

<span class="sd">                with the limitations of HDF5 data; it shuffles in batch-sized</span>

<span class="sd">                chunks. Has no effect when `steps_per_epoch` is not `None`.</span>

<span class="sd">            class_weight: Optional dictionary mapping class indices (integers)</span>

<span class="sd">                to a weight (float) value, used for weighting the loss function</span>

<span class="sd">                (during training only).</span>

<span class="sd">                This can be useful to tell the model to</span>

<span class="sd">                &quot;pay more attention&quot; to samples from</span>

<span class="sd">                an under-represented class.</span>

<span class="sd">            sample_weight: Optional Numpy array of weights for</span>

<span class="sd">                the training samples, used for weighting the loss function</span>

<span class="sd">                (during training only). You can either pass a flat (1D)</span>

<span class="sd">                Numpy array with the same length as the input samples</span>

<span class="sd">                (1:1 mapping between weights and samples),</span>

<span class="sd">                or in the case of temporal data,</span>

<span class="sd">                you can pass a 2D array with shape</span>

<span class="sd">                `(samples, sequence_length)`,</span>

<span class="sd">                to apply a different weight to every timestep of every sample.</span>

<span class="sd">                This argument is not supported when `x` is a dataset, generator,</span>

<span class="sd">                or `keras.utils.Sequence` instance, instead provide the</span>

<span class="sd">                sample_weights as the third element of `x`.</span>

<span class="sd">                Note that sample weighting does not apply to metrics specified</span>

<span class="sd">                via the `metrics` argument in `compile()`. To apply sample</span>

<span class="sd">                weighting to your metrics, you can specify them via the</span>

<span class="sd">                `weighted_metrics` in `compile()` instead.</span>

<span class="sd">            initial_epoch: Integer.</span>

<span class="sd">                Epoch at which to start training</span>

<span class="sd">                (useful for resuming a previous training run).</span>

<span class="sd">            steps_per_epoch: Integer or `None`.</span>

<span class="sd">                Total number of steps (batches of samples)</span>

<span class="sd">                before declaring one epoch finished and starting the</span>

<span class="sd">                next epoch. When training with input tensors such as</span>

<span class="sd">                TensorFlow data tensors, the default `None` is equal to</span>

<span class="sd">                the number of samples in your dataset divided by</span>

<span class="sd">                the batch size, or 1 if that cannot be determined. If x is a</span>

<span class="sd">                `tf.data` dataset, and &#39;steps_per_epoch&#39;</span>

<span class="sd">                is None, the epoch will run until the input dataset is</span>

<span class="sd">                exhausted.  When passing an infinitely repeating dataset, you</span>

<span class="sd">                must specify the `steps_per_epoch` argument. If</span>

<span class="sd">                `steps_per_epoch=-1` the training will run indefinitely with an</span>

<span class="sd">                infinitely repeating dataset.  This argument is not supported</span>

<span class="sd">                with array inputs.</span>

<span class="sd">                When using `tf.distribute.experimental.ParameterServerStrategy`:</span>

<span class="sd">                  * `steps_per_epoch=None` is not supported.</span>

<span class="sd">            validation_steps: Only relevant if `validation_data` is provided and</span>

<span class="sd">                is a `tf.data` dataset. Total number of steps (batches of</span>

<span class="sd">                samples) to draw before stopping when performing validation</span>

<span class="sd">                at the end of every epoch. If &#39;validation_steps&#39; is None,</span>

<span class="sd">                validation will run until the `validation_data` dataset is</span>

<span class="sd">                exhausted. In the case of an infinitely repeated dataset, it</span>

<span class="sd">                will run into an infinite loop. If &#39;validation_steps&#39; is</span>

<span class="sd">                specified and only part of the dataset will be consumed, the</span>

<span class="sd">                evaluation will start from the beginning of the dataset at each</span>

<span class="sd">                epoch. This ensures that the same validation samples are used</span>

<span class="sd">                every time.</span>

<span class="sd">            validation_batch_size: Integer or `None`.</span>

<span class="sd">                Number of samples per validation batch.</span>

<span class="sd">                If unspecified, will default to `batch_size`.</span>

<span class="sd">                Do not specify the `validation_batch_size` if your data is in</span>

<span class="sd">                the form of datasets, generators, or `keras.utils.Sequence`</span>

<span class="sd">                instances (since they generate batches).</span>

<span class="sd">            validation_freq: Only relevant if validation data is provided.</span>

<span class="sd">              Integer or `collections.abc.Container` instance (e.g. list, tuple,</span>

<span class="sd">              etc.).  If an integer, specifies how many training epochs to run</span>

<span class="sd">              before a new validation run is performed, e.g. `validation_freq=2`</span>

<span class="sd">              runs validation every 2 epochs. If a Container, specifies the</span>

<span class="sd">              epochs on which to run validation, e.g.</span>

<span class="sd">              `validation_freq=[1, 2, 10]` runs validation at the end of the</span>

<span class="sd">              1st, 2nd, and 10th epochs.</span>

<span class="sd">            max_queue_size: Integer. Used for generator or</span>

<span class="sd">              `keras.utils.Sequence` input only. Maximum size for the generator</span>

<span class="sd">              queue.  If unspecified, `max_queue_size` will default to 10.</span>

<span class="sd">            workers: Integer. Used for generator or `keras.utils.Sequence` input</span>

<span class="sd">                only. Maximum number of processes to spin up</span>

<span class="sd">                when using process-based threading. If unspecified, `workers`</span>

<span class="sd">                will default to 1.</span>

<span class="sd">            use_multiprocessing: Boolean. Used for generator or</span>

<span class="sd">                `keras.utils.Sequence` input only. If `True`, use process-based</span>

<span class="sd">                threading. If unspecified, `use_multiprocessing` will default to</span>

<span class="sd">                `False`. Note that because this implementation relies on</span>

<span class="sd">                multiprocessing, you should not pass non-picklable arguments to</span>

<span class="sd">                the generator as they can&#39;t be passed easily to children</span>

<span class="sd">                processes.</span>

<span class="sd">        Unpacking behavior for iterator-like inputs:</span>

<span class="sd">            A common pattern is to pass a tf.data.Dataset, generator, or</span>

<span class="sd">          tf.keras.utils.Sequence to the `x` argument of fit, which will in fact</span>

<span class="sd">          yield not only features (x) but optionally targets (y) and sample</span>

<span class="sd">          weights.  Keras requires that the output of such iterator-likes be</span>

<span class="sd">          unambiguous. The iterator should return a tuple of length 1, 2, or 3,</span>

<span class="sd">          where the optional second and third elements will be used for y and</span>

<span class="sd">          sample_weight respectively. Any other type provided will be wrapped in</span>

<span class="sd">          a length one tuple, effectively treating everything as &#39;x&#39;. When</span>

<span class="sd">          yielding dicts, they should still adhere to the top-level tuple</span>

<span class="sd">          structure.</span>

<span class="sd">          e.g. `({&quot;x0&quot;: x0, &quot;x1&quot;: x1}, y)`. Keras will not attempt to separate</span>

<span class="sd">          features, targets, and weights from the keys of a single dict.</span>

<span class="sd">            A notable unsupported data type is the namedtuple. The reason is</span>

<span class="sd">          that it behaves like both an ordered datatype (tuple) and a mapping</span>

<span class="sd">          datatype (dict). So given a namedtuple of the form:</span>

<span class="sd">              `namedtuple(&quot;example_tuple&quot;, [&quot;y&quot;, &quot;x&quot;])`</span>

<span class="sd">          it is ambiguous whether to reverse the order of the elements when</span>

<span class="sd">          interpreting the value. Even worse is a tuple of the form:</span>

<span class="sd">              `namedtuple(&quot;other_tuple&quot;, [&quot;x&quot;, &quot;y&quot;, &quot;z&quot;])`</span>

<span class="sd">          where it is unclear if the tuple was intended to be unpacked into x,</span>

<span class="sd">          y, and sample_weight or passed through as a single element to `x`. As</span>

<span class="sd">          a result the data processing code will simply raise a ValueError if it</span>

<span class="sd">          encounters a namedtuple. (Along with instructions to remedy the</span>

<span class="sd">          issue.)</span>

<span class="sd">        Returns:</span>

<span class="sd">            A `History` object. Its `History.history` attribute is</span>

<span class="sd">            a record of training loss values and metrics values</span>

<span class="sd">            at successive epochs, as well as validation loss values</span>

<span class="sd">            and validation metrics values (if applicable).</span>

<span class="sd">        Raises:</span>

<span class="sd">            RuntimeError: 1. If the model was never compiled or,</span>

<span class="sd">            2. If `model.fit` is  wrapped in `tf.function`.</span>

<span class="sd">            ValueError: In case of mismatch between the provided input data</span>

<span class="sd">                and what the model expects or when the input data is empty.</span>

<span class="sd">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">base_layer</span><span class="o">.</span><span class="n">keras_api_gauge</span><span class="o">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s2">&quot;fit&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">True</span><span class="p">)</span>

<span class="w">        </span><span class="c1"># Legacy graph support is contained in `training_v1.Model`.</span>

<span class="w">        </span><span class="n">version_utils</span><span class="o">.</span><span class="n">disallow_legacy_graph</span><span class="p">(</span><span class="s2">&quot;Model&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;fit&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s2">&quot;fit&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s2">&quot;fit&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="n">verbose</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">_get_verbosity</span><span class="p">(</span><span class="n">verbose</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">validation_split</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">validation_data</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">            </span><span class="c1"># Create the validation data using the training data. Only supported</span>

<span class="w">            </span><span class="c1"># for `Tensor` and `NumPy` input.</span>

<span class="w">            </span><span class="p">(</span>

<span class="w">                </span><span class="n">x</span><span class="p">,</span>

<span class="w">                </span><span class="n">y</span><span class="p">,</span>

<span class="w">                </span><span class="n">sample_weight</span><span class="p">,</span>

<span class="w">            </span><span class="p">),</span><span class="w"> </span><span class="n">validation_data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">train_validation_split</span><span class="p">(</span>

<span class="w">                </span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">),</span><span class="w"> </span><span class="n">validation_split</span><span class="o">=</span><span class="n">validation_split</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">validation_data</span><span class="p">:</span>

<span class="w">            </span><span class="p">(</span>

<span class="w">                </span><span class="n">val_x</span><span class="p">,</span>

<span class="w">                </span><span class="n">val_y</span><span class="p">,</span>

<span class="w">                </span><span class="n">val_sample_weight</span><span class="p">,</span>

<span class="w">            </span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">validation_data</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="o">.</span><span class="n">_should_use_with_coordinator</span><span class="p">:</span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">_cluster_coordinator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span>

<span class="w">                </span><span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">coordinator</span><span class="o">.</span><span class="n">ClusterCoordinator</span><span class="p">(</span>

<span class="w">                    </span><span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="n">with</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">(),</span><span class="w"> </span><span class="n">training_utils</span><span class="o">.</span><span class="n">RespectCompiledTrainableState</span><span class="p">(</span><span class="w">  </span><span class="c1"># noqa: E501</span>

<span class="w">            </span><span class="bp">self</span>

<span class="w">        </span><span class="p">):</span>

<span class="w">            </span><span class="c1"># Creates a `tf.data.Dataset` and handles batch and epoch iteration.</span>

<span class="w">            </span><span class="n">data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">get_data_handler</span><span class="p">(</span>

<span class="w">                </span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>

<span class="w">                </span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>

<span class="w">                </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>

<span class="w">                </span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>

<span class="w">                </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span>

<span class="w">                </span><span class="n">initial_epoch</span><span class="o">=</span><span class="n">initial_epoch</span><span class="p">,</span>

<span class="w">                </span><span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>

<span class="w">                </span><span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>

<span class="w">                </span><span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span>

<span class="w">                </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

<span class="w">                </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

<span class="w">                </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

<span class="w">                </span><span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>

<span class="w">                </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps_per_execution</span><span class="p">,</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">            </span><span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span><span class="w"> </span><span class="n">callbacks_module</span><span class="o">.</span><span class="n">CallbackList</span><span class="p">):</span>

<span class="w">                </span><span class="n">callbacks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">callbacks_module</span><span class="o">.</span><span class="n">CallbackList</span><span class="p">(</span>

<span class="w">                    </span><span class="n">callbacks</span><span class="p">,</span>

<span class="w">                    </span><span class="n">add_history</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

<span class="w">                    </span><span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>

<span class="w">                    </span><span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>

<span class="w">                    </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>

<span class="w">                    </span><span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>

<span class="w">                    </span><span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="o">.</span><span class="n">inferred_steps</span><span class="p">,</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">False</span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">make_train_function</span><span class="p">()</span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">_train_counter</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="w">            </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_begin</span><span class="p">()</span>

<span class="w">            </span><span class="n">training_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span>

<span class="w">            </span><span class="c1"># Handle fault-tolerance for multi-worker.</span>

<span class="w">            </span><span class="c1"># TODO(omalleyt): Fix the ordering issues that mean this has to</span>

<span class="w">            </span><span class="c1"># happen after `callbacks.on_train_begin`.</span>

<span class="w">            </span><span class="n">steps_per_epoch_inferred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span>

<span class="w">                </span><span class="n">steps_per_epoch</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">inferred_steps</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">            </span><span class="p">(</span>

<span class="w">                </span><span class="n">data_handler</span><span class="o">.</span><span class="n">_initial_epoch</span><span class="p">,</span>

<span class="w">                </span><span class="n">data_handler</span><span class="o">.</span><span class="n">_initial_step</span><span class="p">,</span>

<span class="w">            </span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_maybe_load_initial_counters_from_ckpt</span><span class="p">(</span>

<span class="w">                </span><span class="n">steps_per_epoch_inferred</span><span class="p">,</span><span class="w"> </span><span class="n">initial_epoch</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">            </span><span class="n">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span>

<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">epoch</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">enumerate_epochs</span><span class="p">():</span>

<span class="w">                </span><span class="bp">self</span><span class="o">.</span><span class="n">reset_metrics</span><span class="p">()</span>

<span class="w">                </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_epoch_begin</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

<span class="w">                </span><span class="n">with</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">catch_stop_iteration</span><span class="p">():</span>

<span class="w">                    </span><span class="k">for</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">steps</span><span class="p">():</span>

<span class="w">                        </span><span class="n">with</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">Trace</span><span class="p">(</span>

<span class="w">                            </span><span class="s2">&quot;train&quot;</span><span class="p">,</span>

<span class="w">                            </span><span class="n">epoch_num</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>

<span class="w">                            </span><span class="n">step_num</span><span class="o">=</span><span class="n">step</span><span class="p">,</span>

<span class="w">                            </span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>

<span class="w">                            </span><span class="n">_r</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">                        </span><span class="p">):</span>

<span class="w">                            </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>

<span class="w">                            </span><span class="n">tmp_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

<span class="w">                            </span><span class="k">if</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">should_sync</span><span class="p">:</span>

<span class="w">                                </span><span class="n">context</span><span class="o">.</span><span class="n">async_wait</span><span class="p">()</span>

<span class="w">                            </span><span class="c1"># No error, now safe to assign to logs.</span>

<span class="w">                            </span><span class="n">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tmp_logs</span>

<span class="w">                            </span><span class="n">end_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">step_increment</span>

<span class="w">                            </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_end</span><span class="p">(</span><span class="n">end_step</span><span class="p">,</span><span class="w"> </span><span class="n">logs</span><span class="p">)</span>

<span class="w">                            </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span>

<span class="w">                                </span><span class="k">break</span>

<span class="w">                </span><span class="n">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf_utils</span><span class="o">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">logs</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">                    </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                        </span><span class="s2">&quot;Unexpected result of `train_function` &quot;</span>

<span class="w">                        </span><span class="s2">&quot;(Empty logs). Please use &quot;</span>

<span class="w">                        </span><span class="s2">&quot;`Model.compile(..., run_eagerly=True)`, or &quot;</span>

<span class="w">                        </span><span class="s2">&quot;`tf.config.run_functions_eagerly(True)` for more &quot;</span>

<span class="w">                        </span><span class="s2">&quot;information of where went wrong, or file a &quot;</span>

<span class="w">                        </span><span class="s2">&quot;issue/bug to `tf.keras`.&quot;</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">                </span><span class="c1"># Override with model metrics instead of last step logs</span>

<span class="w">                </span><span class="n">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_validate_and_get_metrics_result</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

<span class="w">                </span><span class="n">epoch_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

<span class="w">                </span><span class="c1"># Run validation.</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">validation_data</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_should_eval</span><span class="p">(</span>

<span class="w">                    </span><span class="n">epoch</span><span class="p">,</span><span class="w"> </span><span class="n">validation_freq</span>

<span class="w">                </span><span class="p">):</span>

<span class="w">                    </span><span class="c1"># Create data_handler for evaluation and cache it.</span>

<span class="w">                    </span><span class="k">if</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;_eval_data_handler&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">                        </span><span class="bp">self</span><span class="o">.</span><span class="n">_eval_data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">get_data_handler</span><span class="p">(</span>

<span class="w">                            </span><span class="n">x</span><span class="o">=</span><span class="n">val_x</span><span class="p">,</span>

<span class="w">                            </span><span class="n">y</span><span class="o">=</span><span class="n">val_y</span><span class="p">,</span>

<span class="w">                            </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">val_sample_weight</span><span class="p">,</span>

<span class="w">                            </span><span class="n">batch_size</span><span class="o">=</span><span class="n">validation_batch_size</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">batch_size</span><span class="p">,</span>

<span class="w">                            </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span>

<span class="w">                            </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

<span class="w">                            </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">                            </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

<span class="w">                            </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

<span class="w">                            </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

<span class="w">                            </span><span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>

<span class="w">                            </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps_per_execution</span><span class="p">,</span>

<span class="w">                        </span><span class="p">)</span>

<span class="w">                    </span><span class="n">val_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>

<span class="w">                        </span><span class="n">x</span><span class="o">=</span><span class="n">val_x</span><span class="p">,</span>

<span class="w">                        </span><span class="n">y</span><span class="o">=</span><span class="n">val_y</span><span class="p">,</span>

<span class="w">                        </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">val_sample_weight</span><span class="p">,</span>

<span class="w">                        </span><span class="n">batch_size</span><span class="o">=</span><span class="n">validation_batch_size</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">batch_size</span><span class="p">,</span>

<span class="w">                        </span><span class="n">steps</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span>

<span class="w">                        </span><span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>

<span class="w">                        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

<span class="w">                        </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

<span class="w">                        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

<span class="w">                        </span><span class="n">return_dict</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

<span class="w">                        </span><span class="n">_use_cached_eval_dataset</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">                    </span><span class="n">val_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>

<span class="w">                        </span><span class="s2">&quot;val_&quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">name</span><span class="p">:</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">val_logs</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>

<span class="w">                    </span><span class="p">}</span>

<span class="w">                    </span><span class="n">epoch_logs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">val_logs</span><span class="p">)</span>

<span class="w">                </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_epoch_end</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="w"> </span><span class="n">epoch_logs</span><span class="p">)</span>

<span class="w">                </span><span class="n">training_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">epoch_logs</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span>

<span class="w">                    </span><span class="k">break</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span>

<span class="w">                </span><span class="n">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span><span class="w"> </span><span class="n">optimizer_experimental</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">)</span>

<span class="w">                </span><span class="ow">and</span><span class="w"> </span><span class="n">epochs</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span>

<span class="w">            </span><span class="p">):</span>

<span class="w">                </span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">finalize_variable_values</span><span class="p">(</span>

<span class="w">                    </span><span class="bp">self</span><span class="o">.</span><span class="n">trainable_variables</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="c1"># If eval data_handler exists, delete it after all epochs are done.</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;_eval_data_handler&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">                </span><span class="n">del</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_eval_data_handler</span>

<span class="w">            </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_end</span><span class="p">(</span><span class="n">logs</span><span class="o">=</span><span class="n">training_logs</span><span class="p">)</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">history</span>
</code></pre></div>

</details>
<h4 id="fit_generator_1">fit_generator</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">fit_generator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>

<p>Fits the model on data yielded batch-by-batch by a Python generator.</p>
<p>DEPRECATED:
  <code>Model.fit</code> now supports generators, so there is no longer any need to
  use this endpoint.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_generate_docs</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">fit_generator</span><span class="p">(</span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">generator</span><span class="p">,</span>

<span class="w">        </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">validation_data</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">validation_steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="n">class_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

<span class="w">        </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="k">False</span><span class="p">,</span>

<span class="w">        </span><span class="n">shuffle</span><span class="o">=</span><span class="k">True</span><span class="p">,</span>

<span class="w">        </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Fits the model on data yielded batch-by-batch by a Python generator.</span>

<span class="ss">        DEPRECATED:</span>

<span class="ss">          `Model.fit` now supports generators, so there is no longer any need to</span>

<span class="ss">          use this endpoint.</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span>

<span class="w">            </span><span class="ss">&quot;`Model.fit_generator` is deprecated and &quot;</span>

<span class="w">            </span><span class="ss">&quot;will be removed in a future version. &quot;</span>

<span class="w">            </span><span class="ss">&quot;Please use `Model.fit`, which supports generators.&quot;</span><span class="p">,</span>

<span class="w">            </span><span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>

<span class="w">        </span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>

<span class="w">            </span><span class="n">generator</span><span class="p">,</span>

<span class="w">            </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span>

<span class="w">            </span><span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>

<span class="w">            </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>

<span class="w">            </span><span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>

<span class="w">            </span><span class="n">validation_data</span><span class="o">=</span><span class="n">validation_data</span><span class="p">,</span>

<span class="w">            </span><span class="n">validation_steps</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span>

<span class="w">            </span><span class="n">validation_freq</span><span class="o">=</span><span class="n">validation_freq</span><span class="p">,</span>

<span class="w">            </span><span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span>

<span class="w">            </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

<span class="w">            </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

<span class="w">            </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

<span class="w">            </span><span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>

<span class="w">            </span><span class="n">initial_epoch</span><span class="o">=</span><span class="n">initial_epoch</span><span class="p">,</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="get_config_1">get_config</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns the config of the <code>Model</code>.</p>
<p>Config is a Python dictionary (serializable) containing the
configuration of an object, which in this case is a <code>Model</code>. This allows
the <code>Model</code> to be be reinstantiated later (without its trained weights)
from this configuration.</p>
<p>Note that <code>get_config()</code> does not guarantee to return a fresh copy of
dict every time it is called. The callers should make a copy of the
returned dict if they want to modify it.</p>
<p>Developers of subclassed <code>Model</code> are advised to override this method,
and continue to update the dict from <code>super(MyModel, self).get_config()</code>
to provide the proper configuration of this <code>Model</code>. The default config
is an empty dict. Optionally, raise <code>NotImplementedError</code> to allow Keras
to attempt a default serialization.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Python dictionary containing the configuration of this <code>Model</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">get_config</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns the config of the `Model`.</span>

<span class="s2">        Config is a Python dictionary (serializable) containing the</span>

<span class="s2">        configuration of an object, which in this case is a `Model`. This allows</span>

<span class="s2">        the `Model` to be be reinstantiated later (without its trained weights)</span>

<span class="s2">        from this configuration.</span>

<span class="s2">        Note that `get_config()` does not guarantee to return a fresh copy of</span>

<span class="s2">        dict every time it is called. The callers should make a copy of the</span>

<span class="s2">        returned dict if they want to modify it.</span>

<span class="s2">        Developers of subclassed `Model` are advised to override this method,</span>

<span class="s2">        and continue to update the dict from `super(MyModel, self).get_config()`</span>

<span class="s2">        to provide the proper configuration of this `Model`. The default config</span>

<span class="s2">        is an empty dict. Optionally, raise `NotImplementedError` to allow Keras</span>

<span class="s2">        to attempt a default serialization.</span>

<span class="s2">        Returns:</span>

<span class="s2">            Python dictionary containing the configuration of this `Model`.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="c1"># Return an empty dict here because otherwise Model</span>

<span class="w">        </span><span class="c1"># subclass developers may see</span>

<span class="w">        </span><span class="c1"># their model&#39;s `__init__()` fed with unexpected keyword arguments,</span>

<span class="w">        </span><span class="c1"># if their `__init__()` takes no argument for example, and they</span>

<span class="w">        </span><span class="c1"># don&#39;t override `from_config()`, which would use `cls(**config)`</span>

<span class="w">        </span><span class="c1"># as a result.</span>

<span class="w">        </span><span class="n">config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">{}</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="n">saving_lib</span><span class="p">.</span><span class="n">_SAVING_V3_ENABLED</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;value&quot;</span><span class="p">,</span><span class="w"> </span><span class="no">False</span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_is_compiled</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">hasattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;_compile_config&quot;</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">config</span><span class="err">[</span><span class="s2">&quot;compile_config&quot;</span><span class="err">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_compile_config</span><span class="p">.</span><span class="n">serialize</span><span class="p">()</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">built</span><span class="o">:</span>

<span class="w">                </span><span class="n">config</span><span class="err">[</span><span class="s2">&quot;build_input_shape&quot;</span><span class="err">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_build_input_shape</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">config</span>
</code></pre></div>

</details>
<h4 id="get_input_at_1">get_input_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_input_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the input tensor(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node<br>from which to retrieve the attribute.<br>E.g. <code>node_index=0</code> will correspond to the<br>first input node of the layer.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A tensor (or list of tensors if the layer has multiple inputs).</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If called in Eager mode.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">get_input_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Retrieves the input tensor(s) of a layer at a given node.</span>

<span class="ss">        Args:</span>

<span class="ss">            node_index: Integer, index of the node</span>

<span class="ss">                from which to retrieve the attribute.</span>

<span class="ss">                E.g. `node_index=0` will correspond to the</span>

<span class="ss">                first input node of the layer.</span>

<span class="ss">        Returns:</span>

<span class="ss">            A tensor (or list of tensors if the layer has multiple inputs).</span>

<span class="ss">        Raises:</span>

<span class="ss">          RuntimeError: If called in Eager mode.</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span>

<span class="w">            </span><span class="n">node_index</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;input_tensors&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;input&quot;</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="get_input_mask_at_1">get_input_mask_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_input_mask_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the input mask tensor(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node<br>from which to retrieve the attribute.<br>E.g. <code>node_index=0</code> will correspond to the<br>first time the layer was called.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A mask tensor<br>(or list of tensors if the layer has multiple inputs).</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">get_input_mask_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Retrieves the input mask tensor(s) of a layer at a given node.</span>

<span class="ss">        Args:</span>

<span class="ss">            node_index: Integer, index of the node</span>

<span class="ss">                from which to retrieve the attribute.</span>

<span class="ss">                E.g. `node_index=0` will correspond to the</span>

<span class="ss">                first time the layer was called.</span>

<span class="ss">        Returns:</span>

<span class="ss">            A mask tensor</span>

<span class="ss">            (or list of tensors if the layer has multiple inputs).</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">get_input_at</span><span class="p">(</span><span class="n">node_index</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">list</span><span class="p">)</span><span class="err">:</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="o">[</span><span class="n">getattr(x, &quot;_keras_mask&quot;, None) for x in inputs</span><span class="o">]</span>

<span class="w">        </span><span class="k">else</span><span class="err">:</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;_keras_mask&quot;</span><span class="p">,</span><span class="w"> </span><span class="k">None</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="get_input_shape_at_1">get_input_shape_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_input_shape_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the input shape(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node<br>from which to retrieve the attribute.<br>E.g. <code>node_index=0</code> will correspond to the<br>first time the layer was called.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A shape tuple<br>(or list of shape tuples if the layer has multiple inputs).</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If called in Eager mode.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">get_input_shape_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Retrieves the input shape(s) of a layer at a given node.</span>

<span class="ss">        Args:</span>

<span class="ss">            node_index: Integer, index of the node</span>

<span class="ss">                from which to retrieve the attribute.</span>

<span class="ss">                E.g. `node_index=0` will correspond to the</span>

<span class="ss">                first time the layer was called.</span>

<span class="ss">        Returns:</span>

<span class="ss">            A shape tuple</span>

<span class="ss">            (or list of shape tuples if the layer has multiple inputs).</span>

<span class="ss">        Raises:</span>

<span class="ss">          RuntimeError: If called in Eager mode.</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span>

<span class="w">            </span><span class="n">node_index</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;input_shapes&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;input shape&quot;</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="get_layer_1">get_layer</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_layer</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">index</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves a layer based on either its name (unique) or index.</p>
<p>If <code>name</code> and <code>index</code> are both provided, <code>index</code> will take precedence.
Indices are based on order of horizontal graph traversal (bottom-up).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>name</td>
<td>None</td>
<td>String, name of layer.</td>
<td>None</td>
</tr>
<tr>
<td>index</td>
<td>None</td>
<td>Integer, index of layer.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A layer instance.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">get_layer</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">name</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"> </span><span class="k">index</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Retrieves a layer based on either its name (unique) or index.</span>

<span class="s2">        If `name` and `index` are both provided, `index` will take precedence.</span>

<span class="s2">        Indices are based on order of horizontal graph traversal (bottom-up).</span>

<span class="s2">        Args:</span>

<span class="s2">            name: String, name of layer.</span>

<span class="s2">            index: Integer, index of layer.</span>

<span class="s2">        Returns:</span>

<span class="s2">            A layer instance.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="c1"># TODO(fchollet): We could build a dictionary based on layer names</span>

<span class="w">        </span><span class="c1"># since they are constant, but we have not done that yet.</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="k">index</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">name</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="o">:</span>

<span class="w">            </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                </span><span class="s2">&quot;Provide only a layer name or a layer index. Received: &quot;</span>

<span class="w">                </span><span class="n">f</span><span class="s2">&quot;index={index}, name={name}.&quot;</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="k">index</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="o">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="k">index</span><span class="o">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                    </span><span class="n">f</span><span class="s2">&quot;Was asked to retrieve layer at index {index}&quot;</span>

<span class="w">                    </span><span class="n">f</span><span class="s2">&quot; but model only has {len(self.layers)}&quot;</span>

<span class="w">                    </span><span class="s2">&quot; layers.&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="k">else</span><span class="o">:</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="err">[</span><span class="k">index</span><span class="err">]</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="k">name</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="o">:</span>

<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="o">:</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">layer</span><span class="p">.</span><span class="k">name</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">name</span><span class="o">:</span>

<span class="w">                    </span><span class="k">return</span><span class="w"> </span><span class="n">layer</span>

<span class="w">            </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                </span><span class="n">f</span><span class="s2">&quot;No such layer: {name}. Existing layers are: &quot;</span>

<span class="w">                </span><span class="n">f</span><span class="s2">&quot;{list(layer.name for layer in self.layers)}.&quot;</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">            </span><span class="s2">&quot;Provide either a layer name or layer index at `get_layer`.&quot;</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="get_metrics_result_1">get_metrics_result</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_metrics_result</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns the model's metrics values as a dict.</p>
<p>If any of the metric result is a dict (containing multiple metrics),
each of them gets added to the top level returned dict of this method.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A <code>dict</code> containing values of the metrics listed in <code>self.metrics</code>.<br>Example:<br><code>{'loss': 0.2, 'accuracy': 0.7}</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">get_metrics_result</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns the model&#39;s metrics values as a dict.</span>

<span class="s2">        If any of the metric result is a dict (containing multiple metrics),</span>

<span class="s2">        each of them gets added to the top level returned dict of this method.</span>

<span class="s2">        Returns:</span>

<span class="s2">          A `dict` containing values of the metrics listed in `self.metrics`.</span>

<span class="s2">          Example:</span>

<span class="s2">          `{&#39;loss&#39;: 0.2, &#39;accuracy&#39;: 0.7}`.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="c1"># Collect metrics to return</span>

<span class="w">        </span><span class="n">return_metrics</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">{}</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">metric</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">metrics</span><span class="o">:</span>

<span class="w">            </span><span class="n">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">metric</span><span class="p">.</span><span class="n">result</span><span class="p">()</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span><span class="w"> </span><span class="n">dict</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">return_metrics</span><span class="p">.</span><span class="k">update</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="w">            </span><span class="k">else</span><span class="o">:</span>

<span class="w">                </span><span class="n">return_metrics</span><span class="err">[</span><span class="n">metric</span><span class="p">.</span><span class="k">name</span><span class="err">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">result</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">return_metrics</span>
</code></pre></div>

</details>
<h4 id="get_output_at_1">get_output_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_output_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the output tensor(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node<br>from which to retrieve the attribute.<br>E.g. <code>node_index=0</code> will correspond to the<br>first output node of the layer.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A tensor (or list of tensors if the layer has multiple outputs).</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If called in Eager mode.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">get_output_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Retrieves the output tensor(s) of a layer at a given node.</span>

<span class="ss">        Args:</span>

<span class="ss">            node_index: Integer, index of the node</span>

<span class="ss">                from which to retrieve the attribute.</span>

<span class="ss">                E.g. `node_index=0` will correspond to the</span>

<span class="ss">                first output node of the layer.</span>

<span class="ss">        Returns:</span>

<span class="ss">            A tensor (or list of tensors if the layer has multiple outputs).</span>

<span class="ss">        Raises:</span>

<span class="ss">          RuntimeError: If called in Eager mode.</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span>

<span class="w">            </span><span class="n">node_index</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;output_tensors&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;output&quot;</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="get_output_mask_at_1">get_output_mask_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_output_mask_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the output mask tensor(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node<br>from which to retrieve the attribute.<br>E.g. <code>node_index=0</code> will correspond to the<br>first time the layer was called.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A mask tensor<br>(or list of tensors if the layer has multiple outputs).</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">get_output_mask_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Retrieves the output mask tensor(s) of a layer at a given node.</span>

<span class="ss">        Args:</span>

<span class="ss">            node_index: Integer, index of the node</span>

<span class="ss">                from which to retrieve the attribute.</span>

<span class="ss">                E.g. `node_index=0` will correspond to the</span>

<span class="ss">                first time the layer was called.</span>

<span class="ss">        Returns:</span>

<span class="ss">            A mask tensor</span>

<span class="ss">            (or list of tensors if the layer has multiple outputs).</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">get_output_at</span><span class="p">(</span><span class="n">node_index</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="k">output</span><span class="p">,</span><span class="w"> </span><span class="n">list</span><span class="p">)</span><span class="err">:</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="o">[</span><span class="n">getattr(x, &quot;_keras_mask&quot;, None) for x in output</span><span class="o">]</span>

<span class="w">        </span><span class="k">else</span><span class="err">:</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="k">output</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;_keras_mask&quot;</span><span class="p">,</span><span class="w"> </span><span class="k">None</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="get_output_shape_at_1">get_output_shape_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_output_shape_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the output shape(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node<br>from which to retrieve the attribute.<br>E.g. <code>node_index=0</code> will correspond to the<br>first time the layer was called.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A shape tuple<br>(or list of shape tuples if the layer has multiple outputs).</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If called in Eager mode.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">get_output_shape_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Retrieves the output shape(s) of a layer at a given node.</span>

<span class="ss">        Args:</span>

<span class="ss">            node_index: Integer, index of the node</span>

<span class="ss">                from which to retrieve the attribute.</span>

<span class="ss">                E.g. `node_index=0` will correspond to the</span>

<span class="ss">                first time the layer was called.</span>

<span class="ss">        Returns:</span>

<span class="ss">            A shape tuple</span>

<span class="ss">            (or list of shape tuples if the layer has multiple outputs).</span>

<span class="ss">        Raises:</span>

<span class="ss">          RuntimeError: If called in Eager mode.</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span>

<span class="w">            </span><span class="n">node_index</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;output_shapes&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;output shape&quot;</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="get_weight_paths_1">get_weight_paths</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_weight_paths</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieve all the variables and their paths for the model.</p>
<p>The variable path (string) is a stable key to indentify a <code>tf.Variable</code>
instance owned by the model. It can be used to specify variable-specific
configurations (e.g. DTensor, quantization) from a global view.</p>
<p>This method returns a dict with weight object paths as keys
and the corresponding <code>tf.Variable</code> instances as values.</p>
<p>Note that if the model is a subclassed model and the weights haven't
been initialized, an empty dict will be returned.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A dict where keys are variable paths and values are <code>tf.Variable</code><br>instances.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">get_weight_paths</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Retrieve all the variables and their paths for the model.</span>

<span class="ss">        The variable path (string) is a stable key to indentify a `tf.Variable`</span>

<span class="ss">        instance owned by the model. It can be used to specify variable-specific</span>

<span class="ss">        configurations (e.g. DTensor, quantization) from a global view.</span>

<span class="ss">        This method returns a dict with weight object paths as keys</span>

<span class="ss">        and the corresponding `tf.Variable` instances as values.</span>

<span class="ss">        Note that if the model is a subclassed model and the weights haven&#39;t</span>

<span class="ss">        been initialized, an empty dict will be returned.</span>

<span class="ss">        Returns:</span>

<span class="ss">            A dict where keys are variable paths and values are `tf.Variable`</span>

<span class="ss">             instances.</span>

<span class="ss">        Example:</span>

<span class="ss">        ```python</span>

<span class="ss">        class SubclassModel(tf.keras.Model):</span>

<span class="ss">          def __init__(self, name=None):</span>

<span class="ss">            super().__init__(name=name)</span>

<span class="ss">            self.d1 = tf.keras.layers.Dense(10)</span>

<span class="ss">            self.d2 = tf.keras.layers.Dense(20)</span>

<span class="ss">          def call(self, inputs):</span>

<span class="ss">            x = self.d1(inputs)</span>

<span class="ss">            return self.d2(x)</span>

<span class="ss">        model = SubclassModel()</span>

<span class="ss">        model(tf.zeros((10, 10)))</span>

<span class="ss">        weight_paths = model.get_weight_paths()</span>

<span class="ss">        # weight_paths:</span>

<span class="ss">        # {</span>

<span class="ss">        #    &#39;d1.kernel&#39;: model.d1.kernel,</span>

<span class="ss">        #    &#39;d1.bias&#39;: model.d1.bias,</span>

<span class="ss">        #    &#39;d2.kernel&#39;: model.d2.kernel,</span>

<span class="ss">        #    &#39;d2.bias&#39;: model.d2.bias,</span>

<span class="ss">        # }</span>

<span class="ss">        # Functional model</span>

<span class="ss">        inputs = tf.keras.Input((10,), batch_size=10)</span>

<span class="ss">        x = tf.keras.layers.Dense(20, name=&#39;d1&#39;)(inputs)</span>

<span class="ss">        output = tf.keras.layers.Dense(30, name=&#39;d2&#39;)(x)</span>

<span class="ss">        model = tf.keras.Model(inputs, output)</span>

<span class="ss">        d1 = model.layers[1]</span>

<span class="ss">        d2 = model.layers[2]</span>

<span class="ss">        weight_paths = model.get_weight_paths()</span>

<span class="ss">        # weight_paths:</span>

<span class="ss">        # {</span>

<span class="ss">        #    &#39;d1.kernel&#39;: d1.kernel,</span>

<span class="ss">        #    &#39;d1.bias&#39;: d1.bias,</span>

<span class="ss">        #    &#39;d2.kernel&#39;: d2.kernel,</span>

<span class="ss">        #    &#39;d2.bias&#39;: d2.bias,</span>

<span class="ss">        # }</span>

<span class="ss">        ```</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">{}</span>

<span class="w">        </span><span class="p">(</span>

<span class="w">            </span><span class="n">descendants</span><span class="p">,</span>

<span class="w">            </span><span class="n">object_paths_dict</span><span class="p">,</span>

<span class="w">        </span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">__internal__</span><span class="p">.</span><span class="n">tracking</span><span class="p">.</span><span class="n">ObjectGraphView</span><span class="p">(</span>

<span class="w">            </span><span class="n">self</span>

<span class="w">        </span><span class="p">).</span><span class="n">breadth_first_traversal</span><span class="p">()</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">descendant</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="nl">descendants</span><span class="p">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">descendant</span><span class="p">,</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">Variable</span><span class="p">)</span><span class="err">:</span>

<span class="w">                </span><span class="n">trackable_references</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">object_paths_dict</span><span class="o">[</span><span class="n">descendant</span><span class="o">]</span>

<span class="w">                </span><span class="n">object_path</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">&quot;.&quot;</span><span class="p">.</span><span class="k">join</span><span class="p">(</span><span class="o">[</span><span class="n">t.name for t in trackable_references</span><span class="o">]</span><span class="p">)</span>

<span class="w">                </span><span class="k">result</span><span class="o">[</span><span class="n">object_path</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">descendant</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="k">result</span>
</code></pre></div>

</details>
<h4 id="get_weights_1">get_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_weights</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the weights of the model.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A flat list of Numpy arrays.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">def</span><span class="w"> </span><span class="nv">get_weights</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span>:

<span class="w">        </span><span class="s2">&quot;&quot;</span><span class="err">&quot;Retrieves the weights of the model.</span>

<span class="err">        Returns:</span>

<span class="err">            A flat list of Numpy arrays.</span>

<span class="w">        </span><span class="s2">&quot;&quot;</span><span class="err">&quot;</span>

<span class="err">        with self.distribute_strategy.scope():</span>

<span class="err">            return super().get_weights()</span>
</code></pre></div>

</details>
<h4 id="load_weights_1">load_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">load_weights</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filepath</span><span class="p">,</span>
    <span class="n">by_name</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">skip_mismatch</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Loads all layer weights, either from a TensorFlow or an HDF5 weight file.</p>
<p>If <code>by_name</code> is False weights are loaded based on the network's
topology. This means the architecture should be the same as when the
weights were saved.  Note that layers that don't have weights are not
taken into account in the topological ordering, so adding or removing
layers is fine as long as they don't have weights.</p>
<p>If <code>by_name</code> is True, weights are loaded into layers only if they share
the same name. This is useful for fine-tuning or transfer-learning
models where some of the layers have changed.</p>
<p>Only topological loading (<code>by_name=False</code>) is supported when loading
weights from the TensorFlow format. Note that topological loading
differs slightly between TensorFlow and HDF5 formats for user-defined
classes inheriting from <code>tf.keras.Model</code>: HDF5 loads based on a
flattened list of weights, while the TensorFlow format loads based on
the object-local names of attributes to which layers are assigned in the
<code>Model</code>'s constructor.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>filepath</td>
<td>None</td>
<td>String, path to the weights file to load. For weight files<br>in TensorFlow format, this is the file prefix (the same as was<br>passed to <code>save_weights</code>). This can also be a path to a<br>SavedModel saved from <code>model.save</code>.</td>
<td>None</td>
</tr>
<tr>
<td>by_name</td>
<td>None</td>
<td>Boolean, whether to load weights by name or by topological<br>order. Only topological loading is supported for weight files in<br>TensorFlow format.</td>
<td>None</td>
</tr>
<tr>
<td>skip_mismatch</td>
<td>None</td>
<td>Boolean, whether to skip loading of layers where<br>there is a mismatch in the number of weights, or a mismatch in<br>the shape of the weight (only valid when <code>by_name=True</code>).</td>
<td>None</td>
</tr>
<tr>
<td>options</td>
<td>None</td>
<td>Optional <code>tf.train.CheckpointOptions</code> object that specifies<br>options for loading weights.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>When loading a weight file in TensorFlow format, returns the same<br>status object as <code>tf.train.Checkpoint.restore</code>. When graph building,<br>restore ops are run automatically as soon as the network is built<br>(on first call for user-defined classes inheriting from <code>Model</code>,<br>immediately if it is already built).<br><br>When loading weights in HDF5 format, returns <code>None</code>.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ImportError</td>
<td>If <code>h5py</code> is not available and the weight file is in<br>HDF5 format.</td>
</tr>
<tr>
<td>ValueError</td>
<td>If <code>skip_mismatch</code> is set to <code>True</code> when <code>by_name</code> is<br><code>False</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="err">@</span><span class="n">traceback_utils</span><span class="o">.</span><span class="n">filter_traceback</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">load_weights</span><span class="p">(</span>

<span class="w">        </span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="n">by_name</span><span class="o">=</span><span class="n">False</span><span class="p">,</span><span class="w"> </span><span class="n">skip_mismatch</span><span class="o">=</span><span class="n">False</span><span class="p">,</span><span class="w"> </span><span class="n">options</span><span class="o">=</span><span class="n">None</span>

<span class="w">    </span><span class="p">):</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;Loads all layer weights, either from a TensorFlow or an HDF5 weight file.</span>

<span class="sd">        If `by_name` is False weights are loaded based on the network&#39;s</span>

<span class="sd">        topology. This means the architecture should be the same as when the</span>

<span class="sd">        weights were saved.  Note that layers that don&#39;t have weights are not</span>

<span class="sd">        taken into account in the topological ordering, so adding or removing</span>

<span class="sd">        layers is fine as long as they don&#39;t have weights.</span>

<span class="sd">        If `by_name` is True, weights are loaded into layers only if they share</span>

<span class="sd">        the same name. This is useful for fine-tuning or transfer-learning</span>

<span class="sd">        models where some of the layers have changed.</span>

<span class="sd">        Only topological loading (`by_name=False`) is supported when loading</span>

<span class="sd">        weights from the TensorFlow format. Note that topological loading</span>

<span class="sd">        differs slightly between TensorFlow and HDF5 formats for user-defined</span>

<span class="sd">        classes inheriting from `tf.keras.Model`: HDF5 loads based on a</span>

<span class="sd">        flattened list of weights, while the TensorFlow format loads based on</span>

<span class="sd">        the object-local names of attributes to which layers are assigned in the</span>

<span class="sd">        `Model`&#39;s constructor.</span>

<span class="sd">        Args:</span>

<span class="sd">            filepath: String, path to the weights file to load. For weight files</span>

<span class="sd">                in TensorFlow format, this is the file prefix (the same as was</span>

<span class="sd">                passed to `save_weights`). This can also be a path to a</span>

<span class="sd">                SavedModel saved from `model.save`.</span>

<span class="sd">            by_name: Boolean, whether to load weights by name or by topological</span>

<span class="sd">                order. Only topological loading is supported for weight files in</span>

<span class="sd">                TensorFlow format.</span>

<span class="sd">            skip_mismatch: Boolean, whether to skip loading of layers where</span>

<span class="sd">                there is a mismatch in the number of weights, or a mismatch in</span>

<span class="sd">                the shape of the weight (only valid when `by_name=True`).</span>

<span class="sd">            options: Optional `tf.train.CheckpointOptions` object that specifies</span>

<span class="sd">                options for loading weights.</span>

<span class="sd">        Returns:</span>

<span class="sd">            When loading a weight file in TensorFlow format, returns the same</span>

<span class="sd">            status object as `tf.train.Checkpoint.restore`. When graph building,</span>

<span class="sd">            restore ops are run automatically as soon as the network is built</span>

<span class="sd">            (on first call for user-defined classes inheriting from `Model`,</span>

<span class="sd">            immediately if it is already built).</span>

<span class="sd">            When loading weights in HDF5 format, returns `None`.</span>

<span class="sd">        Raises:</span>

<span class="sd">            ImportError: If `h5py` is not available and the weight file is in</span>

<span class="sd">              HDF5 format.</span>

<span class="sd">            ValueError: If `skip_mismatch` is set to `True` when `by_name` is</span>

<span class="sd">              `False`.</span>

<span class="sd">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">backend</span><span class="o">.</span><span class="n">is_tpu_strategy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="p">):</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="o">.</span><span class="n">extended</span><span class="o">.</span><span class="n">steps_per_run</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="p">(</span>

<span class="w">                </span><span class="ow">not</span><span class="w"> </span><span class="n">saving_utils</span><span class="o">.</span><span class="n">is_hdf5_filepath</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>

<span class="w">            </span><span class="p">):</span>

<span class="w">                </span><span class="n">spr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="o">.</span><span class="n">extended</span><span class="o">.</span><span class="n">steps_per_run</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                    </span><span class="s2">&quot;Load weights is not implemented with TPUStrategy &quot;</span>

<span class="w">                    </span><span class="s2">&quot;with `steps_per_run` greater than 1. The &quot;</span>

<span class="w">                    </span><span class="n">f</span><span class="s2">&quot;`steps_per_run` is {spr}&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">skip_mismatch</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">by_name</span><span class="p">:</span>

<span class="w">            </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                </span><span class="s2">&quot;When calling model.load_weights, skip_mismatch can only be &quot;</span>

<span class="w">                </span><span class="s2">&quot;set to True when by_name is True.&quot;</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">_detect_save_format</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">&quot;tf&quot;</span><span class="p">:</span>

<span class="w">            </span><span class="n">status</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_checkpoint</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="n">options</span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">by_name</span><span class="p">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">NotImplementedError</span><span class="p">(</span>

<span class="w">                    </span><span class="s2">&quot;Weights may only be loaded based on topology into Models &quot;</span>

<span class="w">                    </span><span class="s2">&quot;when loading TensorFlow-formatted weights &quot;</span>

<span class="w">                    </span><span class="s2">&quot;(got by_name=True to load_weights).&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>

<span class="w">                </span><span class="n">session</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">backend</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span>

<span class="w">                </span><span class="c1"># Restore existing variables (if any) immediately, and set up a</span>

<span class="w">                </span><span class="c1"># streaming restore for any variables created in the future.</span>

<span class="w">                </span><span class="n">tf</span><span class="o">.</span><span class="n">__internal__</span><span class="o">.</span><span class="n">tracking</span><span class="o">.</span><span class="n">streaming_restore</span><span class="p">(</span>

<span class="w">                    </span><span class="n">status</span><span class="o">=</span><span class="n">status</span><span class="p">,</span><span class="w"> </span><span class="n">session</span><span class="o">=</span><span class="n">session</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="n">status</span><span class="o">.</span><span class="n">assert_nontrivial_match</span><span class="p">()</span>

<span class="w">        </span><span class="k">else</span><span class="p">:</span>

<span class="w">            </span><span class="n">status</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">h5py</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">ImportError</span><span class="p">(</span>

<span class="w">                    </span><span class="s2">&quot;`load_weights` requires h5py package when loading weights &quot;</span>

<span class="w">                    </span><span class="s2">&quot;from HDF5. Try installing h5py.&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_is_graph_network</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">built</span><span class="p">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                    </span><span class="s2">&quot;Unable to load weights saved in HDF5 format into a &quot;</span>

<span class="w">                    </span><span class="s2">&quot;subclassed Model which has not created its variables yet. &quot;</span>

<span class="w">                    </span><span class="s2">&quot;Call the Model first, then load the weights.&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">_assert_weights_created</span><span class="p">()</span>

<span class="w">            </span><span class="n">with</span><span class="w"> </span><span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;r&quot;</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">f</span><span class="p">:</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="s2">&quot;layer_names&quot;</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">f</span><span class="o">.</span><span class="n">attrs</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="s2">&quot;model_weights&quot;</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">f</span><span class="p">:</span>

<span class="w">                    </span><span class="n">f</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f</span><span class="p">[</span><span class="s2">&quot;model_weights&quot;</span><span class="p">]</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">by_name</span><span class="p">:</span>

<span class="w">                    </span><span class="n">hdf5_format</span><span class="o">.</span><span class="n">load_weights_from_hdf5_group_by_name</span><span class="p">(</span>

<span class="w">                        </span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">skip_mismatch</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">                </span><span class="k">else</span><span class="p">:</span>

<span class="w">                    </span><span class="n">hdf5_format</span><span class="o">.</span><span class="n">load_weights_from_hdf5_group</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="p">)</span>

<span class="w">        </span><span class="c1"># Perform any layer defined finalization of the layer state.</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>

<span class="w">            </span><span class="n">layer</span><span class="o">.</span><span class="n">finalize_state</span><span class="p">()</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">status</span>
</code></pre></div>

</details>
<h4 id="make_predict_function_1">make_predict_function</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">make_predict_function</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">force</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a function that executes one step of inference.</p>
<p>This method can be overridden to support custom inference logic.
This method is called by <code>Model.predict</code> and <code>Model.predict_on_batch</code>.</p>
<p>Typically, this method directly controls <code>tf.function</code> and
<code>tf.distribute.Strategy</code> settings, and delegates the actual evaluation
logic to <code>Model.predict_step</code>.</p>
<p>This function is cached the first time <code>Model.predict</code> or
<code>Model.predict_on_batch</code> is called. The cache is cleared whenever
<code>Model.compile</code> is called. You can skip the cache and generate again the
function with <code>force=True</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>force</td>
<td>None</td>
<td>Whether to regenerate the predict function and skip the cached<br>function if available.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Function. The function created by this method should accept a<br><code>tf.data.Iterator</code>, and return the outputs of the <code>Model</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">make_predict_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">force</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Creates a function that executes one step of inference.</span>

<span class="s2">        This method can be overridden to support custom inference logic.</span>

<span class="s2">        This method is called by `Model.predict` and `Model.predict_on_batch`.</span>

<span class="s2">        Typically, this method directly controls `tf.function` and</span>

<span class="s2">        `tf.distribute.Strategy` settings, and delegates the actual evaluation</span>

<span class="s2">        logic to `Model.predict_step`.</span>

<span class="s2">        This function is cached the first time `Model.predict` or</span>

<span class="s2">        `Model.predict_on_batch` is called. The cache is cleared whenever</span>

<span class="s2">        `Model.compile` is called. You can skip the cache and generate again the</span>

<span class="s2">        function with `force=True`.</span>

<span class="s2">        Args:</span>

<span class="s2">          force: Whether to regenerate the predict function and skip the cached</span>

<span class="s2">            function if available.</span>

<span class="s2">        Returns:</span>

<span class="s2">          Function. The function created by this method should accept a</span>

<span class="s2">          `tf.data.Iterator`, and return the outputs of the `Model`.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">force</span><span class="o">:</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span>

<span class="w">        </span><span class="n">def</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single evaluation step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">            </span><span class="n">def</span><span class="w"> </span><span class="n">run_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">predict_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

<span class="w">                </span><span class="c1"># Ensure counter is updated only if `test_step` succeeds.</span>

<span class="w">                </span><span class="k">with</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_minimum_control_deps</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span><span class="o">:</span>

<span class="w">                    </span><span class="n">model</span><span class="p">.</span><span class="n">_predict_counter</span><span class="p">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_jit_compile</span><span class="o">:</span>

<span class="w">                </span><span class="n">run_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

<span class="w">                    </span><span class="n">run_step</span><span class="p">,</span><span class="w"> </span><span class="n">jit_compile</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"> </span><span class="n">reduce_retracing</span><span class="o">=</span><span class="no">True</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="k">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

<span class="w">            </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="k">data</span><span class="p">,))</span>

<span class="w">            </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">reduce_per_replica</span><span class="p">(</span>

<span class="w">                </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span><span class="w"> </span><span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;concat&quot;</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">        </span><span class="c1"># Special case if steps_per_execution is one.</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span>

<span class="w">            </span><span class="k">or</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span>

<span class="w">        </span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="n">def</span><span class="w"> </span><span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs an evaluation execution with a single step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span>

<span class="w">        </span><span class="k">else</span><span class="o">:</span>

<span class="w">            </span><span class="n">def</span><span class="w"> </span><span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs an evaluation execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">                </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span>

<span class="w">                </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">:</span>

<span class="w">                    </span><span class="n">tf</span><span class="p">.</span><span class="n">autograph</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="k">set</span><span class="n">_loop_options</span><span class="p">(</span>

<span class="w">                        </span><span class="n">shape_invariants</span><span class="o">=</span><span class="err">[</span>

<span class="w">                            </span><span class="p">(</span>

<span class="w">                                </span><span class="n">outputs</span><span class="p">,</span>

<span class="w">                                </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span>

<span class="w">                                    </span><span class="n">lambda</span><span class="w"> </span><span class="n">t</span><span class="o">:</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">get_tensor_spec</span><span class="p">(</span>

<span class="w">                                        </span><span class="n">t</span><span class="p">,</span><span class="w"> </span><span class="n">dynamic_batch</span><span class="o">=</span><span class="no">True</span>

<span class="w">                                    </span><span class="p">).</span><span class="n">shape</span><span class="p">,</span>

<span class="w">                                    </span><span class="n">outputs</span><span class="p">,</span>

<span class="w">                                </span><span class="p">),</span>

<span class="w">                            </span><span class="p">)</span>

<span class="w">                        </span><span class="err">]</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">                    </span><span class="n">step_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span>

<span class="w">                    </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span>

<span class="w">                        </span><span class="n">lambda</span><span class="w"> </span><span class="n">t1</span><span class="p">,</span><span class="w"> </span><span class="n">t2</span><span class="o">:</span><span class="w"> </span><span class="nf">concat</span><span class="p">(</span><span class="err">[</span><span class="n">t1</span><span class="p">,</span><span class="w"> </span><span class="n">t2</span><span class="err">]</span><span class="p">),</span><span class="w"> </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">step_outputs</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span>

<span class="w">            </span><span class="n">predict_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

<span class="w">                </span><span class="n">predict_function</span><span class="p">,</span><span class="w"> </span><span class="n">reduce_retracing</span><span class="o">=</span><span class="no">True</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">predict_function</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span>
</code></pre></div>

</details>
<h4 id="make_test_function_1">make_test_function</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">make_test_function</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">force</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a function that executes one step of evaluation.</p>
<p>This method can be overridden to support custom evaluation logic.
This method is called by <code>Model.evaluate</code> and <code>Model.test_on_batch</code>.</p>
<p>Typically, this method directly controls <code>tf.function</code> and
<code>tf.distribute.Strategy</code> settings, and delegates the actual evaluation
logic to <code>Model.test_step</code>.</p>
<p>This function is cached the first time <code>Model.evaluate</code> or
<code>Model.test_on_batch</code> is called. The cache is cleared whenever
<code>Model.compile</code> is called. You can skip the cache and generate again the
function with <code>force=True</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>force</td>
<td>None</td>
<td>Whether to regenerate the test function and skip the cached<br>function if available.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Function. The function created by this method should accept a<br><code>tf.data.Iterator</code>, and return a <code>dict</code> containing values that will<br>be passed to <code>tf.keras.Callbacks.on_test_batch_end</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">make_test_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">force</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Creates a function that executes one step of evaluation.</span>

<span class="s2">        This method can be overridden to support custom evaluation logic.</span>

<span class="s2">        This method is called by `Model.evaluate` and `Model.test_on_batch`.</span>

<span class="s2">        Typically, this method directly controls `tf.function` and</span>

<span class="s2">        `tf.distribute.Strategy` settings, and delegates the actual evaluation</span>

<span class="s2">        logic to `Model.test_step`.</span>

<span class="s2">        This function is cached the first time `Model.evaluate` or</span>

<span class="s2">        `Model.test_on_batch` is called. The cache is cleared whenever</span>

<span class="s2">        `Model.compile` is called. You can skip the cache and generate again the</span>

<span class="s2">        function with `force=True`.</span>

<span class="s2">        Args:</span>

<span class="s2">          force: Whether to regenerate the test function and skip the cached</span>

<span class="s2">            function if available.</span>

<span class="s2">        Returns:</span>

<span class="s2">          Function. The function created by this method should accept a</span>

<span class="s2">          `tf.data.Iterator`, and return a `dict` containing values that will</span>

<span class="s2">          be passed to `tf.keras.Callbacks.on_test_batch_end`.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">force</span><span class="o">:</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span>

<span class="w">        </span><span class="n">def</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single evaluation step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">            </span><span class="n">def</span><span class="w"> </span><span class="n">run_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">test_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

<span class="w">                </span><span class="c1"># Ensure counter is updated only if `test_step` succeeds.</span>

<span class="w">                </span><span class="k">with</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_minimum_control_deps</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span><span class="o">:</span>

<span class="w">                    </span><span class="n">model</span><span class="p">.</span><span class="n">_test_counter</span><span class="p">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_jit_compile</span><span class="o">:</span>

<span class="w">                </span><span class="n">run_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

<span class="w">                    </span><span class="n">run_step</span><span class="p">,</span><span class="w"> </span><span class="n">jit_compile</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"> </span><span class="n">reduce_retracing</span><span class="o">=</span><span class="no">True</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="k">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

<span class="w">            </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="k">data</span><span class="p">,))</span>

<span class="w">            </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">reduce_per_replica</span><span class="p">(</span>

<span class="w">                </span><span class="n">outputs</span><span class="p">,</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span>

<span class="w">                </span><span class="n">reduction</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">distribute_reduction_method</span><span class="p">,</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">        </span><span class="c1"># Special case if steps_per_execution is one.</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span>

<span class="w">            </span><span class="k">or</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span>

<span class="w">        </span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="n">def</span><span class="w"> </span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a test execution with a single step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span>

<span class="w">                </span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

<span class="w">                    </span><span class="n">test_function</span><span class="p">,</span><span class="w"> </span><span class="n">reduce_retracing</span><span class="o">=</span><span class="no">True</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span>

<span class="w">                    </span><span class="n">lambda</span><span class="w"> </span><span class="n">it</span><span class="o">:</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="p">.</span><span class="k">schedule</span><span class="p">(</span>

<span class="w">                        </span><span class="n">test_function</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">it</span><span class="p">,)</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="k">else</span><span class="o">:</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">test_function</span>

<span class="w">        </span><span class="c1"># If we&#39;re using a coordinator, use the value of</span>

<span class="w">        </span><span class="c1"># self._steps_per_execution at the time the function is</span>

<span class="w">        </span><span class="c1"># called/scheduled, and not when it is actually executed.</span>

<span class="w">        </span><span class="n">elif</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span>

<span class="w">            </span><span class="n">def</span><span class="w"> </span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">,</span><span class="w"> </span><span class="n">steps_per_execution</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a test execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">                </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">steps_per_execution</span><span class="p">)</span><span class="o">:</span>

<span class="w">                    </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span>

<span class="w">                </span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

<span class="w">                    </span><span class="n">test_function</span><span class="p">,</span><span class="w"> </span><span class="n">reduce_retracing</span><span class="o">=</span><span class="no">True</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="n">it</span><span class="o">:</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="p">.</span><span class="k">schedule</span><span class="p">(</span>

<span class="w">                </span><span class="n">test_function</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">it</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="k">value</span><span class="p">())</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="k">else</span><span class="o">:</span>

<span class="w">            </span><span class="n">def</span><span class="w"> </span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a test execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">                </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="o">:</span>

<span class="w">                    </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span>

<span class="w">                </span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

<span class="w">                    </span><span class="n">test_function</span><span class="p">,</span><span class="w"> </span><span class="n">reduce_retracing</span><span class="o">=</span><span class="no">True</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">test_function</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span>
</code></pre></div>

</details>
<h4 id="make_train_function_1">make_train_function</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">make_train_function</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">force</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a function that executes one step of training.</p>
<p>This method can be overridden to support custom training logic.
This method is called by <code>Model.fit</code> and <code>Model.train_on_batch</code>.</p>
<p>Typically, this method directly controls <code>tf.function</code> and
<code>tf.distribute.Strategy</code> settings, and delegates the actual training
logic to <code>Model.train_step</code>.</p>
<p>This function is cached the first time <code>Model.fit</code> or
<code>Model.train_on_batch</code> is called. The cache is cleared whenever
<code>Model.compile</code> is called. You can skip the cache and generate again the
function with <code>force=True</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>force</td>
<td>None</td>
<td>Whether to regenerate the train function and skip the cached<br>function if available.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Function. The function created by this method should accept a<br><code>tf.data.Iterator</code>, and return a <code>dict</code> containing values that will<br>be passed to <code>tf.keras.Callbacks.on_train_batch_end</code>, such as<br><code>{'loss': 0.2, 'accuracy': 0.7}</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">make_train_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">force</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Creates a function that executes one step of training.</span>

<span class="s2">        This method can be overridden to support custom training logic.</span>

<span class="s2">        This method is called by `Model.fit` and `Model.train_on_batch`.</span>

<span class="s2">        Typically, this method directly controls `tf.function` and</span>

<span class="s2">        `tf.distribute.Strategy` settings, and delegates the actual training</span>

<span class="s2">        logic to `Model.train_step`.</span>

<span class="s2">        This function is cached the first time `Model.fit` or</span>

<span class="s2">        `Model.train_on_batch` is called. The cache is cleared whenever</span>

<span class="s2">        `Model.compile` is called. You can skip the cache and generate again the</span>

<span class="s2">        function with `force=True`.</span>

<span class="s2">        Args:</span>

<span class="s2">          force: Whether to regenerate the train function and skip the cached</span>

<span class="s2">            function if available.</span>

<span class="s2">        Returns:</span>

<span class="s2">          Function. The function created by this method should accept a</span>

<span class="s2">          `tf.data.Iterator`, and return a `dict` containing values that will</span>

<span class="s2">          be passed to `tf.keras.Callbacks.on_train_batch_end`, such as</span>

<span class="s2">          `{&#39;loss&#39;: 0.2, &#39;accuracy&#39;: 0.7}`.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">force</span><span class="o">:</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span>

<span class="w">        </span><span class="n">def</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single training step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">            </span><span class="n">def</span><span class="w"> </span><span class="n">run_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">train_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

<span class="w">                </span><span class="c1"># Ensure counter is updated only if `train_step` succeeds.</span>

<span class="w">                </span><span class="k">with</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_minimum_control_deps</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span><span class="o">:</span>

<span class="w">                    </span><span class="n">model</span><span class="p">.</span><span class="n">_train_counter</span><span class="p">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_jit_compile</span><span class="o">:</span>

<span class="w">                </span><span class="n">run_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

<span class="w">                    </span><span class="n">run_step</span><span class="p">,</span><span class="w"> </span><span class="n">jit_compile</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"> </span><span class="n">reduce_retracing</span><span class="o">=</span><span class="no">True</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="k">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

<span class="w">            </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="k">data</span><span class="p">,))</span>

<span class="w">            </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">reduce_per_replica</span><span class="p">(</span>

<span class="w">                </span><span class="n">outputs</span><span class="p">,</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span>

<span class="w">                </span><span class="n">reduction</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">distribute_reduction_method</span><span class="p">,</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">        </span><span class="c1"># Special case if steps_per_execution is one.</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span>

<span class="w">            </span><span class="k">or</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span>

<span class="w">        </span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="n">def</span><span class="w"> </span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a training execution with a single step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span>

<span class="w">                </span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

<span class="w">                    </span><span class="n">train_function</span><span class="p">,</span><span class="w"> </span><span class="n">reduce_retracing</span><span class="o">=</span><span class="no">True</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">train_tf_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span>

<span class="w">                    </span><span class="n">lambda</span><span class="w"> </span><span class="n">it</span><span class="o">:</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="p">.</span><span class="k">schedule</span><span class="p">(</span>

<span class="w">                        </span><span class="n">train_function</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">it</span><span class="p">,)</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="k">else</span><span class="o">:</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span>

<span class="w">        </span><span class="c1"># If we&#39;re using a coordinator, use the value of</span>

<span class="w">        </span><span class="c1"># self._steps_per_execution at the time the function is</span>

<span class="w">        </span><span class="c1"># called/scheduled, and not when it is actually executed.</span>

<span class="w">        </span><span class="n">elif</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span>

<span class="w">            </span><span class="n">def</span><span class="w"> </span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">,</span><span class="w"> </span><span class="n">steps_per_execution</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a training execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">                </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">steps_per_execution</span><span class="p">)</span><span class="o">:</span>

<span class="w">                    </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span>

<span class="w">                </span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

<span class="w">                    </span><span class="n">train_function</span><span class="p">,</span><span class="w"> </span><span class="n">reduce_retracing</span><span class="o">=</span><span class="no">True</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">train_tf_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="n">it</span><span class="o">:</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="p">.</span><span class="k">schedule</span><span class="p">(</span>

<span class="w">                </span><span class="n">train_function</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">it</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="k">value</span><span class="p">())</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="k">else</span><span class="o">:</span>

<span class="w">            </span><span class="n">def</span><span class="w"> </span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a training execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">                </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="o">:</span>

<span class="w">                    </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span>

<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span>

<span class="w">                </span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

<span class="w">                    </span><span class="n">train_function</span><span class="p">,</span><span class="w"> </span><span class="n">reduce_retracing</span><span class="o">=</span><span class="no">True</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">train_tf_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span>
</code></pre></div>

</details>
<h4 id="predict_1">predict</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Generates output predictions for the input samples.</p>
<p>Computation is done in batches. This method is designed for batch
processing of large numbers of inputs. It is not intended for use inside
of loops that iterate over your data and process small numbers of inputs
at a time.</p>
<p>For small numbers of inputs that fit in one batch,
directly use <code>__call__()</code> for faster execution, e.g.,
<code>model(x)</code>, or <code>model(x, training=False)</code> if you have layers such as
<code>tf.keras.layers.BatchNormalization</code> that behave differently during
inference. You may pair the individual model call with a <code>tf.function</code>
for additional performance inside your inner loop.
If you need access to numpy array values instead of tensors after your
model call, you can use <code>tensor.numpy()</code> to get the numpy array value of
an eager tensor.</p>
<p>Also, note the fact that test loss is not affected by
regularization layers like noise and dropout.</p>
<p>Note: See <a href="https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call">this FAQ entry</a>
for more details about the difference between <code>Model</code> methods
<code>predict()</code> and <code>__call__()</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input samples. It could be:<br>- A Numpy array (or array-like), or a list of arrays<br>  (in case the model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors<br>  (in case the model has multiple inputs).<br>- A <code>tf.data</code> dataset.<br>- A generator or <code>keras.utils.Sequence</code> instance.<br>A more detailed description of unpacking behavior for iterator<br>types (Dataset, generator, Sequence) is given in the <code>Unpacking&lt;br&gt;behavior for iterator-like inputs</code> section of <code>Model.fit</code>.</td>
<td>None</td>
</tr>
<tr>
<td>batch_size</td>
<td>None</td>
<td>Integer or <code>None</code>.<br>Number of samples per batch.<br>If unspecified, <code>batch_size</code> will default to 32.<br>Do not specify the <code>batch_size</code> if your data is in the<br>form of dataset, generators, or <code>keras.utils.Sequence</code> instances<br>(since they generate batches).</td>
<td>None</td>
</tr>
<tr>
<td>verbose</td>
<td>None</td>
<td><code>"auto"</code>, 0, 1, or 2. Verbosity mode.<br>0 = silent, 1 = progress bar, 2 = single line.<br><code>"auto"</code> defaults to 1 for most cases, and to 2 when used with<br><code>ParameterServerStrategy</code>. Note that the progress bar is not<br>particularly useful when logged to a file, so <code>verbose=2</code> is<br>recommended when not running interactively (e.g. in a production<br>environment).</td>
<td>None</td>
</tr>
<tr>
<td>steps</td>
<td>None</td>
<td>Total number of steps (batches of samples)<br>before declaring the prediction round finished.<br>Ignored with the default value of <code>None</code>. If x is a <code>tf.data</code><br>dataset and <code>steps</code> is None, <code>predict()</code> will<br>run until the input dataset is exhausted.</td>
<td>None</td>
</tr>
<tr>
<td>callbacks</td>
<td>None</td>
<td>List of <code>keras.callbacks.Callback</code> instances.<br>List of callbacks to apply during prediction.<br>See <a href="&lt;br&gt;https://www.tensorflow.org/api_docs/python/tf/keras/callbacks">callbacks</a>.</td>
<td>None</td>
</tr>
<tr>
<td>max_queue_size</td>
<td>None</td>
<td>Integer. Used for generator or<br><code>keras.utils.Sequence</code> input only. Maximum size for the<br>generator queue. If unspecified, <code>max_queue_size</code> will default<br>to 10.</td>
<td>None</td>
</tr>
<tr>
<td>workers</td>
<td>None</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code> input<br>only. Maximum number of processes to spin up when using<br>process-based threading. If unspecified, <code>workers</code> will default<br>to 1.</td>
<td>None</td>
</tr>
<tr>
<td>use_multiprocessing</td>
<td>None</td>
<td>Boolean. Used for generator or<br><code>keras.utils.Sequence</code> input only. If <code>True</code>, use process-based<br>threading. If unspecified, <code>use_multiprocessing</code> will default to<br><code>False</code>. Note that because this implementation relies on<br>multiprocessing, you should not pass non-picklable arguments to<br>the generator as they can't be passed easily to children<br>processes.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Numpy array(s) of predictions.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.predict</code> is wrapped in a <code>tf.function</code>.</td>
</tr>
<tr>
<td>ValueError</td>
<td>In case of mismatch between the provided<br>input data and the model's expectations,<br>or in case a stateful model receives a number of samples<br>that is not a multiple of the batch size.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@traceback_utils.filter_traceback</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">x</span><span class="p">,</span>

<span class="w">        </span><span class="n">batch_size</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">verbose</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>

<span class="w">        </span><span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

<span class="w">        </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="no">False</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Generates output predictions for the input samples.</span>

<span class="s2">        Computation is done in batches. This method is designed for batch</span>

<span class="s2">        processing of large numbers of inputs. It is not intended for use inside</span>

<span class="s2">        of loops that iterate over your data and process small numbers of inputs</span>

<span class="s2">        at a time.</span>

<span class="s2">        For small numbers of inputs that fit in one batch,</span>

<span class="s2">        directly use `__call__()` for faster execution, e.g.,</span>

<span class="s2">        `model(x)`, or `model(x, training=False)` if you have layers such as</span>

<span class="s2">        `tf.keras.layers.BatchNormalization` that behave differently during</span>

<span class="s2">        inference. You may pair the individual model call with a `tf.function`</span>

<span class="s2">        for additional performance inside your inner loop.</span>

<span class="s2">        If you need access to numpy array values instead of tensors after your</span>

<span class="s2">        model call, you can use `tensor.numpy()` to get the numpy array value of</span>

<span class="s2">        an eager tensor.</span>

<span class="s2">        Also, note the fact that test loss is not affected by</span>

<span class="s2">        regularization layers like noise and dropout.</span>

<span class="s2">        Note: See [this FAQ entry](</span>

<span class="s2">        https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call)</span>

<span class="s2">        for more details about the difference between `Model` methods</span>

<span class="s2">        `predict()` and `__call__()`.</span>

<span class="s2">        Args:</span>

<span class="s2">            x: Input samples. It could be:</span>

<span class="s2">              - A Numpy array (or array-like), or a list of arrays</span>

<span class="s2">                (in case the model has multiple inputs).</span>

<span class="s2">              - A TensorFlow tensor, or a list of tensors</span>

<span class="s2">                (in case the model has multiple inputs).</span>

<span class="s2">              - A `tf.data` dataset.</span>

<span class="s2">              - A generator or `keras.utils.Sequence` instance.</span>

<span class="s2">              A more detailed description of unpacking behavior for iterator</span>

<span class="s2">              types (Dataset, generator, Sequence) is given in the `Unpacking</span>

<span class="s2">              behavior for iterator-like inputs` section of `Model.fit`.</span>

<span class="s2">            batch_size: Integer or `None`.</span>

<span class="s2">                Number of samples per batch.</span>

<span class="s2">                If unspecified, `batch_size` will default to 32.</span>

<span class="s2">                Do not specify the `batch_size` if your data is in the</span>

<span class="s2">                form of dataset, generators, or `keras.utils.Sequence` instances</span>

<span class="s2">                (since they generate batches).</span>

<span class="s2">            verbose: `&quot;</span><span class="n">auto</span><span class="s2">&quot;`, 0, 1, or 2. Verbosity mode.</span>

<span class="s2">                0 = silent, 1 = progress bar, 2 = single line.</span>

<span class="s2">                `&quot;</span><span class="n">auto</span><span class="s2">&quot;` defaults to 1 for most cases, and to 2 when used with</span>

<span class="s2">                `ParameterServerStrategy`. Note that the progress bar is not</span>

<span class="s2">                particularly useful when logged to a file, so `verbose=2` is</span>

<span class="s2">                recommended when not running interactively (e.g. in a production</span>

<span class="s2">                environment).</span>

<span class="s2">            steps: Total number of steps (batches of samples)</span>

<span class="s2">                before declaring the prediction round finished.</span>

<span class="s2">                Ignored with the default value of `None`. If x is a `tf.data`</span>

<span class="s2">                dataset and `steps` is None, `predict()` will</span>

<span class="s2">                run until the input dataset is exhausted.</span>

<span class="s2">            callbacks: List of `keras.callbacks.Callback` instances.</span>

<span class="s2">                List of callbacks to apply during prediction.</span>

<span class="s2">                See [callbacks](</span>

<span class="s2">                https://www.tensorflow.org/api_docs/python/tf/keras/callbacks).</span>

<span class="s2">            max_queue_size: Integer. Used for generator or</span>

<span class="s2">                `keras.utils.Sequence` input only. Maximum size for the</span>

<span class="s2">                generator queue. If unspecified, `max_queue_size` will default</span>

<span class="s2">                to 10.</span>

<span class="s2">            workers: Integer. Used for generator or `keras.utils.Sequence` input</span>

<span class="s2">                only. Maximum number of processes to spin up when using</span>

<span class="s2">                process-based threading. If unspecified, `workers` will default</span>

<span class="s2">                to 1.</span>

<span class="s2">            use_multiprocessing: Boolean. Used for generator or</span>

<span class="s2">                `keras.utils.Sequence` input only. If `True`, use process-based</span>

<span class="s2">                threading. If unspecified, `use_multiprocessing` will default to</span>

<span class="s2">                `False`. Note that because this implementation relies on</span>

<span class="s2">                multiprocessing, you should not pass non-picklable arguments to</span>

<span class="s2">                the generator as they can&#39;t be passed easily to children</span>

<span class="s2">                processes.</span>

<span class="s2">        See the discussion of `Unpacking behavior for iterator-like inputs` for</span>

<span class="s2">        `Model.fit`. Note that Model.predict uses the same interpretation rules</span>

<span class="s2">        as `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for</span>

<span class="s2">        all three methods.</span>

<span class="s2">        Returns:</span>

<span class="s2">            Numpy array(s) of predictions.</span>

<span class="s2">        Raises:</span>

<span class="s2">            RuntimeError: If `model.predict` is wrapped in a `tf.function`.</span>

<span class="s2">            ValueError: In case of mismatch between the provided</span>

<span class="s2">                input data and the model&#39;s expectations,</span>

<span class="s2">                or in case a stateful model receives a number of samples</span>

<span class="s2">                that is not a multiple of the batch size.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">base_layer</span><span class="p">.</span><span class="n">keras_api_gauge</span><span class="p">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s2">&quot;predict&quot;</span><span class="p">).</span><span class="kt">set</span><span class="p">(</span><span class="no">True</span><span class="p">)</span>

<span class="w">        </span><span class="n">version_utils</span><span class="p">.</span><span class="n">disallow_legacy_graph</span><span class="p">(</span><span class="s2">&quot;Model&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;predict&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s2">&quot;predict&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s2">&quot;predict&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="c1"># TODO(yashkatariya): Cache model on the coordinator for faster</span>

<span class="w">        </span><span class="c1"># prediction.  If running under PSS, then swap it with OneDeviceStrategy</span>

<span class="w">        </span><span class="c1"># so that execution will run on the coordinator.</span>

<span class="w">        </span><span class="n">original_pss_strategy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">_should_use_with_coordinator</span><span class="o">:</span>

<span class="w">            </span><span class="n">original_pss_strategy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">_distribution_strategy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span>

<span class="w">        </span><span class="c1"># Cluster coordinator is set by `.fit()` and `.evaluate()` which is not</span>

<span class="w">        </span><span class="c1"># needed in `.predict()` because all the predictions happen on the</span>

<span class="w">        </span><span class="c1"># coordinator/locally.</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span>

<span class="w">        </span><span class="n">verbose</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">_get_verbosity</span><span class="p">(</span><span class="n">verbose</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">)</span>

<span class="w">        </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span>

<span class="w">            </span><span class="c1"># Creates a `tf.data.Dataset` and handles batch and epoch iteration.</span>

<span class="w">            </span><span class="n">dataset_types</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="k">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">,</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">_in_multi_worker_mode</span><span class="p">()</span>

<span class="w">                </span><span class="k">or</span><span class="w"> </span><span class="n">_is_tpu_multi_host</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">)</span>

<span class="w">            </span><span class="p">)</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">dataset_types</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">try</span><span class="o">:</span>

<span class="w">                    </span><span class="k">options</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">data</span><span class="p">.</span><span class="k">Options</span><span class="p">()</span>

<span class="w">                    </span><span class="n">data_option</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">data</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">AutoShardPolicy</span><span class="p">.</span><span class="k">DATA</span>

<span class="w">                    </span><span class="k">options</span><span class="p">.</span><span class="n">experimental_distribute</span><span class="p">.</span><span class="n">auto_shard_policy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span>

<span class="w">                        </span><span class="n">data_option</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">                    </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">.</span><span class="n">with_options</span><span class="p">(</span><span class="k">options</span><span class="p">)</span>

<span class="w">                </span><span class="k">except</span><span class="w"> </span><span class="n">ValueError</span><span class="o">:</span>

<span class="w">                    </span><span class="k">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span>

<span class="w">                        </span><span class="s2">&quot;Using Model.predict with MultiWorkerMirroredStrategy &quot;</span>

<span class="w">                        </span><span class="s2">&quot;or TPUStrategy and AutoShardPolicy.FILE might lead to &quot;</span>

<span class="w">                        </span><span class="s2">&quot;out-of-order result. Consider setting it to &quot;</span>

<span class="w">                        </span><span class="s2">&quot;AutoShardPolicy.DATA.&quot;</span><span class="p">,</span>

<span class="w">                        </span><span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">            </span><span class="n">data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">get_data_handler</span><span class="p">(</span>

<span class="w">                </span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>

<span class="w">                </span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>

<span class="w">                </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>

<span class="w">                </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

<span class="w">                </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">                </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

<span class="w">                </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

<span class="w">                </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

<span class="w">                </span><span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span>

<span class="w">                </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">,</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">            </span><span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span><span class="w"> </span><span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">callbacks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">(</span>

<span class="w">                    </span><span class="n">callbacks</span><span class="p">,</span>

<span class="w">                    </span><span class="n">add_history</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

<span class="w">                    </span><span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>

<span class="w">                    </span><span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span>

<span class="w">                    </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>

<span class="w">                    </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">                    </span><span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="p">.</span><span class="n">inferred_steps</span><span class="p">,</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">make_predict_function</span><span class="p">()</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">_predict_counter</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="w">            </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_begin</span><span class="p">()</span>

<span class="w">            </span><span class="n">batch_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span>

<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">enumerate_epochs</span><span class="p">()</span><span class="o">:</span><span class="w">  </span><span class="c1"># Single epoch.</span>

<span class="w">                </span><span class="k">with</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">catch_stop_iteration</span><span class="p">()</span><span class="o">:</span>

<span class="w">                    </span><span class="k">for</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">steps</span><span class="p">()</span><span class="o">:</span>

<span class="w">                        </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>

<span class="w">                        </span><span class="n">tmp_batch_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

<span class="w">                        </span><span class="k">if</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">should_sync</span><span class="o">:</span>

<span class="w">                            </span><span class="k">context</span><span class="p">.</span><span class="n">async_wait</span><span class="p">()</span>

<span class="w">                        </span><span class="n">batch_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span>

<span class="w">                            </span><span class="n">tmp_batch_outputs</span><span class="w">  </span><span class="c1"># No error, now safe to assign.</span>

<span class="w">                        </span><span class="p">)</span>

<span class="w">                        </span><span class="k">if</span><span class="w"> </span><span class="n">outputs</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="o">:</span>

<span class="w">                            </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span>

<span class="w">                                </span><span class="n">lambda</span><span class="w"> </span><span class="n">batch_output</span><span class="o">:</span><span class="w"> </span><span class="err">[</span><span class="n">batch_output</span><span class="err">]</span><span class="p">,</span>

<span class="w">                                </span><span class="n">batch_outputs</span><span class="p">,</span>

<span class="w">                            </span><span class="p">)</span>

<span class="w">                        </span><span class="k">else</span><span class="o">:</span>

<span class="w">                            </span><span class="n">tf</span><span class="p">.</span><span class="n">__internal__</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure_up_to</span><span class="p">(</span>

<span class="w">                                </span><span class="n">batch_outputs</span><span class="p">,</span>

<span class="w">                                </span><span class="n">lambda</span><span class="w"> </span><span class="n">output</span><span class="p">,</span><span class="w"> </span><span class="n">batch_output</span><span class="o">:</span><span class="w"> </span><span class="n">output</span><span class="p">.</span><span class="n">append</span><span class="p">(</span>

<span class="w">                                    </span><span class="n">batch_output</span>

<span class="w">                                </span><span class="p">),</span>

<span class="w">                                </span><span class="n">outputs</span><span class="p">,</span>

<span class="w">                                </span><span class="n">batch_outputs</span><span class="p">,</span>

<span class="w">                            </span><span class="p">)</span>

<span class="w">                        </span><span class="n">end_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">step_increment</span>

<span class="w">                        </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_batch_end</span><span class="p">(</span>

<span class="w">                            </span><span class="n">end_step</span><span class="p">,</span><span class="w"> </span><span class="err">{</span><span class="s2">&quot;outputs&quot;</span><span class="o">:</span><span class="w"> </span><span class="n">batch_outputs</span><span class="err">}</span>

<span class="w">                        </span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">batch_outputs</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="o">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                    </span><span class="s2">&quot;Unexpected result of `predict_function` &quot;</span>

<span class="w">                    </span><span class="s2">&quot;(Empty batch_outputs). Please use &quot;</span>

<span class="w">                    </span><span class="s2">&quot;`Model.compile(..., run_eagerly=True)`, or &quot;</span>

<span class="w">                    </span><span class="s2">&quot;`tf.config.run_functions_eagerly(True)` for more &quot;</span>

<span class="w">                    </span><span class="s2">&quot;information of where went wrong, or file a &quot;</span>

<span class="w">                    </span><span class="s2">&quot;issue/bug to `tf.keras`.&quot;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_end</span><span class="p">()</span>

<span class="w">        </span><span class="n">all_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">__internal__</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure_up_to</span><span class="p">(</span>

<span class="w">            </span><span class="n">batch_outputs</span><span class="p">,</span><span class="w"> </span><span class="n">potentially_ragged_concat</span><span class="p">,</span><span class="w"> </span><span class="n">outputs</span>

<span class="w">        </span><span class="p">)</span>

<span class="w">        </span><span class="c1"># If originally PSS strategy was used, then replace it back since</span>

<span class="w">        </span><span class="c1"># predict is running under `OneDeviceStrategy` after the swap and once</span>

<span class="w">        </span><span class="c1"># its done we need to replace it back to PSS again.</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">original_pss_strategy</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="o">:</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">_distribution_strategy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">original_pss_strategy</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="n">all_outputs</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="predict_generator_1">predict_generator</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_generator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>

<p>Generates predictions for the input samples from a data generator.</p>
<p>DEPRECATED:
  <code>Model.predict</code> now supports generators, so there is no longer any
  need to use this endpoint.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_generate_docs</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">predict_generator</span><span class="p">(</span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">generator</span><span class="p">,</span>

<span class="w">        </span><span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

<span class="w">        </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="k">False</span><span class="p">,</span>

<span class="w">        </span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Generates predictions for the input samples from a data generator.</span>

<span class="ss">        DEPRECATED:</span>

<span class="ss">          `Model.predict` now supports generators, so there is no longer any</span>

<span class="ss">          need to use this endpoint.</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span>

<span class="w">            </span><span class="ss">&quot;`Model.predict_generator` is deprecated and &quot;</span>

<span class="w">            </span><span class="ss">&quot;will be removed in a future version. &quot;</span>

<span class="w">            </span><span class="ss">&quot;Please use `Model.predict`, which supports generators.&quot;</span><span class="p">,</span>

<span class="w">            </span><span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>

<span class="w">        </span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span>

<span class="w">            </span><span class="n">generator</span><span class="p">,</span>

<span class="w">            </span><span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>

<span class="w">            </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

<span class="w">            </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

<span class="w">            </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

<span class="w">            </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>

<span class="w">            </span><span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="predict_on_batch_1">predict_on_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns predictions for a single batch of samples.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input data. It could be:<br>- A Numpy array (or array-like), or a list of arrays (in case the<br>    model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors (in case the model has<br>    multiple inputs).</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Numpy array(s) of predictions.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.predict_on_batch</code> is wrapped in a<br><code>tf.function</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">def</span><span class="w"> </span><span class="nv">predict_on_batch</span><span class="ss">(</span><span class="nv">self</span>,<span class="w"> </span><span class="nv">x</span><span class="ss">)</span>:

<span class="w">        </span><span class="s2">&quot;&quot;</span><span class="err">&quot;Returns predictions for a single batch of samples.</span>

<span class="err">        Args:</span>

<span class="err">            x: Input data. It could be:</span>

<span class="err">              - A Numpy array (or array-like), or a list of arrays (in case the</span>

<span class="err">                  model has multiple inputs).</span>

<span class="err">              - A TensorFlow tensor, or a list of tensors (in case the model has</span>

<span class="err">                  multiple inputs).</span>

<span class="err">        Returns:</span>

<span class="err">            Numpy array(s) of predictions.</span>

<span class="err">        Raises:</span>

<span class="err">            RuntimeError: If `model.predict_on_batch` is wrapped in a</span>

<span class="err">              `tf.function`.</span>

<span class="w">        </span><span class="s2">&quot;&quot;</span><span class="err">&quot;</span>

<span class="w">        </span><span class="nv">self</span>.<span class="nv">_check_call_args</span><span class="ss">(</span><span class="s2">&quot;predict_on_batch&quot;</span><span class="ss">)</span>

<span class="w">        </span><span class="nv">_disallow_inside_tf_function</span><span class="ss">(</span><span class="s2">&quot;predict_on_batch&quot;</span><span class="ss">)</span>

<span class="w">        </span><span class="nv">with</span><span class="w"> </span><span class="nv">self</span>.<span class="nv">distribute_strategy</span>.<span class="nv">scope</span><span class="ss">()</span>:

<span class="w">            </span><span class="nv">iterator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">data_adapter</span>.<span class="nv">single_batch_iterator</span><span class="ss">(</span>

<span class="w">                </span><span class="nv">self</span>.<span class="nv">distribute_strategy</span>,<span class="w"> </span><span class="nv">x</span>

<span class="w">            </span><span class="ss">)</span>

<span class="w">            </span><span class="nv">self</span>.<span class="nv">predict_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">self</span>.<span class="nv">make_predict_function</span><span class="ss">()</span>

<span class="w">            </span><span class="nv">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">self</span>.<span class="nv">predict_function</span><span class="ss">(</span><span class="nv">iterator</span><span class="ss">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="nv">tf_utils</span>.<span class="nv">sync_to_numpy_or_python_type</span><span class="ss">(</span><span class="nv">outputs</span><span class="ss">)</span>
</code></pre></div>

</details>
<h4 id="predict_step_1">predict_step</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span>
<span class="p">)</span>
</code></pre></div>

<p>The logic for one inference step.</p>
<p>This method can be overridden to support custom inference logic.
This method is called by <code>Model.make_predict_function</code>.</p>
<p>This method should contain the mathematical logic for one step of
inference.  This typically includes the forward pass.</p>
<p>Configuration details for <em>how</em> this logic is run (e.g. <code>tf.function</code>
and <code>tf.distribute.Strategy</code> settings), should be left to
<code>Model.make_predict_function</code>, which can also be overridden.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>data</td>
<td>None</td>
<td>A nested structure of <code>Tensor</code>s.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>The result of one inference step, typically the output of calling the<br><code>Model</code> on data.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">predict_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">data</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">The logic for one inference step.</span>

<span class="s2">        This method can be overridden to support custom inference logic.</span>

<span class="s2">        This method is called by `Model.make_predict_function`.</span>

<span class="s2">        This method should contain the mathematical logic for one step of</span>

<span class="s2">        inference.  This typically includes the forward pass.</span>

<span class="s2">        Configuration details for *how* this logic is run (e.g. `tf.function`</span>

<span class="s2">        and `tf.distribute.Strategy` settings), should be left to</span>

<span class="s2">        `Model.make_predict_function`, which can also be overridden.</span>

<span class="s2">        Args:</span>

<span class="s2">          data: A nested structure of `Tensor`s.</span>

<span class="s2">        Returns:</span>

<span class="s2">          The result of one inference step, typically the output of calling the</span>

<span class="s2">          `Model` on data.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">_</span><span class="p">,</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">training</span><span class="o">=</span><span class="no">False</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="reset_metrics_1">reset_metrics</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">reset_metrics</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Resets the state of all the metrics in the model.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">def</span><span class="w"> </span><span class="nv">reset_metrics</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span>:

<span class="w">        </span><span class="s2">&quot;&quot;</span><span class="err">&quot;Resets the state of all the metrics in the model.</span>

<span class="err">        Examples:</span>

<span class="err">        &gt;&gt;&gt; inputs = tf.keras.layers.Input(shape=(3,))</span>

<span class="err">        &gt;&gt;&gt; outputs = tf.keras.layers.Dense(2)(inputs)</span>

<span class="err">        &gt;&gt;&gt; model = tf.keras.models.Model(inputs=inputs, outputs=outputs)</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="nv">model</span>.<span class="nv">compile</span><span class="ss">(</span><span class="nv">optimizer</span><span class="o">=</span><span class="s2">&quot;Adam&quot;</span>,<span class="w"> </span><span class="nv">loss</span><span class="o">=</span><span class="s2">&quot;mse&quot;</span>,<span class="w"> </span><span class="nv">metrics</span><span class="o">=</span>[<span class="s2">&quot;mae&quot;</span>]<span class="ss">)</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="nv">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">np</span>.<span class="k">random</span>.<span class="k">random</span><span class="ss">((</span><span class="mi">2</span>,<span class="w"> </span><span class="mi">3</span><span class="ss">))</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="nv">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">np</span>.<span class="k">random</span>.<span class="nv">randint</span><span class="ss">(</span><span class="mi">0</span>,<span class="w"> </span><span class="mi">2</span>,<span class="w"> </span><span class="ss">(</span><span class="mi">2</span>,<span class="w"> </span><span class="mi">2</span><span class="ss">))</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="nv">_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">model</span>.<span class="nv">fit</span><span class="ss">(</span><span class="nv">x</span>,<span class="w"> </span><span class="nv">y</span>,<span class="w"> </span><span class="nv">verbose</span><span class="o">=</span><span class="mi">0</span><span class="ss">)</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="nv">assert</span><span class="w"> </span><span class="nv">all</span><span class="ss">(</span><span class="nv">float</span><span class="ss">(</span><span class="nv">m</span>.<span class="nb">result</span><span class="ss">())</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nv">m</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">model</span>.<span class="nv">metrics</span><span class="ss">)</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="nv">model</span>.<span class="nv">reset_metrics</span><span class="ss">()</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="nv">assert</span><span class="w"> </span><span class="nv">all</span><span class="ss">(</span><span class="nv">float</span><span class="ss">(</span><span class="nv">m</span>.<span class="nb">result</span><span class="ss">())</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nv">m</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">model</span>.<span class="nv">metrics</span><span class="ss">)</span>

<span class="w">        </span><span class="s2">&quot;&quot;</span><span class="err">&quot;</span>

<span class="err">        for m in self.metrics:</span>

<span class="err">            m.reset_state()</span>
</code></pre></div>

</details>
<h4 id="reset_states_1">reset_states</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">reset_states</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">def</span><span class="w"> </span><span class="nv">reset_states</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span>:

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="nv">layer</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">self</span>.<span class="nv">layers</span>:

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="nv">hasattr</span><span class="ss">(</span><span class="nv">layer</span>,<span class="w"> </span><span class="s2">&quot;reset_states&quot;</span><span class="ss">)</span><span class="w"> </span><span class="nv">and</span><span class="w"> </span><span class="nv">getattr</span><span class="ss">(</span>

<span class="w">                </span><span class="nv">layer</span>,<span class="w"> </span><span class="s2">&quot;stateful&quot;</span>,<span class="w"> </span><span class="nv">False</span>

<span class="w">            </span><span class="ss">)</span>:

<span class="w">                </span><span class="nv">layer</span>.<span class="nv">reset_states</span><span class="ss">()</span>
</code></pre></div>

</details>
<h4 id="save_1">save</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filepath</span><span class="p">,</span>
    <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">include_optimizer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">save_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">signatures</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">save_traces</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</code></pre></div>

<p>Saves the model to Tensorflow SavedModel or a single HDF5 file.</p>
<p>Please see <code>tf.keras.models.save_model</code> or the
<a href="https://keras.io/guides/serialization_and_saving/">Serialization and Saving guide</a>
for details.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>filepath</td>
<td>None</td>
<td>String, PathLike, path to SavedModel or H5 file to save<br>the model.</td>
<td>None</td>
</tr>
<tr>
<td>overwrite</td>
<td>None</td>
<td>Whether to silently overwrite any existing file at the<br>target location, or provide the user with a manual prompt.</td>
<td>None</td>
</tr>
<tr>
<td>include_optimizer</td>
<td>None</td>
<td>If True, save optimizer's state together.</td>
<td>None</td>
</tr>
<tr>
<td>save_format</td>
<td>None</td>
<td>Either <code>'tf'</code> or <code>'h5'</code>, indicating whether to save the<br>model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF<br>2.X, and 'h5' in TF 1.X.</td>
<td>None</td>
</tr>
<tr>
<td>signatures</td>
<td>None</td>
<td>Signatures to save with the SavedModel. Applicable to<br>the 'tf' format only. Please see the <code>signatures</code> argument in<br><code>tf.saved_model.save</code> for details.</td>
<td>None</td>
</tr>
<tr>
<td>options</td>
<td>None</td>
<td>(only applies to SavedModel format)<br><code>tf.saved_model.SaveOptions</code> object that specifies options for<br>saving to SavedModel.</td>
<td>None</td>
</tr>
<tr>
<td>save_traces</td>
<td>None</td>
<td>(only applies to SavedModel format) When enabled, the<br>SavedModel will store the function traces for each layer. This<br>can be disabled, so that only the configs of each layer are<br>stored.  Defaults to <code>True</code>. Disabling this will decrease<br>serialization time and reduce file size, but it requires that<br>all custom layers/models implement a <code>get_config()</code> method.</td>
<td>None</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@traceback_utils.filter_traceback</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">save</span><span class="p">(</span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">filepath</span><span class="p">,</span>

<span class="w">        </span><span class="n">overwrite</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

<span class="w">        </span><span class="n">include_optimizer</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

<span class="w">        </span><span class="n">save_format</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">signatures</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="k">options</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">save_traces</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Saves the model to Tensorflow SavedModel or a single HDF5 file.</span>

<span class="s2">        Please see `tf.keras.models.save_model` or the</span>

<span class="s2">        [Serialization and Saving guide](</span>

<span class="s2">        https://keras.io/guides/serialization_and_saving/)</span>

<span class="s2">        for details.</span>

<span class="s2">        Args:</span>

<span class="s2">            filepath: String, PathLike, path to SavedModel or H5 file to save</span>

<span class="s2">                the model.</span>

<span class="s2">            overwrite: Whether to silently overwrite any existing file at the</span>

<span class="s2">                target location, or provide the user with a manual prompt.</span>

<span class="s2">            include_optimizer: If True, save optimizer&#39;s state together.</span>

<span class="s2">            save_format: Either `&#39;tf&#39;` or `&#39;h5&#39;`, indicating whether to save the</span>

<span class="s2">                model to Tensorflow SavedModel or HDF5. Defaults to &#39;tf&#39; in TF</span>

<span class="s2">                2.X, and &#39;h5&#39; in TF 1.X.</span>

<span class="s2">            signatures: Signatures to save with the SavedModel. Applicable to</span>

<span class="s2">                the &#39;tf&#39; format only. Please see the `signatures` argument in</span>

<span class="s2">                `tf.saved_model.save` for details.</span>

<span class="s2">            options: (only applies to SavedModel format)</span>

<span class="s2">                `tf.saved_model.SaveOptions` object that specifies options for</span>

<span class="s2">                saving to SavedModel.</span>

<span class="s2">            save_traces: (only applies to SavedModel format) When enabled, the</span>

<span class="s2">                SavedModel will store the function traces for each layer. This</span>

<span class="s2">                can be disabled, so that only the configs of each layer are</span>

<span class="s2">                stored.  Defaults to `True`. Disabling this will decrease</span>

<span class="s2">                serialization time and reduce file size, but it requires that</span>

<span class="s2">                all custom layers/models implement a `get_config()` method.</span>

<span class="s2">        Example:</span>

<span class="s2">        ```python</span>

<span class="s2">        from keras.models import load_model</span>

<span class="s2">        model.save(&#39;my_model.h5&#39;)  # creates a HDF5 file &#39;my_model.h5&#39;</span>

<span class="s2">        del model  # deletes the existing model</span>

<span class="s2">        # returns a compiled model</span>

<span class="s2">        # identical to the previous one</span>

<span class="s2">        model = load_model(&#39;my_model.h5&#39;)</span>

<span class="s2">        ```</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">save</span><span class="p">.</span><span class="n">save_model</span><span class="p">(</span>

<span class="w">            </span><span class="n">self</span><span class="p">,</span>

<span class="w">            </span><span class="n">filepath</span><span class="p">,</span>

<span class="w">            </span><span class="n">overwrite</span><span class="p">,</span>

<span class="w">            </span><span class="n">include_optimizer</span><span class="p">,</span>

<span class="w">            </span><span class="n">save_format</span><span class="p">,</span>

<span class="w">            </span><span class="n">signatures</span><span class="p">,</span>

<span class="w">            </span><span class="k">options</span><span class="p">,</span>

<span class="w">            </span><span class="n">save_traces</span><span class="p">,</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="save_spec_1">save_spec</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save_spec</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">dynamic_batch</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns the <code>tf.TensorSpec</code> of call inputs as a tuple <code>(args, kwargs)</code>.</p>
<p>This value is automatically defined after calling the model for the
first time. Afterwards, you can use it when exporting the model for
serving:</p>
<div class="codehilite"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

<span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">serve</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
  <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
  <span class="c1"># Apply postprocessing steps, or add additional outputs.</span>
  <span class="o">...</span>
  <span class="k">return</span> <span class="n">outputs</span>

<span class="c1"># arg_specs is `[tf.TensorSpec(...), ...]`. kwarg_specs, in this</span>
<span class="c1"># example, is an empty dict since functional models do not use keyword</span>
<span class="c1"># arguments.</span>
<span class="n">arg_specs</span><span class="p">,</span> <span class="n">kwarg_specs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">save_spec</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">signatures</span><span class="o">=</span><span class="p">{</span>
  <span class="s1">&#39;serving_default&#39;</span><span class="p">:</span> <span class="n">serve</span><span class="o">.</span><span class="n">get_concrete_function</span><span class="p">(</span><span class="o">*</span><span class="n">arg_specs</span><span class="p">,</span>
                                                 <span class="o">**</span><span class="n">kwarg_specs</span><span class="p">)</span>
<span class="p">})</span>
</code></pre></div>

<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>dynamic_batch</td>
<td>None</td>
<td>Whether to set the batch sizes of all the returned<br><code>tf.TensorSpec</code> to <code>None</code>. (Note that when defining functional or<br>Sequential models with <code>tf.keras.Input([...], batch_size=X)</code>, the<br>batch size will always be preserved). Defaults to <code>True</code>.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>If the model inputs are defined, returns a tuple <code>(args, kwargs)</code>. All<br>elements in <code>args</code> and <code>kwargs</code> are <code>tf.TensorSpec</code>.<br>If the model inputs are not defined, returns <code>None</code>.<br>The model inputs are automatically set when calling the model,<br><code>model.fit</code>, <code>model.evaluate</code> or <code>model.predict</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">save_spec</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">dynamic_batch</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns the `tf.TensorSpec` of call inputs as a tuple `(args, kwargs)`.</span>

<span class="s2">        This value is automatically defined after calling the model for the</span>

<span class="s2">        first time. Afterwards, you can use it when exporting the model for</span>

<span class="s2">        serving:</span>

<span class="s2">        ```python</span>

<span class="s2">        model = tf.keras.Model(...)</span>

<span class="s2">        @tf.function</span>

<span class="s2">        def serve(*args, **kwargs):</span>

<span class="s2">          outputs = model(*args, **kwargs)</span>

<span class="s2">          # Apply postprocessing steps, or add additional outputs.</span>

<span class="s2">          ...</span>

<span class="s2">          return outputs</span>

<span class="s2">        # arg_specs is `[tf.TensorSpec(...), ...]`. kwarg_specs, in this</span>

<span class="s2">        # example, is an empty dict since functional models do not use keyword</span>

<span class="s2">        # arguments.</span>

<span class="s2">        arg_specs, kwarg_specs = model.save_spec()</span>

<span class="s2">        model.save(path, signatures={</span>

<span class="s2">          &#39;serving_default&#39;: serve.get_concrete_function(*arg_specs,</span>

<span class="s2">                                                         **kwarg_specs)</span>

<span class="s2">        })</span>

<span class="s2">        ```</span>

<span class="s2">        Args:</span>

<span class="s2">          dynamic_batch: Whether to set the batch sizes of all the returned</span>

<span class="s2">            `tf.TensorSpec` to `None`. (Note that when defining functional or</span>

<span class="s2">            Sequential models with `tf.keras.Input([...], batch_size=X)`, the</span>

<span class="s2">            batch size will always be preserved). Defaults to `True`.</span>

<span class="s2">        Returns:</span>

<span class="s2">          If the model inputs are defined, returns a tuple `(args, kwargs)`. All</span>

<span class="s2">          elements in `args` and `kwargs` are `tf.TensorSpec`.</span>

<span class="s2">          If the model inputs are not defined, returns `None`.</span>

<span class="s2">          The model inputs are automatically set when calling the model,</span>

<span class="s2">          `model.fit`, `model.evaluate` or `model.predict`.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_save_spec</span><span class="p">(</span><span class="n">dynamic_batch</span><span class="p">,</span><span class="w"> </span><span class="n">inputs_only</span><span class="o">=</span><span class="no">False</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="save_weights_1">save_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save_weights</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filepath</span><span class="p">,</span>
    <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">save_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Saves all layer weights.</p>
<p>Either saves in HDF5 or in TensorFlow format based on the <code>save_format</code>
argument.</p>
<p>When saving in HDF5 format, the weight file has:
  - <code>layer_names</code> (attribute), a list of strings
      (ordered names of model layers).
  - For every layer, a <code>group</code> named <code>layer.name</code>
      - For every such layer group, a group attribute <code>weight_names</code>,
          a list of strings
          (ordered names of weights tensor of the layer).
      - For every weight in the layer, a dataset
          storing the weight value, named after the weight tensor.</p>
<p>When saving in TensorFlow format, all objects referenced by the network
are saved in the same format as <code>tf.train.Checkpoint</code>, including any
<code>Layer</code> instances or <code>Optimizer</code> instances assigned to object
attributes. For networks constructed from inputs and outputs using
<code>tf.keras.Model(inputs, outputs)</code>, <code>Layer</code> instances used by the network
are tracked/saved automatically. For user-defined classes which inherit
from <code>tf.keras.Model</code>, <code>Layer</code> instances must be assigned to object
attributes, typically in the constructor. See the documentation of
<code>tf.train.Checkpoint</code> and <code>tf.keras.Model</code> for details.</p>
<p>While the formats are the same, do not mix <code>save_weights</code> and
<code>tf.train.Checkpoint</code>. Checkpoints saved by <code>Model.save_weights</code> should
be loaded using <code>Model.load_weights</code>. Checkpoints saved using
<code>tf.train.Checkpoint.save</code> should be restored using the corresponding
<code>tf.train.Checkpoint.restore</code>. Prefer <code>tf.train.Checkpoint</code> over
<code>save_weights</code> for training checkpoints.</p>
<p>The TensorFlow format matches objects and variables by starting at a
root object, <code>self</code> for <code>save_weights</code>, and greedily matching attribute
names. For <code>Model.save</code> this is the <code>Model</code>, and for <code>Checkpoint.save</code>
this is the <code>Checkpoint</code> even if the <code>Checkpoint</code> has a model attached.
This means saving a <code>tf.keras.Model</code> using <code>save_weights</code> and loading
into a <code>tf.train.Checkpoint</code> with a <code>Model</code> attached (or vice versa)
will not match the <code>Model</code>'s variables. See the
<a href="https://www.tensorflow.org/guide/checkpoint">guide to training checkpoints</a> for details on
the TensorFlow format.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>filepath</td>
<td>None</td>
<td>String or PathLike, path to the file to save the weights<br>to. When saving in TensorFlow format, this is the prefix used<br>for checkpoint files (multiple files are generated). Note that<br>the '.h5' suffix causes weights to be saved in HDF5 format.</td>
<td>None</td>
</tr>
<tr>
<td>overwrite</td>
<td>None</td>
<td>Whether to silently overwrite any existing file at the<br>target location, or provide the user with a manual prompt.</td>
<td>None</td>
</tr>
<tr>
<td>save_format</td>
<td>None</td>
<td>Either 'tf' or 'h5'. A <code>filepath</code> ending in '.h5' or<br>'.keras' will default to HDF5 if <code>save_format</code> is <code>None</code>.<br>Otherwise <code>None</code> defaults to 'tf'.</td>
<td>None</td>
</tr>
<tr>
<td>options</td>
<td>None</td>
<td>Optional <code>tf.train.CheckpointOptions</code> object that specifies<br>options for saving weights.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ImportError</td>
<td>If <code>h5py</code> is not available when attempting to save in<br>HDF5 format.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="err">@</span><span class="n">traceback_utils</span><span class="o">.</span><span class="n">filter_traceback</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">save_weights</span><span class="p">(</span>

<span class="w">        </span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="n">overwrite</span><span class="o">=</span><span class="n">True</span><span class="p">,</span><span class="w"> </span><span class="n">save_format</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"> </span><span class="n">options</span><span class="o">=</span><span class="n">None</span>

<span class="w">    </span><span class="p">):</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;Saves all layer weights.</span>

<span class="sd">        Either saves in HDF5 or in TensorFlow format based on the `save_format`</span>

<span class="sd">        argument.</span>

<span class="sd">        When saving in HDF5 format, the weight file has:</span>

<span class="sd">          - `layer_names` (attribute), a list of strings</span>

<span class="sd">              (ordered names of model layers).</span>

<span class="sd">          - For every layer, a `group` named `layer.name`</span>

<span class="sd">              - For every such layer group, a group attribute `weight_names`,</span>

<span class="sd">                  a list of strings</span>

<span class="sd">                  (ordered names of weights tensor of the layer).</span>

<span class="sd">              - For every weight in the layer, a dataset</span>

<span class="sd">                  storing the weight value, named after the weight tensor.</span>

<span class="sd">        When saving in TensorFlow format, all objects referenced by the network</span>

<span class="sd">        are saved in the same format as `tf.train.Checkpoint`, including any</span>

<span class="sd">        `Layer` instances or `Optimizer` instances assigned to object</span>

<span class="sd">        attributes. For networks constructed from inputs and outputs using</span>

<span class="sd">        `tf.keras.Model(inputs, outputs)`, `Layer` instances used by the network</span>

<span class="sd">        are tracked/saved automatically. For user-defined classes which inherit</span>

<span class="sd">        from `tf.keras.Model`, `Layer` instances must be assigned to object</span>

<span class="sd">        attributes, typically in the constructor. See the documentation of</span>

<span class="sd">        `tf.train.Checkpoint` and `tf.keras.Model` for details.</span>

<span class="sd">        While the formats are the same, do not mix `save_weights` and</span>

<span class="sd">        `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should</span>

<span class="sd">        be loaded using `Model.load_weights`. Checkpoints saved using</span>

<span class="sd">        `tf.train.Checkpoint.save` should be restored using the corresponding</span>

<span class="sd">        `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over</span>

<span class="sd">        `save_weights` for training checkpoints.</span>

<span class="sd">        The TensorFlow format matches objects and variables by starting at a</span>

<span class="sd">        root object, `self` for `save_weights`, and greedily matching attribute</span>

<span class="sd">        names. For `Model.save` this is the `Model`, and for `Checkpoint.save`</span>

<span class="sd">        this is the `Checkpoint` even if the `Checkpoint` has a model attached.</span>

<span class="sd">        This means saving a `tf.keras.Model` using `save_weights` and loading</span>

<span class="sd">        into a `tf.train.Checkpoint` with a `Model` attached (or vice versa)</span>

<span class="sd">        will not match the `Model`&#39;s variables. See the</span>

<span class="sd">        [guide to training checkpoints](</span>

<span class="sd">        https://www.tensorflow.org/guide/checkpoint) for details on</span>

<span class="sd">        the TensorFlow format.</span>

<span class="sd">        Args:</span>

<span class="sd">            filepath: String or PathLike, path to the file to save the weights</span>

<span class="sd">                to. When saving in TensorFlow format, this is the prefix used</span>

<span class="sd">                for checkpoint files (multiple files are generated). Note that</span>

<span class="sd">                the &#39;.h5&#39; suffix causes weights to be saved in HDF5 format.</span>

<span class="sd">            overwrite: Whether to silently overwrite any existing file at the</span>

<span class="sd">                target location, or provide the user with a manual prompt.</span>

<span class="sd">            save_format: Either &#39;tf&#39; or &#39;h5&#39;. A `filepath` ending in &#39;.h5&#39; or</span>

<span class="sd">                &#39;.keras&#39; will default to HDF5 if `save_format` is `None`.</span>

<span class="sd">                Otherwise `None` defaults to &#39;tf&#39;.</span>

<span class="sd">            options: Optional `tf.train.CheckpointOptions` object that specifies</span>

<span class="sd">                options for saving weights.</span>

<span class="sd">        Raises:</span>

<span class="sd">            ImportError: If `h5py` is not available when attempting to save in</span>

<span class="sd">                HDF5 format.</span>

<span class="sd">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">_assert_weights_created</span><span class="p">()</span>

<span class="w">        </span><span class="n">filepath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">io_utils</span><span class="o">.</span><span class="n">path_to_string</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>

<span class="w">        </span><span class="n">filepath_is_h5</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">saving_utils</span><span class="o">.</span><span class="n">is_hdf5_filepath</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">filepath_is_h5</span><span class="p">:</span>

<span class="w">                </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;h5&quot;</span>

<span class="w">            </span><span class="k">else</span><span class="p">:</span>

<span class="w">                </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;tf&quot;</span>

<span class="w">        </span><span class="k">else</span><span class="p">:</span>

<span class="w">            </span><span class="n">user_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">save_format</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">user_format</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="p">(</span><span class="s2">&quot;tensorflow&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;tf&quot;</span><span class="p">):</span>

<span class="w">                </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;tf&quot;</span>

<span class="w">            </span><span class="k">elif</span><span class="w"> </span><span class="n">user_format</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="p">(</span><span class="s2">&quot;hdf5&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;h5&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;keras&quot;</span><span class="p">):</span>

<span class="w">                </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;h5&quot;</span>

<span class="w">            </span><span class="k">else</span><span class="p">:</span>

<span class="w">                </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                    </span><span class="n">f</span><span class="s2">&quot;Unknown format. Received: `save_format`={save_format}. &quot;</span>

<span class="w">                    </span><span class="s1">&#39;Was expecting one of {&quot;tf&quot;, &quot;h5&quot;}.&#39;</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">&quot;tf&quot;</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">filepath_is_h5</span><span class="p">:</span>

<span class="w">            </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                </span><span class="s1">&#39;save_weights got save_format=&quot;tf&quot;/&quot;tensorflow&quot;, but the &#39;</span>

<span class="w">                </span><span class="n">f</span><span class="s2">&quot;filepath ({filepath}) looks like an HDF5 file. &quot;</span>

<span class="w">                </span><span class="s1">&#39;Omit the &quot;.h5&quot;/&quot;.keras&quot; when saving in TensorFlow format.&#39;</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">&quot;h5&quot;</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">h5py</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">            </span><span class="n">raise</span><span class="w"> </span><span class="n">ImportError</span><span class="p">(</span>

<span class="w">                </span><span class="s2">&quot;`save_weights` requires h5py when saving in hdf5, but h5py is &quot;</span>

<span class="w">                </span><span class="s2">&quot;not available. Try installing h5py package.&quot;</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">&quot;tf&quot;</span><span class="p">:</span>

<span class="w">            </span><span class="n">check_filepath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">filepath</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s2">&quot;.index&quot;</span>

<span class="w">        </span><span class="k">else</span><span class="p">:</span>

<span class="w">            </span><span class="n">check_filepath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">filepath</span>

<span class="w">        </span><span class="c1"># If file exists and should not be overwritten:</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">overwrite</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">check_filepath</span><span class="p">):</span>

<span class="w">            </span><span class="n">proceed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">io_utils</span><span class="o">.</span><span class="n">ask_to_proceed_with_overwrite</span><span class="p">(</span><span class="n">check_filepath</span><span class="p">)</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">proceed</span><span class="p">:</span>

<span class="w">                </span><span class="k">return</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">&quot;h5&quot;</span><span class="p">:</span>

<span class="w">            </span><span class="n">with</span><span class="w"> </span><span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;w&quot;</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">f</span><span class="p">:</span>

<span class="w">                </span><span class="n">hdf5_format</span><span class="o">.</span><span class="n">save_weights_to_hdf5_group</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="p">)</span>

<span class="w">        </span><span class="k">else</span><span class="p">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>

<span class="w">                </span><span class="c1"># Call `get_session` to initialize any uninitialized variables.</span>

<span class="w">                </span><span class="n">backend</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">_checkpoint</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">)</span>

<span class="w">            </span><span class="c1"># Record this checkpoint so it&#39;s visible from</span>

<span class="w">            </span><span class="c1"># tf.train.latest_checkpoint.</span>

<span class="w">            </span><span class="n">tf</span><span class="o">.</span><span class="n">__internal__</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">update_checkpoint_state</span><span class="p">(</span>

<span class="w">                </span><span class="n">save_dir</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">filepath</span><span class="p">),</span>

<span class="w">                </span><span class="n">model_checkpoint_path</span><span class="o">=</span><span class="n">filepath</span><span class="p">,</span>

<span class="w">                </span><span class="n">save_relative_paths</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

<span class="w">                </span><span class="n">all_model_checkpoint_paths</span><span class="o">=</span><span class="p">[</span><span class="n">filepath</span><span class="p">],</span>

<span class="w">            </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="set_weights_1">set_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">set_weights</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">weights</span>
<span class="p">)</span>
</code></pre></div>

<p>Sets the weights of the layer, from NumPy arrays.</p>
<p>The weights of a layer represent the state of the layer. This function
sets the weight values from numpy arrays. The weight values should be
passed in the order they are created by the layer. Note that the layer's
weights must be instantiated before calling this function, by calling
the layer.</p>
<p>For example, a <code>Dense</code> layer returns a list of two values: the kernel
matrix and the bias vector. These can be used to set the weights of
another <code>Dense</code> layer:</p>
<blockquote>
<blockquote>
<blockquote>
<p>layer_a = tf.keras.layers.Dense(1,
...   kernel_initializer=tf.constant_initializer(1.))
a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))
layer_a.get_weights()
[array([[1.],
       [1.],
       [1.]], dtype=float32), array([0.], dtype=float32)]
layer_b = tf.keras.layers.Dense(1,
...   kernel_initializer=tf.constant_initializer(2.))
b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))
layer_b.get_weights()
[array([[2.],
       [2.],
       [2.]], dtype=float32), array([0.], dtype=float32)]
layer_b.set_weights(layer_a.get_weights())
layer_b.get_weights()
[array([[1.],
       [1.],
       [1.]], dtype=float32), array([0.], dtype=float32)]</p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>weights</td>
<td>None</td>
<td>a list of NumPy arrays. The number<br>of arrays and their shape must match<br>number of the dimensions of the weights<br>of the layer (i.e. it should match the<br>output of <code>get_weights</code>).</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>If the provided weights list does not match the<br>layer's specifications.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">set_weights</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span><span class="w"> </span><span class="n">weights</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s">&quot;&quot;&quot;Sets the weights of the layer, from NumPy arrays.</span>

<span class="w">        </span><span class="n">The</span><span class="w"> </span><span class="n">weights</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="n">represent</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">state</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">layer</span><span class="p">.</span><span class="w"> </span><span class="n">This</span><span class="w"> </span><span class="n">function</span>

<span class="w">        </span><span class="n">sets</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">weight</span><span class="w"> </span><span class="n">values</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="n">numpy</span><span class="w"> </span><span class="n">arrays</span><span class="p">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">weight</span><span class="w"> </span><span class="n">values</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">be</span>

<span class="w">        </span><span class="n">passed</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">order</span><span class="w"> </span><span class="n">they</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">created</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">layer</span><span class="p">.</span><span class="w"> </span><span class="n">Note</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">layer</span><span class="err">&#39;</span><span class="n">s</span>

<span class="w">        </span><span class="n">weights</span><span class="w"> </span><span class="n">must</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">instantiated</span><span class="w"> </span><span class="n">before</span><span class="w"> </span><span class="n">calling</span><span class="w"> </span><span class="n">this</span><span class="w"> </span><span class="n">function</span><span class="p">,</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">calling</span>

<span class="w">        </span><span class="n">the</span><span class="w"> </span><span class="n">layer</span><span class="p">.</span>

<span class="w">        </span><span class="n">For</span><span class="w"> </span><span class="n">example</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="err">`</span><span class="n">Dense</span><span class="err">`</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="n">returns</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">two</span><span class="w"> </span><span class="n">values</span><span class="o">:</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">kernel</span>

<span class="w">        </span><span class="n">matrix</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">bias</span><span class="w"> </span><span class="n">vector</span><span class="p">.</span><span class="w"> </span><span class="n">These</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">used</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">weights</span><span class="w"> </span><span class="n">of</span>

<span class="w">        </span><span class="n">another</span><span class="w"> </span><span class="err">`</span><span class="n">Dense</span><span class="err">`</span><span class="w"> </span><span class="n">layer</span><span class="o">:</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">layer_a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="p">...</span><span class="w">   </span><span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">constant_initializer</span><span class="p">(</span><span class="mf">1.</span><span class="p">))</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">a_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">layer_a</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">convert_to_tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span><span class="w"> </span><span class="mf">2.</span><span class="p">,</span><span class="w"> </span><span class="mf">3.</span><span class="p">]]))</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">layer_a</span><span class="p">.</span><span class="n">get_weights</span><span class="p">()</span>

<span class="w">        </span><span class="p">[</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">],</span>

<span class="w">               </span><span class="p">[</span><span class="mf">1.</span><span class="p">],</span>

<span class="w">               </span><span class="p">[</span><span class="mf">1.</span><span class="p">]],</span><span class="w"> </span><span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span><span class="w"> </span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">],</span><span class="w"> </span><span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)]</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">layer_b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="p">...</span><span class="w">   </span><span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">constant_initializer</span><span class="p">(</span><span class="mf">2.</span><span class="p">))</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">b_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">layer_b</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">convert_to_tensor</span><span class="p">([[</span><span class="mf">10.</span><span class="p">,</span><span class="w"> </span><span class="mf">20.</span><span class="p">,</span><span class="w"> </span><span class="mf">30.</span><span class="p">]]))</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">layer_b</span><span class="p">.</span><span class="n">get_weights</span><span class="p">()</span>

<span class="w">        </span><span class="p">[</span><span class="n">array</span><span class="p">([[</span><span class="mf">2.</span><span class="p">],</span>

<span class="w">               </span><span class="p">[</span><span class="mf">2.</span><span class="p">],</span>

<span class="w">               </span><span class="p">[</span><span class="mf">2.</span><span class="p">]],</span><span class="w"> </span><span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span><span class="w"> </span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">],</span><span class="w"> </span><span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)]</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">layer_b</span><span class="p">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">layer_a</span><span class="p">.</span><span class="n">get_weights</span><span class="p">())</span>

<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">layer_b</span><span class="p">.</span><span class="n">get_weights</span><span class="p">()</span>

<span class="w">        </span><span class="p">[</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">],</span>

<span class="w">               </span><span class="p">[</span><span class="mf">1.</span><span class="p">],</span>

<span class="w">               </span><span class="p">[</span><span class="mf">1.</span><span class="p">]],</span><span class="w"> </span><span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span><span class="w"> </span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">],</span><span class="w"> </span><span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)]</span>

<span class="w">        </span><span class="nl">Args</span><span class="p">:</span>

<span class="w">          </span><span class="nl">weights</span><span class="p">:</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">NumPy</span><span class="w"> </span><span class="n">arrays</span><span class="p">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">number</span>

<span class="w">            </span><span class="n">of</span><span class="w"> </span><span class="n">arrays</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">their</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="n">must</span><span class="w"> </span><span class="n">match</span>

<span class="w">            </span><span class="n">number</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">dimensions</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">weights</span>

<span class="w">            </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="p">.</span><span class="n">e</span><span class="p">.</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">match</span><span class="w"> </span><span class="n">the</span>

<span class="w">            </span><span class="n">output</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="err">`</span><span class="n">get_weights</span><span class="err">`</span><span class="p">).</span>

<span class="w">        </span><span class="nl">Raises</span><span class="p">:</span>

<span class="w">          </span><span class="nl">ValueError</span><span class="p">:</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">provided</span><span class="w"> </span><span class="n">weights</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">does</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">match</span><span class="w"> </span><span class="n">the</span>

<span class="w">            </span><span class="n">layer</span><span class="err">&#39;</span><span class="n">s</span><span class="w"> </span><span class="n">specifications</span><span class="p">.</span>

<span class="w">        </span><span class="s">&quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">params</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">weights</span>

<span class="w">        </span><span class="n">expected_num_weights</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">param</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">params</span><span class="o">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span><span class="w"> </span><span class="n">base_layer_utils</span><span class="p">.</span><span class="n">TrackableWeightHandler</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">expected_num_weights</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">param</span><span class="p">.</span><span class="n">num_tensors</span>

<span class="w">            </span><span class="nl">else</span><span class="p">:</span>

<span class="w">                </span><span class="n">expected_num_weights</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="mi">1</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">expected_num_weights</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                </span><span class="err">&#39;</span><span class="n">You</span><span class="w"> </span><span class="n">called</span><span class="w"> </span><span class="err">`</span><span class="n">set_weights</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span><span class="err">`</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="s">&quot;%s&quot;</span><span class="w"> </span><span class="err">&#39;</span>

<span class="w">                </span><span class="s">&quot;with a weight list of length %s, but the layer was &quot;</span>

<span class="w">                </span><span class="s">&quot;expecting %s weights. Provided weights: %s...&quot;</span>

<span class="w">                </span><span class="o">%</span><span class="w"> </span><span class="p">(</span>

<span class="w">                    </span><span class="nb">self</span><span class="p">.</span><span class="n">name</span><span class="p">,</span>

<span class="w">                    </span><span class="n">len</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span>

<span class="w">                    </span><span class="n">expected_num_weights</span><span class="p">,</span>

<span class="w">                    </span><span class="n">str</span><span class="p">(</span><span class="n">weights</span><span class="p">)[</span><span class="o">:</span><span class="mi">50</span><span class="p">],</span>

<span class="w">                </span><span class="p">)</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="n">weight_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>

<span class="w">        </span><span class="n">weight_value_tuples</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[]</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">param</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">params</span><span class="o">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span><span class="w"> </span><span class="n">base_layer_utils</span><span class="p">.</span><span class="n">TrackableWeightHandler</span><span class="p">)</span><span class="o">:</span>

<span class="w">                </span><span class="n">num_tensors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">param</span><span class="p">.</span><span class="n">num_tensors</span>

<span class="w">                </span><span class="n">tensors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">weights</span><span class="p">[</span><span class="n">weight_index</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">weight_index</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">num_tensors</span><span class="p">]</span>

<span class="w">                </span><span class="n">param</span><span class="p">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span>

<span class="w">                </span><span class="n">weight_index</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">num_tensors</span>

<span class="w">            </span><span class="nl">else</span><span class="p">:</span>

<span class="w">                </span><span class="n">weight</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">weights</span><span class="p">[</span><span class="n">weight_index</span><span class="p">]</span>

<span class="w">                </span><span class="n">weight_shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">weight</span><span class="p">.</span><span class="n">shape</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">hasattr</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;shape&quot;</span><span class="p">)</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">()</span>

<span class="w">                </span><span class="n">ref_shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">param</span><span class="p">.</span><span class="n">shape</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">ref_shape</span><span class="p">.</span><span class="n">is_compatible_with</span><span class="p">(</span><span class="n">weight_shape</span><span class="p">)</span><span class="o">:</span>

<span class="w">                    </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                        </span><span class="n">f</span><span class="s">&quot;Layer {self.name} weight shape {ref_shape} &quot;</span>

<span class="w">                        </span><span class="s">&quot;is not compatible with provided weight &quot;</span>

<span class="w">                        </span><span class="n">f</span><span class="s">&quot;shape {weight_shape}.&quot;</span>

<span class="w">                    </span><span class="p">)</span>

<span class="w">                </span><span class="n">weight_value_tuples</span><span class="p">.</span><span class="n">append</span><span class="p">((</span><span class="n">param</span><span class="p">,</span><span class="w"> </span><span class="n">weight</span><span class="p">))</span>

<span class="w">                </span><span class="n">weight_index</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="mi">1</span>

<span class="w">        </span><span class="n">backend</span><span class="p">.</span><span class="n">batch_set_value</span><span class="p">(</span><span class="n">weight_value_tuples</span><span class="p">)</span>

<span class="w">        </span><span class="cp"># Perform any layer defined finalization of the layer state.</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">_flatten_layers</span><span class="p">()</span><span class="o">:</span>

<span class="w">            </span><span class="n">layer</span><span class="p">.</span><span class="n">finalize_state</span><span class="p">()</span>
</code></pre></div>

</details>
<h4 id="summary_1">summary</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">summary</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">line_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">positions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">print_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">expand_nested</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">show_trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">layer_range</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Prints a string summary of the network.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>line_length</td>
<td>None</td>
<td>Total length of printed lines<br>(e.g. set this to adapt the display to different<br>terminal window sizes).</td>
<td>None</td>
</tr>
<tr>
<td>positions</td>
<td>None</td>
<td>Relative or absolute positions of log elements<br>in each line. If not provided,<br>defaults to <code>[.33, .55, .67, 1.]</code>.</td>
<td>None</td>
</tr>
<tr>
<td>print_fn</td>
<td>None</td>
<td>Print function to use. Defaults to <code>print</code>.<br>It will be called on each line of the summary.<br>You can set it to a custom function<br>in order to capture the string summary.</td>
<td><code>print</code></td>
</tr>
<tr>
<td>expand_nested</td>
<td>None</td>
<td>Whether to expand the nested models.<br>If not provided, defaults to <code>False</code>.</td>
<td>None</td>
</tr>
<tr>
<td>show_trainable</td>
<td>None</td>
<td>Whether to show if a layer is trainable.<br>If not provided, defaults to <code>False</code>.</td>
<td>None</td>
</tr>
<tr>
<td>layer_range</td>
<td>None</td>
<td>a list or tuple of 2 strings,<br>which is the starting layer name and ending layer name<br>(both inclusive) indicating the range of layers to be printed<br>in summary. It also accepts regex patterns instead of exact<br>name. In such case, start predicate will be the first element<br>it matches to <code>layer_range[0]</code> and the end predicate will be<br>the last element it matches to <code>layer_range[1]</code>.<br>By default <code>None</code> which considers all layers of model.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>if <code>summary()</code> is called before the model is built.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">summary</span><span class="p">(</span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">line_length</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">positions</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">print_fn</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">expand_nested</span><span class="o">=</span><span class="no">False</span><span class="p">,</span>

<span class="w">        </span><span class="n">show_trainable</span><span class="o">=</span><span class="no">False</span><span class="p">,</span>

<span class="w">        </span><span class="n">layer_range</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Prints a string summary of the network.</span>

<span class="s2">        Args:</span>

<span class="s2">            line_length: Total length of printed lines</span>

<span class="s2">                (e.g. set this to adapt the display to different</span>

<span class="s2">                terminal window sizes).</span>

<span class="s2">            positions: Relative or absolute positions of log elements</span>

<span class="s2">                in each line. If not provided,</span>

<span class="s2">                defaults to `[.33, .55, .67, 1.]`.</span>

<span class="s2">            print_fn: Print function to use. Defaults to `print`.</span>

<span class="s2">                It will be called on each line of the summary.</span>

<span class="s2">                You can set it to a custom function</span>

<span class="s2">                in order to capture the string summary.</span>

<span class="s2">            expand_nested: Whether to expand the nested models.</span>

<span class="s2">                If not provided, defaults to `False`.</span>

<span class="s2">            show_trainable: Whether to show if a layer is trainable.</span>

<span class="s2">                If not provided, defaults to `False`.</span>

<span class="s2">            layer_range: a list or tuple of 2 strings,</span>

<span class="s2">                which is the starting layer name and ending layer name</span>

<span class="s2">                (both inclusive) indicating the range of layers to be printed</span>

<span class="s2">                in summary. It also accepts regex patterns instead of exact</span>

<span class="s2">                name. In such case, start predicate will be the first element</span>

<span class="s2">                it matches to `layer_range[0]` and the end predicate will be</span>

<span class="s2">                the last element it matches to `layer_range[1]`.</span>

<span class="s2">                By default `None` which considers all layers of model.</span>

<span class="s2">        Raises:</span>

<span class="s2">            ValueError: if `summary()` is called before the model is built.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">built</span><span class="o">:</span>

<span class="w">            </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span>

<span class="w">                </span><span class="s2">&quot;This model has not yet been built. &quot;</span>

<span class="w">                </span><span class="s2">&quot;Build the model first by calling `build()` or by calling &quot;</span>

<span class="w">                </span><span class="s2">&quot;the model on a batch of data.&quot;</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">        </span><span class="n">layer_utils</span><span class="p">.</span><span class="n">print_summary</span><span class="p">(</span>

<span class="w">            </span><span class="n">self</span><span class="p">,</span>

<span class="w">            </span><span class="n">line_length</span><span class="o">=</span><span class="n">line_length</span><span class="p">,</span>

<span class="w">            </span><span class="n">positions</span><span class="o">=</span><span class="n">positions</span><span class="p">,</span>

<span class="w">            </span><span class="n">print_fn</span><span class="o">=</span><span class="n">print_fn</span><span class="p">,</span>

<span class="w">            </span><span class="n">expand_nested</span><span class="o">=</span><span class="n">expand_nested</span><span class="p">,</span>

<span class="w">            </span><span class="n">show_trainable</span><span class="o">=</span><span class="n">show_trainable</span><span class="p">,</span>

<span class="w">            </span><span class="n">layer_range</span><span class="o">=</span><span class="n">layer_range</span><span class="p">,</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="test_on_batch_1">test_on_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">test_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">reset_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Test the model on a single batch of samples.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input data. It could be:<br>- A Numpy array (or array-like), or a list of arrays (in case the<br>    model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors (in case the model has<br>    multiple inputs).<br>- A dict mapping input names to the corresponding array/tensors,<br>    if the model has named inputs.</td>
<td>None</td>
</tr>
<tr>
<td>y</td>
<td>None</td>
<td>Target data. Like the input data <code>x</code>, it could be either Numpy<br>array(s) or TensorFlow tensor(s). It should be consistent with <code>x</code><br>(you cannot have Numpy inputs and tensor targets, or inversely).</td>
<td>None</td>
</tr>
<tr>
<td>sample_weight</td>
<td>None</td>
<td>Optional array of the same length as x, containing<br>weights to apply to the model's loss for each sample. In the case<br>of temporal data, you can pass a 2D array with shape (samples,<br>sequence_length), to apply a different weight to every timestep of<br>every sample.</td>
<td>None</td>
</tr>
<tr>
<td>reset_metrics</td>
<td>None</td>
<td>If <code>True</code>, the metrics returned will be only for this<br>batch. If <code>False</code>, the metrics will be statefully accumulated<br>across batches.</td>
<td>None</td>
</tr>
<tr>
<td>return_dict</td>
<td>None</td>
<td>If <code>True</code>, loss and metric results are returned as a<br>dict, with each key being the name of the metric. If <code>False</code>, they<br>are returned as a list.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Scalar test loss (if the model has a single output and no metrics)<br>or list of scalars (if the model has multiple outputs<br>and/or metrics). The attribute <code>model.metrics_names</code> will give you<br>the display labels for the scalar outputs.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.test_on_batch</code> is wrapped in a<br><code>tf.function</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">test_on_batch</span><span class="p">(</span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">x</span><span class="p">,</span>

<span class="w">        </span><span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">reset_metrics</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

<span class="w">        </span><span class="n">return_dict</span><span class="o">=</span><span class="no">False</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Test the model on a single batch of samples.</span>

<span class="s2">        Args:</span>

<span class="s2">            x: Input data. It could be:</span>

<span class="s2">              - A Numpy array (or array-like), or a list of arrays (in case the</span>

<span class="s2">                  model has multiple inputs).</span>

<span class="s2">              - A TensorFlow tensor, or a list of tensors (in case the model has</span>

<span class="s2">                  multiple inputs).</span>

<span class="s2">              - A dict mapping input names to the corresponding array/tensors,</span>

<span class="s2">                  if the model has named inputs.</span>

<span class="s2">            y: Target data. Like the input data `x`, it could be either Numpy</span>

<span class="s2">              array(s) or TensorFlow tensor(s). It should be consistent with `x`</span>

<span class="s2">              (you cannot have Numpy inputs and tensor targets, or inversely).</span>

<span class="s2">            sample_weight: Optional array of the same length as x, containing</span>

<span class="s2">              weights to apply to the model&#39;s loss for each sample. In the case</span>

<span class="s2">              of temporal data, you can pass a 2D array with shape (samples,</span>

<span class="s2">              sequence_length), to apply a different weight to every timestep of</span>

<span class="s2">              every sample.</span>

<span class="s2">            reset_metrics: If `True`, the metrics returned will be only for this</span>

<span class="s2">              batch. If `False`, the metrics will be statefully accumulated</span>

<span class="s2">              across batches.</span>

<span class="s2">            return_dict: If `True`, loss and metric results are returned as a</span>

<span class="s2">              dict, with each key being the name of the metric. If `False`, they</span>

<span class="s2">              are returned as a list.</span>

<span class="s2">        Returns:</span>

<span class="s2">            Scalar test loss (if the model has a single output and no metrics)</span>

<span class="s2">            or list of scalars (if the model has multiple outputs</span>

<span class="s2">            and/or metrics). The attribute `model.metrics_names` will give you</span>

<span class="s2">            the display labels for the scalar outputs.</span>

<span class="s2">        Raises:</span>

<span class="s2">            RuntimeError: If `model.test_on_batch` is wrapped in a</span>

<span class="s2">              `tf.function`.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s2">&quot;test_on_batch&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s2">&quot;test_on_batch&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">reset_metrics</span><span class="o">:</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span>

<span class="w">            </span><span class="n">iterator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">single_batch_iterator</span><span class="p">(</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">make_test_function</span><span class="p">()</span>

<span class="w">            </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

<span class="w">        </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">return_dict</span><span class="o">:</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="k">logs</span>

<span class="w">        </span><span class="k">else</span><span class="o">:</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">flatten_metrics_in_order</span><span class="p">(</span><span class="k">logs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="test_step_1">test_step</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span>
<span class="p">)</span>
</code></pre></div>

<p>The logic for one evaluation step.</p>
<p>This method can be overridden to support custom evaluation logic.
This method is called by <code>Model.make_test_function</code>.</p>
<p>This function should contain the mathematical logic for one step of
evaluation.
This typically includes the forward pass, loss calculation, and metrics
updates.</p>
<p>Configuration details for <em>how</em> this logic is run (e.g. <code>tf.function</code>
and <code>tf.distribute.Strategy</code> settings), should be left to
<code>Model.make_test_function</code>, which can also be overridden.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>data</td>
<td>None</td>
<td>A nested structure of <code>Tensor</code>s.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A <code>dict</code> containing values that will be passed to<br><code>tf.keras.callbacks.CallbackList.on_train_batch_end</code>. Typically, the<br>values of the <code>Model</code>'s metrics are returned.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">test_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">data</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">The logic for one evaluation step.</span>

<span class="s2">        This method can be overridden to support custom evaluation logic.</span>

<span class="s2">        This method is called by `Model.make_test_function`.</span>

<span class="s2">        This function should contain the mathematical logic for one step of</span>

<span class="s2">        evaluation.</span>

<span class="s2">        This typically includes the forward pass, loss calculation, and metrics</span>

<span class="s2">        updates.</span>

<span class="s2">        Configuration details for *how* this logic is run (e.g. `tf.function`</span>

<span class="s2">        and `tf.distribute.Strategy` settings), should be left to</span>

<span class="s2">        `Model.make_test_function`, which can also be overridden.</span>

<span class="s2">        Args:</span>

<span class="s2">          data: A nested structure of `Tensor`s.</span>

<span class="s2">        Returns:</span>

<span class="s2">          A `dict` containing values that will be passed to</span>

<span class="s2">          `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the</span>

<span class="s2">          values of the `Model`&#39;s metrics are returned.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

<span class="w">        </span><span class="n">y_pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">training</span><span class="o">=</span><span class="no">False</span><span class="p">)</span>

<span class="w">        </span><span class="c1"># Updates stateful loss metrics.</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">compute_metrics</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="to_json_1">to_json</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">to_json</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns a JSON string containing the network configuration.</p>
<p>To load a network from a JSON save file, use
<code>keras.models.model_from_json(json_string, custom_objects={})</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Additional keyword arguments to be passed to<br>*<code>json.dumps()</code>.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A JSON string.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">to_json</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a JSON string containing the network configuration.</span>

<span class="sd">        To load a network from a JSON save file, use</span>

<span class="sd">        `keras.models.model_from_json(json_string, custom_objects={})`.</span>

<span class="sd">        Args:</span>

<span class="sd">            **kwargs: Additional keyword arguments to be passed to</span>

<span class="sd">                *`json.dumps()`.</span>

<span class="sd">        Returns:</span>

<span class="sd">            A JSON string.</span>

<span class="sd">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">model_config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_updated_config</span><span class="p">()</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span>

<span class="w">            </span><span class="n">model_config</span><span class="p">,</span><span class="w"> </span><span class="n">default</span><span class="o">=</span><span class="n">json_utils</span><span class="o">.</span><span class="n">get_json_type</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="to_yaml_1">to_yaml</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">to_yaml</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns a yaml string containing the network configuration.</p>
<p>Note: Since TF 2.6, this method is no longer supported and will raise a
RuntimeError.</p>
<p>To load a network from a yaml save file, use
<code>keras.models.model_from_yaml(yaml_string, custom_objects={})</code>.</p>
<p><code>custom_objects</code> should be a dictionary mapping
the names of custom losses / layers / etc to the corresponding
functions / classes.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Additional keyword arguments<br>to be passed to <code>yaml.dump()</code>.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A YAML string.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>announces that the method poses a security risk</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">to_yaml</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns a yaml string containing the network configuration.</span>

<span class="s2">        Note: Since TF 2.6, this method is no longer supported and will raise a</span>

<span class="s2">        RuntimeError.</span>

<span class="s2">        To load a network from a yaml save file, use</span>

<span class="s2">        `keras.models.model_from_yaml(yaml_string, custom_objects={})`.</span>

<span class="s2">        `custom_objects` should be a dictionary mapping</span>

<span class="s2">        the names of custom losses / layers / etc to the corresponding</span>

<span class="s2">        functions / classes.</span>

<span class="s2">        Args:</span>

<span class="s2">            **kwargs: Additional keyword arguments</span>

<span class="s2">                to be passed to `yaml.dump()`.</span>

<span class="s2">        Returns:</span>

<span class="s2">            A YAML string.</span>

<span class="s2">        Raises:</span>

<span class="s2">            RuntimeError: announces that the method poses a security risk</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">RuntimeError</span><span class="p">(</span>

<span class="w">            </span><span class="s2">&quot;Method `model.to_yaml()` has been removed due to security risk of &quot;</span>

<span class="w">            </span><span class="s2">&quot;arbitrary code execution. Please use `model.to_json()` instead.&quot;</span>

<span class="w">        </span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="train_on_batch_1">train_on_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">train_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">reset_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Runs a single gradient update on a single batch of data.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input data. It could be:<br>- A Numpy array (or array-like), or a list of arrays<br>    (in case the model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors<br>    (in case the model has multiple inputs).<br>- A dict mapping input names to the corresponding array/tensors,<br>    if the model has named inputs.</td>
<td>None</td>
</tr>
<tr>
<td>y</td>
<td>None</td>
<td>Target data. Like the input data <code>x</code>, it could be either Numpy<br>array(s) or TensorFlow tensor(s).</td>
<td>None</td>
</tr>
<tr>
<td>sample_weight</td>
<td>None</td>
<td>Optional array of the same length as x, containing<br>weights to apply to the model's loss for each sample. In the case<br>of temporal data, you can pass a 2D array with shape (samples,<br>sequence_length), to apply a different weight to every timestep of<br>every sample.</td>
<td>None</td>
</tr>
<tr>
<td>class_weight</td>
<td>None</td>
<td>Optional dictionary mapping class indices (integers)<br>to a weight (float) to apply to the model's loss for the samples<br>from this class during training. This can be useful to tell the<br>model to "pay more attention" to samples from an under-represented<br>class.</td>
<td>None</td>
</tr>
<tr>
<td>reset_metrics</td>
<td>None</td>
<td>If <code>True</code>, the metrics returned will be only for this<br>batch. If <code>False</code>, the metrics will be statefully accumulated<br>across batches.</td>
<td>None</td>
</tr>
<tr>
<td>return_dict</td>
<td>None</td>
<td>If <code>True</code>, loss and metric results are returned as a<br>dict, with each key being the name of the metric. If <code>False</code>, they<br>are returned as a list.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Scalar training loss<br>(if the model has a single output and no metrics)<br>or list of scalars (if the model has multiple outputs<br>and/or metrics). The attribute <code>model.metrics_names</code> will give you<br>the display labels for the scalar outputs.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.train_on_batch</code> is wrapped in a <code>tf.function</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">train_on_batch</span><span class="p">(</span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">x</span><span class="p">,</span>

<span class="w">        </span><span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">class_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">reset_metrics</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

<span class="w">        </span><span class="n">return_dict</span><span class="o">=</span><span class="no">False</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single gradient update on a single batch of data.</span>

<span class="s2">        Args:</span>

<span class="s2">            x: Input data. It could be:</span>

<span class="s2">              - A Numpy array (or array-like), or a list of arrays</span>

<span class="s2">                  (in case the model has multiple inputs).</span>

<span class="s2">              - A TensorFlow tensor, or a list of tensors</span>

<span class="s2">                  (in case the model has multiple inputs).</span>

<span class="s2">              - A dict mapping input names to the corresponding array/tensors,</span>

<span class="s2">                  if the model has named inputs.</span>

<span class="s2">            y: Target data. Like the input data `x`, it could be either Numpy</span>

<span class="s2">              array(s) or TensorFlow tensor(s).</span>

<span class="s2">            sample_weight: Optional array of the same length as x, containing</span>

<span class="s2">              weights to apply to the model&#39;s loss for each sample. In the case</span>

<span class="s2">              of temporal data, you can pass a 2D array with shape (samples,</span>

<span class="s2">              sequence_length), to apply a different weight to every timestep of</span>

<span class="s2">              every sample.</span>

<span class="s2">            class_weight: Optional dictionary mapping class indices (integers)</span>

<span class="s2">              to a weight (float) to apply to the model&#39;s loss for the samples</span>

<span class="s2">              from this class during training. This can be useful to tell the</span>

<span class="s2">              model to &quot;</span><span class="n">pay</span><span class="w"> </span><span class="n">more</span><span class="w"> </span><span class="n">attention</span><span class="s2">&quot; to samples from an under-represented</span>

<span class="s2">              class.</span>

<span class="s2">            reset_metrics: If `True`, the metrics returned will be only for this</span>

<span class="s2">              batch. If `False`, the metrics will be statefully accumulated</span>

<span class="s2">              across batches.</span>

<span class="s2">            return_dict: If `True`, loss and metric results are returned as a</span>

<span class="s2">              dict, with each key being the name of the metric. If `False`, they</span>

<span class="s2">              are returned as a list.</span>

<span class="s2">        Returns:</span>

<span class="s2">            Scalar training loss</span>

<span class="s2">            (if the model has a single output and no metrics)</span>

<span class="s2">            or list of scalars (if the model has multiple outputs</span>

<span class="s2">            and/or metrics). The attribute `model.metrics_names` will give you</span>

<span class="s2">            the display labels for the scalar outputs.</span>

<span class="s2">        Raises:</span>

<span class="s2">          RuntimeError: If `model.train_on_batch` is wrapped in a `tf.function`.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s2">&quot;train_on_batch&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s2">&quot;train_on_batch&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">reset_metrics</span><span class="o">:</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">(),</span><span class="w"> </span><span class="n">training_utils</span><span class="p">.</span><span class="n">RespectCompiledTrainableState</span><span class="p">(</span><span class="w">  </span><span class="c1"># noqa: E501</span>

<span class="w">            </span><span class="n">self</span>

<span class="w">        </span><span class="p">)</span><span class="o">:</span>

<span class="w">            </span><span class="n">iterator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">single_batch_iterator</span><span class="p">(</span>

<span class="w">                </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">,</span><span class="w"> </span><span class="n">class_weight</span>

<span class="w">            </span><span class="p">)</span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">make_train_function</span><span class="p">()</span>

<span class="w">            </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

<span class="w">        </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">return_dict</span><span class="o">:</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="k">logs</span>

<span class="w">        </span><span class="k">else</span><span class="o">:</span>

<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">flatten_metrics_in_order</span><span class="p">(</span><span class="k">logs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="train_step_1">train_step</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span>
<span class="p">)</span>
</code></pre></div>

<p>The logic for one training step.</p>
<p>This method can be overridden to support custom training logic.
For concrete examples of how to override this method see
<a href="https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit">Customizing what happens in fit</a>.
This method is called by <code>Model.make_train_function</code>.</p>
<p>This method should contain the mathematical logic for one step of
training.  This typically includes the forward pass, loss calculation,
backpropagation, and metric updates.</p>
<p>Configuration details for <em>how</em> this logic is run (e.g. <code>tf.function</code>
and <code>tf.distribute.Strategy</code> settings), should be left to
<code>Model.make_train_function</code>, which can also be overridden.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>data</td>
<td>None</td>
<td>A nested structure of <code>Tensor</code>s.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A <code>dict</code> containing values that will be passed to<br><code>tf.keras.callbacks.CallbackList.on_train_batch_end</code>. Typically, the<br>values of the <code>Model</code>'s metrics are returned. Example:<br><code>{'loss': 0.2, 'accuracy': 0.7}</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">train_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">data</span><span class="p">)</span><span class="o">:</span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">The logic for one training step.</span>

<span class="s2">        This method can be overridden to support custom training logic.</span>

<span class="s2">        For concrete examples of how to override this method see</span>

<span class="s2">        [Customizing what happens in fit](</span>

<span class="s2">        https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit).</span>

<span class="s2">        This method is called by `Model.make_train_function`.</span>

<span class="s2">        This method should contain the mathematical logic for one step of</span>

<span class="s2">        training.  This typically includes the forward pass, loss calculation,</span>

<span class="s2">        backpropagation, and metric updates.</span>

<span class="s2">        Configuration details for *how* this logic is run (e.g. `tf.function`</span>

<span class="s2">        and `tf.distribute.Strategy` settings), should be left to</span>

<span class="s2">        `Model.make_train_function`, which can also be overridden.</span>

<span class="s2">        Args:</span>

<span class="s2">          data: A nested structure of `Tensor`s.</span>

<span class="s2">        Returns:</span>

<span class="s2">          A `dict` containing values that will be passed to</span>

<span class="s2">          `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the</span>

<span class="s2">          values of the `Model`&#39;s metrics are returned. Example:</span>

<span class="s2">          `{&#39;loss&#39;: 0.2, &#39;accuracy&#39;: 0.7}`.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

<span class="w">        </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

<span class="w">        </span><span class="c1"># Run forward pass.</span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">GradientTape</span><span class="p">()</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">tape</span><span class="o">:</span>

<span class="w">            </span><span class="n">y_pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">training</span><span class="o">=</span><span class="no">True</span><span class="p">)</span>

<span class="w">            </span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">)</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_validate_target_and_loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">loss</span><span class="p">)</span>

<span class="w">        </span><span class="c1"># Run backwards pass.</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">,</span><span class="w"> </span><span class="n">tape</span><span class="o">=</span><span class="n">tape</span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">compute_metrics</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">)</span>
</code></pre></div>

</details>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        
<footer class="md-footer">
    
      <nav class="md-footer__inner md-grid" aria-label="Footer">
        
          
          <a href="../" class="md-footer__link md-footer__link--prev" aria-label="Previous: Index" rel="prev">
            <div class="md-footer__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <div class="md-ellipsis">
                <span class="md-footer__direction">
                  Previous
                </span>
                Index
              </div>
            </div>
          </a>
        
        
          
          <a href="../mask/" class="md-footer__link md-footer__link--next" aria-label="Next: Mask" rel="next">
            <div class="md-footer__title">
              <div class="md-ellipsis">
                <span class="md-footer__direction">
                  Next
                </span>
                Mask
              </div>
            </div>
            <div class="md-footer__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
            
            Powered by
            <a href="http://timothycrosley.github.io/portray">portray.</a>
            You too can
            <a href="http://timothycrosley.github.io/portray">
              portray</a>
            your Python project well using automatic documentation.
          </div>
        
      </div>
    </div>
  </footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../..", "features": [], "search": "../../../assets/javascripts/workers/search.5bf1dace.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.078830c0.min.js"></script>
      
    
  </body>
</html>